{
 "cells": [
  {
   "attachments": {
    "2c62c3c8-94ae-4044-bcd0-219b4d11a26b.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "fbbd8230-d5ef-419d-8f00-21a2697091ff",
   "metadata": {},
   "source": [
    "## `Elvis-Bot` with prompt bootstrapping using LangSmith + Claude\n",
    "\n",
    "Many users ask about how to customize an LLM to write in their voice or in a paritcular style.\n",
    "\n",
    "Let's consider Twitter as an example: \n",
    "\n",
    "[`@omarsar0`](https://twitter.com/omarsar0), Elvis Saravia, is a user who write fantastic paper summaries.\n",
    "\n",
    "Let's assume I want to prompt an LLM to write in this style.\n",
    "\n",
    "The challenge is that it's a non-trivial prompt engineering task! \n",
    "\n",
    "--- \n",
    "\n",
    "Enter Claude3, which has [very strong prompt engineering](https://twitter.com/alexalbert__/status/1767258557039378511?s=20) capabilities.\n",
    "\n",
    "[`@alexalbert__`](https://twitter.com/alexalbert__/status/1767258557039378511?s=20) presented a nice flow for doing this:\n",
    "\n",
    "```\n",
    "1. I write an initial prompt for a task.\n",
    "\n",
    "2. I use Opus to generate a diverse test dataset.\n",
    "\n",
    "3. I run the prompt on all the test cases in the generated dataset.\n",
    "\n",
    "4. Manually make evaluations.\n",
    "\n",
    "5. Using these observations, I ask Opus to generate a new version of the original prompt.\n",
    "\n",
    "6. Repeat\n",
    "```\n",
    "\n",
    "![prompt-optimizer.png](attachment:2c62c3c8-94ae-4044-bcd0-219b4d11a26b.png)\n",
    "\n",
    "Below we can show how to implement this flow using LangSmith and apply it creating prompts in the style of @omarsar0 (Elvis Saravia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dafa0ad7-3b94-4cd4-b9dd-3061b2216cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (1.23.26)\n",
      "Requirement already satisfied: arxiv in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: langchainhub in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (0.1.15)\n",
      "Requirement already satisfied: langsmith in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (0.1.31)\n",
      "Requirement already satisfied: langchain_anthropic in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (0.1.13)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (0.0.8)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (0.1.33)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from pymupdf) (1.23.22)\n",
      "Requirement already satisfied: feedparser==6.0.10 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from arxiv) (6.0.10)\n",
      "Requirement already satisfied: requests==2.31.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from arxiv) (2.31.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from feedparser==6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from requests==2.31.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from requests==2.31.0->arxiv) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from requests==2.31.0->arxiv) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from requests==2.31.0->arxiv) (2023.11.17)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchainhub) (2.31.0.20240311)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langsmith) (3.9.15)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langsmith) (2.6.0)\n",
      "Requirement already satisfied: anthropic<1,>=0.17.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain_anthropic) (0.21.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain_anthropic) (0.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain_openai) (1.10.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain_openai) (0.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain_core) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from anthropic<1,>=0.17.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from anthropic<1,>=0.17.0->langchain_anthropic) (0.26.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from anthropic<1,>=0.17.0->langchain_anthropic) (1.3.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from anthropic<1,>=0.17.0->langchain_anthropic) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from anthropic<1,>=0.17.0->langchain_anthropic) (4.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from pydantic<3,>=1->langsmith) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from pydantic<3,>=1->langsmith) (2.16.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.17.0->langchain_anthropic) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.17.0->langchain_anthropic) (0.14.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from tokenizers>=0.13.0->anthropic<1,>=0.17.0->langchain_anthropic) (0.21.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.17.0->langchain_anthropic) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nick\\anaconda3\\envs\\aisys\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.17.0->langchain_anthropic) (2024.3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U pymupdf arxiv langchainhub langsmith langchain_anthropic langchain langchain_openai langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0079fae2-2b33-4e6d-b479-88389b446968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass.getpass(var + \":\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Self-Promt\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d6452-6549-4f1d-984e-07415d6b2b63",
   "metadata": {},
   "source": [
    "## 1. Get Papers, Store As Dataset\n",
    "\n",
    "I choose 4 papers that @omarsar0 has Tweeted under 32k tokens per paper :\n",
    "\n",
    "https://arxiv.org/abs/2403.05313\n",
    "\n",
    "https://arxiv.org/abs/2403.04121\n",
    "\n",
    "https://arxiv.org/abs/2402.15809\n",
    "\n",
    "https://arxiv.org/abs/2403.07816\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcb350bd-88b2-45d2-b987-840b738528bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "# Arxiv IDs\n",
    "ids = [\"2403.05313\", \"2403.04121\", \"2402.15809\", \"2403.08319\", \"2403.07816\"]\n",
    "\n",
    "# Load papers\n",
    "docs = []\n",
    "for paper_id in ids:\n",
    "    doc = ArxivLoader(query=paper_id, load_max_docs=1).load()\n",
    "    docs.extend(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a7eacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='March 2024\\nRAT: Retrieval Augmented Thoughts Elicit\\nContext-Aware Reasoning in Long-Horizon\\nGeneration\\nZihao Wang1, Anji Liu2, Haowei Lin1, Jiaqi Li3, Xiaojian Ma3 and Yitao Liang1\\n1Peking University, 2University of California, Los Angeles, 3Beijing Institute for General Artificial Intelligence\\nWe explore how iterative revising a chain of thoughts with the help of information retrieval significantly\\nimproves large language models’ reasoning and generation ability in long-horizon generation tasks, while\\nhugely mitigating hallucination. In particular, the proposed method — retrieval-augmented thoughts\\n(RAT) — revises each thought step one by one with retrieved information relevant to the task query,\\nthe current and the past thought steps, after the initial zero-shot CoT is generated. Applying RAT to\\nGPT-3.5, GPT-4, and CodeLLaMA-7b substantially improves their performances on various long-horizon\\ngeneration tasks; on average of relatively increasing rating scores by 13.63% on code generation, 16.96%\\non mathematical reasoning, 19.2% on creative writing, and 42.78% on embodied task planning.\\nThe demo page can be found in https://craftjarvis.github.io/RAT.\\n1. Introduction\\nLarge Language Models (LLMs) have achieved\\nfruitful progress on various natural language rea-\\nsoning tasks (Brown et al., 2020; Wang et al.,\\n2023a; Wei et al., 2022; Yao et al., 2022; Zhou\\net al., 2023), especially when combining large-\\nscale models (OpenAI, 2023; Team, 2022) with\\nsophisticated prompting strategies, notably chain-\\nof-thought (CoT) prompting (Kojima et al., 2022;\\nWei et al., 2022). However, there have been in-\\ncreasing concerns about the factual correctness of\\nLLMs reasoning, citing the possible hallucinations\\nin model responses (Rawte et al., 2023) or the\\nintermediate reasoning paths, i.e. CoTs (Dhuli-\\nawala et al., 2023). This issue becomes more sig-\\nnificant when it comes to zero-shot CoT prompt-\\ning, aka. “let’s think step-by-step” (Kojima et al.,\\n2022) and long-horizon generation tasks that re-\\nquire multi-step and context-aware reasoning, in-\\ncluding code generation, task planning, mathe-\\nmatical reasoning, etc. Factually valid interme-\\ndiate thoughts could be critical to the successful\\ncompletion of these tasks.\\nSeveral prompting techniques have been\\nproposed to mitigate this issue, one promis-\\ning direction, Retrieval Augmented Generation\\n(RAG) (Lewis et al., 2020b) seeks insights from\\nhuman reasoning (Holyoak and Morrison, 2012),\\nand utilizes retrieved information to facilitate\\nmore factually grounded reasoning. In this paper,\\nwe explore how to synergize RAG with sophis-\\nticated long-horizon reasoning. Our intuition is\\nthat the hallucination within the intermediate\\nreasoning process could be alleviated through\\nthe help of outside knowledge. The resulting\\nprompting strategy, retrieval-augmented thoughts\\n(RAT), is illustrated in Figure 1. Our strategy com-\\nprises two key ideas. Firstly, the initial zero-shot\\nCoT produced by LLMs along with the original\\ntask prompt will be used as queries to retrieve\\nthe information that could help revise the possi-\\nbly flawed CoT. Secondly, instead of retrieving\\nand revising with the full CoT and producing\\nthe final response at once, we devise a progres-\\nsive approach, where LLMs produce the response\\nstep-by-step following the CoT (a series of sub-\\ntasks), and only the current thought step will\\nbe revised based on the information retrieved\\nwith task prompt, the current and the past CoTs.\\nThis strategy can be an analogy to the human\\nreasoning process: we utilize outside knowledge\\nto adjust our step-by-step thinking during com-\\nplex long-horizon problem-solving (Holyoak and\\nMorrison, 2012). A comparison of RAT and coun-\\nterparts can be found in Figure 2.\\nWe evaluate RAT on a wide collection of chal-\\nlenging long-horizon tasks, including code gen-\\nCorresponding author(s): Yitao Liang yitaol@pku.edu.cn\\n<Zihao Wang> zhwang@stu.pku.edu.cn <Anji Liu> liuanji@cs.ucla.edu <Haowei Lin> linhaowei@pku.edu.cn\\n<Jiaqi Li> ljqjane@gmail.com <Xiaojian Ma> xiaojian.ma@ucla.edu\\narXiv:2403.05313v1  [cs.CL]  8 Mar 2024\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nStep 0\\nDraft initial step-by-step zero-shot\\nCoTs based on the task prompt.\\nA task prompt\\nis given by a \\nhuman user.\\nLLM makes\\nzero-shot\\nstep-by-step\\nreasoning based\\non the prompt.\\nThis initial\\nzero-shot CoT \\nanswer may\\nbe ﬂawed.\\nHow to obtain diamond\\nsword in Minecraft?\\nLLM\\nTask Prompt (I)\\nT1: Mine 4 planks (ﬂawed)\\nT2: craft table from planks\\n...\\nTn: Craft diamond sword\\nInitial CoTs\\nRetrieve with\\nthe task prompt\\nand previous\\ngenerated CoTs.\\nLLM revises the\\ni-th steps in thought\\nchains (T1:i-1, Ti)\\nbased on the\\nretrieved content.\\nThe thought chain \\n(T1:i-1, Ti) is replaced\\nwith the revised \\ngeneration T1:i.\\nT1*\\nT2\\nT3\\nTn\\n...\\nT1*: Mine 4 logs\\nT2: craft table from planks\\n...\\nTn: Craft diamond sword\\nRevised CoTs\\nStep 1 - Step n\\nStep 1\\nStep n\\nRetrieve relevant information and iteratively revise \\neach CoT with all previous generations in context.\\nRetrieval\\nT1\\nLibrary\\nR1\\nAugmented Revision\\nI\\nRn\\nT1*\\nT1*\\nT2*\\nT3*\\nTn*\\n...\\nT1*: Mine 4 logs\\nT2*: craft 12 planks\\n...\\nTn*: Craft diamond sword\\nRevised CoTs\\nRetrieval\\nLibrary\\nRn\\nT1* T2*\\nTn\\n...\\n...\\nAugmented Revision\\nI\\nRn\\nT1*\\nT2*\\n...\\nT1\\nT2\\nT3\\nTn\\n...\\n*\\n*\\n*\\nFigure 1 | Pipeline of Retrieval Augmented Thoughts (RAT). Given a task prompt (denoted as I in the\\nfigure), RAT starts from initial step-by-step thoughts (𝑇1, 𝑇2, · · · , 𝑇𝑛) produced by an LLM in zero-shot (“let’s\\nthink step by step”). Some thought steps (such as 𝑇1 in the figure) may be flawed due to hallucination. RAT\\niteratively revises each thought step (𝑇★\\n1 , 𝑇★\\n2 , · · · , 𝑇★\\n𝑖−1, 𝑇𝑖) using RAG from an external knowledge base (denoted\\nas Library). Detailed prompting strategy can be found in subsection 2.2.\\neration, mathematical reasoning, embodied task\\nplanning, and creative writing. We employ sev-\\neral LLMs of varied scales:\\nGPT-3.5 (Brown\\net al., 2020), GPT-4 (OpenAI, 2023), CodeLLaMA-\\n7b (Rozière et al., 2023). The results indicate that\\ncombing RAT with these LLMs elicits strong ad-\\nvantages over vanilla CoT prompting and RAG\\napproaches. In particular, we observe new state-\\nof-the-art level of performances across our selec-\\ntion of tasks: 1) code generation: HumanEval\\n(+20.94%), HumanEval+ (+18.89%), MBPP\\n(+14.83%), MBPP+ (+1.86%); 2) mathemat-\\nical reasoning problems: GSM8K (+8.36%), and\\nGSMHard (+31.37%); 3) Minecraft task plan-\\nning (2.96 times on executability and +51.94%\\non plausibility); 4) creative writing (+19.19%\\non human score). Our additional ablation studies\\nfurther confirm the crucial roles played by the\\ntwo key ingredients of RAT: revising CoT using\\nRAG and progressive revision & generation. This\\nwork reveals how can LLMs revise their reasoning\\nprocess in a zero-shot fashion with the help of\\noutside knowledge, just as what humans do.\\n2. Retrieval Augmented Thoughts\\nOur goal is to support long-horizon reasoning and\\ngeneration while mitigating hallucination when\\nusing LLMs. To have satisfying performance on\\nlong-horizon tasks, two ingredients are indispens-\\nable. Firstly, access to factual information can\\nbe facilitated by retrieval. Secondly, appropriate\\nintermediate steps that outline a scratchpad to\\nfinish complex tasks, can be facilitated by CoT.\\nYet, a naive combination of the two would not\\nnecessarily yield improvements. Two questions\\nstill persist: (1) what is relevant information to\\nretrieve; (2) how to effectively correct reasoning\\nsteps with relevant factual information. To better\\nappreciate our method and why our method can\\naddress these two questions, we first provide a\\nbrief preliminary introduction of RAG and CoT.\\n2.1. Preliminary\\nRetrieval-Augmented Generation (RAG) targets\\nthe problem of generating fictitious facts by pro-\\n2\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nDIRECT\\nQ: Introduce Jin Yong\\'s life.\\nA: Jin Yong, born Louis Cha in 1924 …\\nGraduating from the University of Cambridge,\\nhe later begin to write full-time, leaving an\\nindelible mark on Chinese literature and\\nculture... [not informative, loose structure]\\n😿\\nCoT\\nQ: Introduce Jin Yong\\'s life. Let’s \\nthink it step-by-step.\\nA: Jin Yong is a Chinese novelist... \\nThe details of his life are \\nintroduced as follows:\\nEarly Life: Jin Yong, born on \\nFebruary 6, 1924...\\nEducation: ...He graduated from \\nthe University of Cambridge \\nbefore dedicating himself to \\nwriting full-time...\\nLiterature: His ﬁrst novel, \"The \\nBook and the Sword,\" was \\npublished in 1955, followed by \\nsuccessful works including \\n\"Handsome Siblings\", ...\\nRAT\\nQ: Introduce Jin Yong\\'s life. Let’s think it step-by-step.\\nA: Jin Yong is a Chinese novelist... The details of his life \\nare introduced as follows:\\nEarly Life: Jin Yong, born on February 6, 1924, in \\nHaining, Zhejiang province, China, was a renowned \\nChinese novelist known by his pen name Louis Cha....\\nEducation: ...In his eighties, he applied at Cambridge\\nUniversity for a doctorate in AsianStudies and\\nanother doctorate in Chinese literature at\\nPeking University...\\nLiterature: In 1955, Jin Yong published his first arts \\nnovel, \"The Book and the Sword,\" which achieved \\nimmense success and marked the beginning of his \\nliterary journey. He went on to write many acclaimed \\nnovels, including the revered \"Legends of the Condor \\nHeroes\" and \"The Deer and the Cauldron.\"\\n😸\\nRAG\\nQ: Introduce Jin Yong\\'s life.\\nA: Jin Yong, born Louis Cha in 1924... In his \\neighties, he applied at Cambridge University \\nfor a doctorate in Asian Studies and another \\ndoctorate in Chinese literature at Peking \\nUniversity... [too specific, loose structure]😾\\n😿\\nFigure 2 | Top: An example of different LLM reasoning methods on creative generation tasks. Red text indicates\\nerrors or illusions in the text generated by LLM, while green text represents correct generation. Methods\\nwithout RAG often generate incorrect information with hallucination, classical RAG is highly related to retrieved\\ncontent with a loose structure, and RAT-generated texts perform best in terms of accuracy and completeness.\\nBottom: The quantitative performance comparison for different LLM reasoning methods on complex embodied\\nplanning, mathematical reasoning, code generation, and creative generation tasks. Our RAT outperforms all\\nthe baselines on all tasks.\\nviding LLMs with relevant text extracted from\\ntrusted sources. It is primarily used in question-\\nanswering (QA) tasks (Lewis et al., 2020b).\\nSpecifically, given a set of 𝑛 candidate documents\\n𝑅 := {𝑅𝑖}𝑛\\n𝑖=1, RAG aims to retrieve the most rel-\\nevant ones w.r.t. a query 𝑄, which can be the\\nquestion/task prompt itself or relevant informa-\\ntion generated by LLMs. To achieve this, RAG first\\nextracts semantic-aware embeddings of the docu-\\nments 𝑟𝑖 := emb(𝑅𝑖) ∈ ℝ𝐾 (𝐾 is the size of the em-\\nbedding) as well as the query 𝑞 := emb(𝑄) ∈ ℝ𝐾.\\nemb(·) can be implemented with various text em-\\nbedding models, such as Sentence-BERT (Reimers\\nand Gurevych, 2019). The relevance between the\\nquery and a document is measured by their cosine\\nsimilarity:\\nsim(𝑄, 𝑅𝑖) =\\n𝑞 · 𝑟𝑖\\n∥𝑞∥∥𝑟𝑖∥ .\\nBased on their relevance, the top-ranked 𝑘 doc-\\numents are then fed into the prompt for LLMs\\nto generate the final answer. With such rich and\\nfactual contexts, RAG mitigates the hallucination\\nof LLMs. However, complex reasoning tasks (e.g.,\\nthose requiring multi-step reasoning) can be diffi-\\ncult to translate into effective search queries, lead-\\ning to challenges in finding relevant documents\\nand making RAG less applicable. Traditionally,\\nRAG retrieves all relevant information at once.\\nYet, it overlooks the fact that it is difficult to pre-\\ndict what “facts\" or information is required in the\\nsubsequent reasoning and generation steps. The\\ntask prompt itself is hardly sufficient to provide\\nenough clues for this.\\nChain of Thoughts (CoT) prompting is designed\\nto enhance the performance of LLMs under tasks\\nthat require complex reasoning steps (Wei et al.,\\n2022), such as multi-step math word problems.\\nSpecifically, instead of tasking LLMs to generate\\nthe correct answer directly, CoT prompting in-\\ncentivizes LLMs to first output intermediate rea-\\nsoning steps, termed thoughts, that serve as a\\nscratch space for the task, before summarizing\\n3\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nAlgorithm 1 Retrieval augmented thoughts (RAT)\\nInput: Task Prompt 𝐼, Autoregressive Large Language Model 𝑝𝜃\\n1: 𝑇 = {𝑇1, 𝑇2, . . . , 𝑇𝑛} ← 𝑝𝜃(·|𝐼)\\n⊲ Generate zero-shot initial step-by-step thoughts 𝑇\\n2: 𝑇★ ← 𝑇1, 𝑖 ← 1\\n⊲ Draft answer 𝑇★ initialized with the first thought step 𝑇1\\n3: repeat\\n4:\\n𝑄𝑖 ← ToQuery(𝐼, 𝑇★)\\n⊲ Generate query 𝑄𝑖 based on current draft answer 𝑇★\\n5:\\n𝑅𝑖 ← RetrieveFromCorpus(𝑄𝑖)\\n⊲ Retrieve information 𝑅𝑖 from corpus or Internet\\n6:\\n𝑇★ ← 𝑝𝜃(·|𝐼, 𝑇★, 𝑅𝑖)\\n⊲ Revise draft answer 𝑇★ based on retrieved text 𝑅𝑖\\n7:\\n𝑇★ ← CONCAT(𝑇★, 𝑇𝑖+1)\\n⊲ Append the next thought step 𝑇𝑖+1\\n8:\\n𝑖 ← 𝑖 + 1\\n⊲ Begin the next revision round\\n9: until 𝑖 > 𝑛\\n⊲ Repeat until all the revised thoughts 𝑇★\\n1:𝑛 are obtained\\n10: return 𝑇★\\n⊲ Output 𝑇★ as the final generation\\nthe thoughts into a final answer. Such behavior\\nof LLMs can either be stimulated in zero-shot by\\nprompting terms that encourage CoT reasoning\\n(e.g., “let’s think step by step”) (Kojima et al.,\\n2022), or triggered by few-shot examples that\\nperform CoT in similar tasks. However, since no\\ndirect supervision is posed to the intermediate\\nthoughts, LLMs could make errors due to the lack\\nof relevant domain knowledge (Touvron et al.,\\n2023) or biased by hallucinations (Rawte et al.,\\n2023).\\n2.2. Our Approach\\nOur intuition to mitigate the issues of CoT prompt-\\ning and RAG mentioned above is to apply RAG\\nto revise every thought step generated by CoT\\nprompting. An overview can be found in Figure 1\\nand Algorithm 1. Specifically, given a task prompt\\nI, we first prompt LLM to generate step-by-step\\nthoughts in zero shot (“let’s think step-by-step”)\\n𝑇 := {𝑇𝑖}𝑛\\n𝑖=1, where 𝑇𝑖 represents the 𝑖th thought\\nstep. In long-horizon generation tasks, 𝑇 can ei-\\nther be the intermediate reasoning steps, e.g. the\\npseudo code with comments in code generation,\\narticle outline in creative writing, etc., or the draft\\nresponse itself, e.g. a list of sub-goals in embodied\\ntask planning as shown in Figure 1.\\nSince 𝑇 could be flawed (e.g., contains halluci-\\nnation), we proceed to use RAG to revise every\\ngenerated thought step before generating the fi-\\nnal response from these thoughts. Specifically, as-\\nsuming we have fixed the previous thought steps\\nand now are about to revise 𝑇1:𝑖, we begin by\\nconverting the text {I, 𝑇1, . . . , 𝑇𝑖} into a query 𝑄𝑖:\\n𝑄𝑖 = ToQuery(I, 𝑇1, . . . , 𝑇𝑖),\\nwhere ToQuery(·) can either be a text encoder\\nor an LLM that translates the task prompt I, the\\ncurrent and the past thought steps 𝑇1, . . . , 𝑇𝑖 into\\na query 𝑄𝑖 that can be processed by the retrieval\\nsystem. We adopt RAG to retrieve relevant docu-\\nments 𝑅𝑖 using 𝑄𝑖, which are then prepended to\\nthe prompt to generate a revised thought step 𝑇★\\n𝑖 .\\n𝑇★\\n1:𝑖 = 𝑝𝜃(·|I, 𝑇1, . . . , 𝑇𝑖, 𝑅𝑖).\\nFinally, depending on the actual task, the revised\\nthought steps 𝑇★\\n1:𝑛 can simply be used as the final\\nmodel response, e.g., embodied task planning.\\nFor tasks like code generation, or creative writing,\\nthe LLM will be further prompted to produce\\nthe complete response (code, passage) from each\\nrevised thought step in a step-by-step fashion.\\nNote that, when revising the 𝑖-th thought step\\n𝑇𝑖, instead of using the current step 𝑇𝑖 only, or\\nthe complete chain of thoughts 𝑇1, . . . , 𝑇𝑛 to pro-\\nduce the query for RAG, we ensure the query\\n𝑄𝑖 is produced from the current thought step 𝑇𝑖\\nand previous revised thought steps 𝑇★\\n1:𝑖−1, i.e., we\\nadopt a casual reasoning to revise the thoughts\\nusing RAG:\\n𝑄𝑖 = ToQuery(𝐼, 𝑇★\\n1:𝑖−1, 𝑇𝑖)\\n𝑇★\\n1:𝑖 = 𝑝𝜃(·|𝐼, 𝑇★\\n1:𝑖−1, 𝑇𝑖, 𝑅𝑖).\\nThis allows for the correction of errors in the\\noriginal thoughts 𝑇 by continually consulting dif-\\nferent reference texts and ensures that each step\\n4\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nof reasoning is informed by the most accurate and\\nrelevant information, significantly improving the\\nquality and reliability of the generated output.\\nOur hypothesis why our method can address\\nthe two problems mentioned at the beginning of\\nthis section is as follows. Firstly, the most straight-\\nforward way to know what information will be\\nused in complex reasoning is to “see” the reason-\\ning steps. Our approach leverages all the gen-\\nerated thoughts along with the task prompt to\\nprovide more clues for more effective retrieval.\\nSecondly, some information cannot be directly\\nretrieved, especially information related to the\\nfinal answer to a hard complex question. Instead,\\nretrieval of information relevant to intermediate\\nquestions, which are assumed to be easier, is more\\naccessible. Thanks to the compositional nature of\\nmany reasoning tasks, an iterative retrieval pro-\\ncess could also be more effective. Thirdly, correct-\\ning potential hallucinations needs to be targeted.\\nRevising a complete CoT with RAG could intro-\\nduce errors at otherwise already-correct steps.\\nRevising every step one by one could be more\\nreliable. The first two points address question (1)\\nand the last point addresses question (2). Quan-\\ntitative evidence can be found in our ablation\\nstudies in subsection 3.4.\\n3. Experiments\\nWe test our proposed method RAT on a diverse set\\nof benchmarks that highlight long-horizon gener-\\nation and reasoning. Existing methods tradition-\\nally struggle in those benchmarks; “hallucinated\"\\nsteps are obvious in LLMs’ outputs. Those steps ei-\\nther fail to stick to the original query or are plainly\\ninvalid. We kindly refer readers to subsection\\n3.3 (case analysis) for a more detailed discussion.\\nDue to space constraints, we do not introduce\\neach benchmark setting, nor do we discuss our\\nresults in each benchmark in full length. Rather,\\nthis section provides a comprehensive demonstra-\\ntion of our method’s performance and provides a\\nspotlight to provide preliminary empirical analy-\\nsis about why and when our method works and\\nwhen it fails.\\n3.1. Experimental Setups\\nWe adopt four groups of benchmarks.\\nCode Generation includess HumanEval (Chen\\net al., 2021), HumanEval+ (Liu et al., 2023b),\\nMBPP (Austin et al., 2021), and MBPP+ (Liu\\net al., 2023b). These benchmarks encompass a\\nwide range of programming problems, from sim-\\nple function implementations to more complex\\nalgorithmic challenges, providing a robust testbed\\nfor assessing generative capabilities.\\nMathematical Reasoning evaluation is con-\\nducted on GSM8K and GSM-HARD dataset, which\\ncomprises thousands of multi-step mathematical\\nproblems (Cobbe et al., 2021; Gao et al., 2022).\\nCreative Writing tasks are conducted to evalu-\\nate the versatility of RAT, including survey, sum-\\nmarization etc., highlighting different aspects of\\nopen-ended text generation.\\nEmbodied Planning tasks are evaluated on open-\\nended environments Minecraft. A set of 100 tasks\\nranging from simple objectives to challenging\\ndiamond objectives are evaluated through MC-\\nTextWorld (Lin et al., 2023).\\nEvaluation Metrics. For code generation, the\\nclassical pass rate pass@k is selected as the evalu-\\nation metrics (Chen et al., 2021; Liu et al., 2023b),\\n𝑘 denotes the sampling number. We compute ac-\\ncuracy to evaluate every question in mathemati-\\ncal reasoning tasks, aligning with the established\\nmetric for the GSM8K (Cobbe et al., 2021). For\\nembodied planning tasks, we compute the plan\\nexecution success rate in MC-TextWorld as exe-\\ncutability (Lin et al., 2023). We also conduct hu-\\nman elo rating evaluation to compute the trueskill\\nrating score (Herbrich et al., 2006) for embod-\\nied planning (as plausibility) and creative writing\\ntasks. These indicators are better the higher they\\nare.\\nBaselines. To establish a comprehensive and eq-\\nuitable comparison landscape, we incorporate\\na suite of baseline methods. Our baselines in-\\nclude the original language models, referred to\\nas DIRECT, and the Retrieval-Augmented Gen-\\neration (RAG) methodology with 𝑛 retrieved ex-\\namples, instantiated in both single-shot (1 shot)\\nand multi-shot (5 shots) configurations, as doc-\\n5\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nTable 1 | Code generation results on different benchmarks.∗All tests are evaluated under zero-shot (0-\\ndemonstration) settings. We also report the relative improvements between RAT and DIRECT methods.\\nHumanEval\\nHumanEval+\\nMBPP\\nMBPP+\\nAverage ↑\\nBase Models\\nMethod\\npass@1\\npass@5\\npass@1\\npass@5\\npass@1\\npass@5\\npass@1\\npass@5\\npass@1\\npass@5\\nDIRECT\\n33.78%\\n40.85%\\n30.85%\\n36.59%\\n39.27%\\n54.27%\\n41.22%\\n48.17%\\n36.28%\\n44.97%\\nCoT\\n27.86%\\n29.58%\\n25.12%\\n27.83%\\n31.99%\\n55.91%\\n42.19%\\n47.51%\\n31.79%\\n40.21%\\nRAG_1 shot\\n37.50%\\n47.65%\\n33.66%\\n41.83%\\n35.41%\\n51.63%\\n43.66%\\n50.09%\\n37.56%\\n47.80%\\nRAG_5 shot\\n38.90%\\n47.90%\\n35.37%\\n42.75%\\n34.06%\\n53.90%\\n43.35%\\n51.08%\\n37.92%\\n48.91%\\nCodeLlama-7b\\nRAT\\n39.57%\\n51.34%\\n36.22%\\n46.50%\\n40.86%\\n60.63%\\n39.14%\\n48.04%\\n38.95%\\n51.63%\\nRelative Improvement\\n17.14%\\n25.68%\\n17.41%\\n27.08%\\n4.05%\\n11.72%\\n-5.05%\\n-0.27%\\n7.35%\\n14.80%\\nDIRECT\\n50.49%\\n72.56%\\n48.09%\\n70.55%\\n60.84%\\n72.95%\\n54.92%\\n64.09%\\n53.59%\\n70.04%\\nCoT\\n47.31%\\n75.88%\\n41.72%\\n74.85%\\n55.19%\\n65.49%\\n47.69%\\n62.94%\\n47.98%\\n69.79%\\nRAG_1 shot\\n50.61%\\n76.22%\\n48.22%\\n70.55%\\n55.23%\\n70.54%\\n53.62%\\n68.09%\\n51.92%\\n71.35%\\nRAG_5 shot\\n45.49%\\n74.39%\\n42.58%\\n70.55%\\n54.39%\\n69.73%\\n55.98%\\n70.10%\\n49.61%\\n71.19%\\nGPT-3.5\\nRAT\\n59.27%\\n80.49%\\n56.31%\\n76.07%\\n59.31%\\n74.74%\\n59.10%\\n72.61%\\n58.50%\\n75.98%\\nRelative Improvement\\n17.39%\\n10.93%\\n17.09%\\n7.82%\\n-2.51%\\n2.45%\\n7.61%\\n13.29%\\n9.17%\\n8.48%\\nDIRECT\\n57.32%\\n78.66%\\n54.36%\\n76.69%\\n60.00%\\n76.07%\\n66.13%\\n78.53%\\n59.45%\\n77.49%\\nCoT\\n54.87%\\n72.56%\\n51.90%\\n66.25%\\n61.22%\\n74.23%\\n64.42%\\n79.75%\\n58.10%\\n73.20%\\nRAG_1 shot\\n61.10%\\n79.27%\\n58.04%\\n77.30%\\n58.53%\\n69.94%\\n65.77%\\n77.30%\\n60.86%\\n75.95%\\nRAG_5 shot\\n62.80%\\n82.93%\\n59.51%\\n79.75%\\n60.12%\\n74.23%\\n63.56%\\n78.53%\\n61.50%\\n78.86%\\nGPT-4\\nRAT\\n69.33%\\n88.40%\\n64.63%\\n82.21%\\n68.90%\\n79.85%\\n67.36%\\n82.14%\\n67.55%\\n83.15%\\nRelative Improvement\\n20.94%\\n12.38%\\n18.89%\\n7.20%\\n14.83%\\n4.97%\\n1.86%\\n4.60%\\n13.63%\\n7.31%\\nTable 2 | Evaluation results on mathematical reasoning, creative writing, and embodied planning tasks.\\nAmong them, mathematical reasoning and creative writing use gpt-3.5 as base models, while embodied\\nplanning uses gpt-4 as base models. Δ represents the relative improvements than DIRECT.\\nMethod\\nMath Reasoning Accuracy ∗ ↑\\nCreative Writing ↑\\nEmbodied Planning ↑\\nGSM8K\\nGSMHard\\nAverage (Δ)\\nWin Rate\\nTrueSkill Rating (Δ)\\nUncertainty\\nExecutablity\\nPlausibitlity (Δ)\\nUncertainty\\nDIRECT\\n65.85%\\n51.26%\\n58.56%\\n46.67%\\n24.39\\n1.17\\n19.33±2.08%\\n20.57\\n2.05\\nCoT\\n63.82%\\n44.72%\\n54.27(-7.32)%\\n41.67%\\n24.31(-0.0%)\\n1.09\\n49.33±3.05%\\n25.75(+25.2%)\\n2.33\\nRAG-1 shot\\n61.81%\\n51.26%\\n56.54(+4.17)%\\n38.71%\\n23.99(-1.6%)\\n1.11\\n31.00±5.29%\\n24.97(+21.4%)\\n2.11\\nRAG-5 shot\\n61.81%\\n56.78%\\n59.30(+4.88)%\\n31.67%\\n23.88(-2.1%)\\n1.22\\n33.00±3.61%\\n25.02(+21.6%)\\n2.11\\nRAT\\n71.36%\\n67.34%\\n69.35(+16.96)%\\n81.01%\\n29.07(+19.2%)\\n1.08\\n76.67±8.02%\\n29.37(+42.78%)\\n3.37\\numented by Lewis et al. (2020b). Additionally,\\nwe examine the zero-shot CoT (CoT) approach,\\nas conceptualized by Kojima et al. (2022), which\\nsimulates a step-by-step reasoning process to fa-\\ncilitate complex problem-solving tasks under zero\\ndemonstration. For different methods, the same\\nlanguage model is used as base models. To en-\\nsure a fair comparison, none of the methods used\\nexamples from the benchmark as demonstrations\\nfor in-context learning.\\nRAG Settings.\\nRAT leverages the capabili-\\nties of Retrieval-Augmented Generation meth-\\nods, which enhance the performance of lan-\\nguage models by integrating external knowl-\\nedge\\nsources.\\nSpecifically,\\nwe\\nemployed\\nthe codeparrot/github-jupyter dataset as\\nour primary search vector library for code gen-\\neration and mathematical reasoning tasks. For\\nembodied planning tasks in Minecraft, we utilized\\nthe Minecraft Wiki1 and DigMinecraft2 websites\\nas the information sources accessible to the LLMs.\\n1https://minecraft.wiki/\\n2https://www.digminecraft.com/\\nFor open-ended creative writing tasks, we use\\nGoogle to search the query on the Internet. We\\nutilized OpenAI’s text-embedding-ada-002\\nAPI service for all embedding calculations across\\ndifferent methods and base models.\\nAcknowledging the risk of benchmark contam-\\nination (an issue where the code library may con-\\ntain solutions to the exact problems being eval-\\nuated), we adopted a rigorous pre-processing\\nmethodology as described by Guo et al. (2024).\\nThe potential implications of benchmark contam-\\nination, along with the effectiveness of our pre-\\nprocessing strategy, are discussed in detail in Ap-\\npendix D.\\n3.2. Results\\nThe code generation results presented in Table 1\\nand results on other benchmarks presented in\\nTable 2 demonstrate the comprehensive evalu-\\nation of the RAT across multiple benchmarks.\\nRAT consistently outperforms the other methods\\nacross the majority of the benchmarks and met-\\n6\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nrics, showcasing its superior ability to generate\\nlong-horizon context. Notably, in the HumanEval\\nand HumanEval+ benchmarks of code genera-\\ntion, RAT achieves remarkable improvements in\\npass@1 and pass@5 rates, indicating a signifi-\\ncant enhancement in first-attempt accuracy and\\nwithin the top five attempts. For example, on the\\nHumanEval benchmark, RAT improves pass@1 by\\nup to 20.94% and pass@5 by up to 25.68% rela-\\ntive to the base models’ performances. This trend\\nis observed across different underlying base mod-\\nels, highlighting RAT’s effectiveness regardless of\\nthe initial model’s capabilities. For mathematical\\nreasoning tasks, RAT demonstrates a significant\\nrelative improvement, with an 8.37% increase in\\naccuracy on GSM8K and a remarkable 31.37%\\nincrease on GSMHard, culminating in an overall\\naverage improvement of 18.44% when deployed\\non the GPT-3.5 model. RAT significantly outper-\\nforms all other methods on open-ended embodied\\nplanning tasks in Minecraft, achieving the highest\\nscores with 76.67±8.02% for executability and\\n29.37 human rating score for plausibility, demon-\\nstrating its superior ability to generate feasible\\nand contextually appropriate plans in the com-\\nplex open-world environment. RAT’s superior per-\\nformance also keeps across a broad spectrum of\\ncreative writing tasks. Its ability to generate high-\\nquality content in diverse scenarios was demon-\\nstrated, highlighting its potential as a powerful\\ntool for enhancing the general creative writing\\ncapabilities of LLMs in open-ended scenarios.\\nThe tasks are extremely diverse, while RAT can\\nhave consistent improvements over all baselines.\\nThese results underline the advantages of RAT’s\\napproach, which leverages iterative refinement\\nof retrieval queries based on evolving reasoning\\nthoughts. This strategy not only enhances the\\nrelevance and quality of the information retrieved\\nbut also significantly improves the accuracy and\\nefficiency of the generated context.\\n3.3. Case Analysis\\nHere we take the embodied planning task and\\ncreative writing task to do case analysis.\\nIn a manner analogous to multi-document\\nquestion-answering tasks (Trivedi et al., 2022a),\\nthe task of long-horizon planning in Minecraft\\nis knowledge-dense, requiring consideration of\\nvarious items for the completion of each task.\\nHowever, open-world Minecraft knowledge on\\nthe internet is fragmented, making task comple-\\ntion often dependent on information from mul-\\ntiple sources. We observed that while language\\nmodels like ChatGPT can identify necessary items\\nthrough zero-shot CoT reasoning, inaccuracies\\nin procedural steps are common. For example,\\nChatGPT inaccurately identified the materials for\\na crafting table as 4 wood blocks (the right an-\\nswer is 4 planks), indicating lower executability\\nreliability in CoT plans. Classical RAG algorithms,\\nretrieving the knowledge with the question as a\\nquery and focusing on the final target item, inade-\\nquately retrieve intermediary items, offering min-\\nimal task improvement. Contrastingly, RAT im-\\nproves upon CoT’s initial answers by continuously\\nrefining thoughts with targeted retrieval, align-\\ning closely with task progression and relevant\\nitem knowledge. This methodology significantly\\nenhances planning effectiveness by ensuring a\\ncomprehensive understanding and retrieval of all\\nitems involved in a plan, highlighting the syn-\\nergy between structured reasoning and dynamic\\nknowledge retrieval in addressing long-horizon\\nplanning challenges in Minecraft.\\nIn addressing open-ended creative writing\\ntasks, assessments of LM’s generations typically\\nfocus on completeness and accuracy.\\nWhen\\ntasked with “summarizing the American Civil War\\naccording to a timeline”, LMs under DIRECT and\\nCoT prompts often produce significant halluci-\\nnations. For example, the statement “The Civil\\nWar officially began on April 12, 1860, when Con-\\nfederate troops attacked Fort Sumter in South\\nCarolina, a Union-held fort” contains incorrect\\ninformation, where the year 1860 is erroneously\\nmentioned instead of the correct year, 1861.\\nDirect queries to the internet for this task tend\\nto retrieve limited events, frequently overlook-\\ning the accurate start date of the war, April 12,\\n1861. Moreover, the RAG approach, which tends\\nto summarize content retrieved from searches,\\noften misses this event in its responses, whether\\nit’s RAG-1 or RAG-5. On the other hand, RAT\\nbases its search on a language model’s draft an-\\n7\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nTable 3 | Comparative Impact of Retrieval Strategies\\non RAT Performance.\\nMethod\\nHumanEval\\nHumanEval+\\npass@1(Δ) ↑\\npass@5(Δ) ↑\\npass@1(Δ) ↑\\npass@5(Δ) ↑\\nBaseline\\n50.6%\\n76.2%\\n48.2%\\n70.5%\\nCoT+RAG\\n53.9(+3.3)%\\n76.8(+0.6)%\\n51.3(+3.1)%\\n69.3(-1.2)%\\nRAT\\n59.2(+8.7)%\\n80.4(+7.9)%\\n56.3(+8.2)%\\n76.0(+5.5)%\\nswer, finding that hallucinations usually occur\\nin details, such as specific dates, which do not\\nhinder the search engine from identifying rele-\\nvant information like “American Civil War starting\\ndate”. RAT utilizes the content retrieved to iden-\\ntify and correct errors in the draft answer rather\\nthan merely summarizing the retrieved content.\\nTherefore, RAT can achieve a complete genera-\\ntion through reasoning and enhance the accuracy\\nand credibility of the answer by leveraging re-\\ntrieved knowledge. Experimental results validate\\nthe effectiveness of RAT.\\n3.4. Ablation Study\\nAblation on retrieval in RAT. In this ablation\\nstudy, we investigate the influence of various re-\\ntrieval strategies on the efficacy of RAT, focusing\\non the optimization of content retrieval for im-\\nproving generative outputs. The experimental\\nresults, detailed in Table 3, highlight the signif-\\nicant advancements achieved through the itera-\\ntive refinement of retrieval queries in RAT com-\\npared to baseline methods. The baseline denoted\\nas RAG-1, employs a direct approach by using\\nthe question itself as the retrieval query. In con-\\ntrast, CoT+RAG enhances this process by utiliz-\\ning the entirety of the reasoning thoughts output\\nby the language model as the query, aiming for\\na broader contextual understanding. However,\\nRAT introduces a more dynamic method by em-\\nploying continuously modified parts of reason-\\ning thoughts as queries, which allows for a more\\nfocused and relevant information retrieval pro-\\ncess. The comparative analysis shows that RAT\\nsurpasses both the baseline and the CoT+RAG\\nmethod in terms of pass@1 and pass@5 metrics\\nacross the HumanEval and HumanEval+ bench-\\nmarks. Specifically, RAT demonstrates an 8.7 per-\\ncentage point increase in pass@1 and a 7.9 per-\\ncentage point increase in pass@5 over the base-\\nline in the HumanEval benchmark, and similarly\\nTable 4 | Ablation Study on Causal vs. Non-Causal\\nReasoning in RAT.\\nMethod\\nHumanEval\\nHumanEval+\\npass@1(Δ) ↑\\npass@5(Δ) ↑\\npass@1(Δ) ↑\\npass@5(Δ) ↑\\nBaseline\\n47.3%\\n75.8%\\n41.7%\\n74.8%\\nNon-Causal\\n57.3(+10.0)%\\n78.0(+2.1)%\\n54.9(+13.2)%\\n74.8(+0.0)%\\nCausal\\n59.2(+11.9)%\\n80.4(+4.6)%\\n56.3(+14.6)%\\n76.0(+1.2)%\\nimpressive gains in the HumanEval+ benchmark.\\nThese improvements underscore the effectiveness\\nof RAT’s retrieval strategy, which by iteratively\\nrefining next queries based on evolving reason-\\ning thoughts and previous queries, ensures the\\nretrieval of highly pertinent information. This\\nprocess not only enhances the relevance of the\\ninformation retrieved but also significantly im-\\nproves the quality and accuracy of the final gen-\\nerated outputs. The results firmly establish the\\nsuperiority of RAT’s dynamic retrieval method\\nin leveraging contextual nuances to drive more\\nprecise and effective generative processes.\\nAblation on causal reasoning in RAT. In this\\nablation study, we systematically examine the\\nimpact of causal and non-causal reasoning ap-\\nproaches on the performance of the RAT system,\\nwith the Chain of Thought (CoT) serving as our\\nbaseline. Our findings, as summarized in Ta-\\nble 4, reveal significant enhancements in gen-\\neration capabilities when incorporating causal\\nreasoning techniques. Specifically, the causal ap-\\nproach, which iteratively performs reasoning and\\nretrieval, leads to notable improvements in both\\npass@1 and pass@5 metrics across HumanEval\\nand HumanEval+ benchmarks. For instance, the\\ncausal method outperforms the baseline (CoT)\\nby 11.9 percentage points in pass@1 and by 4.6\\npercentage points in pass@5 on the HumanEval\\ndataset. This approach contrasts with the non-\\ncausal method, which, although also surpass-\\ning the baseline, leverages the initial reasoning\\nthought to directly retrieve all necessary steps and\\ngenerate the final answer. The causal method’s\\nsuperior performance underscores the value of\\nsequential reasoning and information retrieval in\\nenhancing the accuracy and reliability of gener-\\nated outputs. This iterative process likely aids in\\nrefining the search and reasoning steps based on\\ncontinuously updated context, allowing for more\\nprecise and relevant information retrieval, which\\nin turn supports more accurate final answers.\\n8\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nThese results firmly establish the efficacy of causal\\nreasoning in long-horizon problem-solving tasks.\\n3.5. Robustness of RAT\\nRAT was rigorously validated across a diverse\\nset of tasks, including code generation, mathe-\\nmatical reasoning, creative writing, and embod-\\nied planning. This variety of tasks underscores\\nthe generalization capability of RAT, demonstrat-\\ning its robust performance across highly diverse\\nchallenges. Furthermore, all our experimental\\nsettings were conducted in a zero-shot manner;\\nwe did not design task-specific prompts for RAT,\\nbut rather used the simplest possible prompts\\n(which can be found in Appendix B) to articulate\\nquestions or instructions for all methods. This\\napproach ensures RAT’s generalization ability in\\nopen-ended scenarios.\\nThe diversity of our evaluation was further en-\\nhanced by testing RAT across various language\\nmodels of differing capacities.\\nThis included\\nCodeLlama-7b (Rozière et al., 2023), ChatGPT\\n(gpt-3.5-turbo) (Ouyang et al., 2022), and the\\nmore advanced GPT-4 (gpt-4) model (OpenAI,\\n2023). Remarkably, RAT maintained its general-\\nization capability across different scales of lan-\\nguage models, showing improvements in bench-\\nmarks such as the HumanEval for code generation\\ntasks. Notably, the largest improvement was ob-\\nserved with GPT-4, attributed to its superior abil-\\nity for in-context learning from retrieved text. On\\nMBPP+, CodeLlama-7b based RAT has demon-\\nstrated performance degradation. This decline\\ncould be due to the limited in-context learning\\nability of smaller language models.\\nFor mathematical reasoning tasks, RAT demon-\\nstrated a significant relative improvement, with\\nan overall average improvement of 18.44% when\\napplied to the GPT-3.5 model. This trend of im-\\nprovement persisted with GPT-4, which achieved\\na remarkable 10.26% relative improvement from\\nDIRECT to RAT. These findings highlight RAT’s\\nrobustness and its effective enhancement of lan-\\nguage models’ performance across a spectrum of\\ncomputational and creative tasks.\\n4. Related Works\\nRetrieval-augmented Generation (RAG). Re-\\ncently, RAG has gained popularity for boosting\\nthe performance of LLMs by guiding their genera-\\ntion process using the retrieved knowledge (Zhao\\net al., 2023). Without updating model parame-\\nters that may be expensive (Lewis et al., 2020a)\\nor unstable (Ke et al., 2022a,b), RAG is a cost-\\neffective way for LLMs to interact with the exter-\\nnal world (Gu et al., 2018; Lewis et al., 2020a).\\nRAG is widely applied to downstream tasks, such\\nas code generation (Lu et al., 2022; Nashid et al.,\\n2023; Zhou et al., 2022b), question answer-\\ning (Baek et al., 2023; Siriwardhana et al., 2023),\\nand creative writing (Asai et al., 2023; Wen et al.,\\n2023).\\nReasoning-enhanced RAG. Some recent works\\nalso leverage reasoning to enhance the perfor-\\nmance of RAG (Li et al., 2023b). For example,\\nIRCoT (Trivedi et al., 2022b) exploits CoT to gen-\\nerate better queries for retrieval, IRGR (Ribeiro\\net al., 2022) performs iteratively retrieval to\\nsearch for suitable premises for multi-hop QA,\\nGEEK (Liu et al., 2023a) can choose to query ex-\\nternal knowledge or perform a single logical rea-\\nsoning step in long-horizon generation tasks, and\\nITRG (Feng et al., 2023a) performs retrieval based\\non the last-step generation. However, these pre-\\nvious RAG methods simply adopt a single query\\nto retrieve the knowledge for question-answering\\ntasks (Feng et al., 2023b; Gao et al., 2023), while\\nour proposed RAT performs retrieval using reason-\\ning and draft answers in an autoregressive way,\\nwhich significantly improves the performance of\\nRAG in various tasks as demonstrated in Figure 2.\\nLanguage Model for Reasoning.\\nThe ad-\\nvancement of reasoning in language models\\nhas seen notable methodologies emerge since\\nCoT was proposed by Wei et al. (2022), which\\nshowcased LMs’ ability to generate self-derived\\nproblem-solving strategies.\\nThis foundational\\nwork spurred further innovations such as the least-\\nto-most prompting (Zhou et al., 2022a), zero-shot\\nCoT (Kojima et al., 2022), self-consistency (Wang\\net al., 2022), zero-shot CoT without prompt-\\ning (Wang and Zhou, 2024). Moving beyond\\nbasic prompting, Creswell et al. (2022) intro-\\n9\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nduced the Selection-Inference framework, while\\nZelikman et al. (2022) developed STaR to refine\\nreasoning through model finetuning. Creswell\\nand Shanahan (2022) proposed a faithful reason-\\ning model, segmenting reasoning into dedicated\\nsteps, similar to Scratchpad’s approach by Nye\\net al. (2021) for enhancing multi-step compu-\\ntation. Tree-of-Thought (Yao et al., 2023) and\\nGraph-of-Thought (Besta et al., 2023) also ex-\\npand the reasoning paths into a complex struc-\\nture instead of linear CoT. These methods usually\\naim to improve the reasoning ability of LLM by\\ndesigning prompts or providing feedback from\\nthe environment to assist in better planning and\\ndecision-making (Li et al., 2023a; Shinn et al.,\\n2023; Wang et al., 2023c; Yao et al., 2022; Zhang\\net al., 2023). However, RAT takes a different\\napproach by using RAG to access external knowl-\\nedge that can help LLM with its reasoning pro-\\ncess.\\n5. Conclusion\\nWe\\nhave\\npresented\\nRetrieval\\nAugmented\\nThoughts (RAT), a simple yet effective prompting\\nstrategy that synergies chain of thought (CoT)\\nprompting and retrieval augmented generation\\n(RAG) to address the challenging long-horizon\\nreasoning and generation tasks. Our key ideas\\ninvolve revising the zero-shot chain of thoughts\\nproduced by LLMs through RAG with the\\nthoughts as queries, and causally revising the\\nthoughts & generating the response progressively.\\nRAT, a zero-shot prompting approach, has\\ndemonstrated significant advantages over vanilla\\nCoT prompting, RAG, and other baselines on\\nchallenging\\ncode\\ngeneration,\\nmathematics\\nreasoning, embodied task planning, and creative\\nwriting tasks.\\nAcknowledgments\\nWe thank a grant from CCF-Tencent Rhino-Bird\\nOpen Research Fund. One author is funded in\\npart by NSF grants #IIS-1943641, #IIS-1956441,\\n#CCF-1837129, an SRA from Meta and a re-\\nsearch gift from Amazon Alexa AI, and a gift from\\nRelationalAI.\\nLimitations\\nIn this seciton, we discuss three limitations of our\\nRAT as follows.\\nOne limitation of this work is that the perfor-\\nmance of RAT relies on the chain-of-thought rea-\\nsoning and in-context learning (or RAG) capa-\\nbility of the base LLM. Since this work does not\\ninvolve any model training, the capability of base\\nLLM will not change when applying RAT. De-\\nspite RAT achieves significant improvement on\\npowerful LLMs such as GPT-3.5 and GPT-4, the\\neffect on smaller and weaker LLMs such as GPT-2\\nis questionable. On top of that, it is interesting\\nto further explore how to improve RAT via fine-\\ntuning weaker LLMs (Ke et al., 2023; Lin et al.,\\n2024).\\nAnother limitation of this work is that the per-\\nformance of RAT also relies on the quality of the\\nretrieved knowledge. When we have an inferior\\nexternal knowledge base which is irrelevant to\\nthe user query, the retrieved knowledge may be\\nunhelpful for LLMs to generate useful informa-\\ntion. Also, even if we select a relatively large\\nknowledge base that entails the relevant informa-\\ntion, it will be expensive to maintain and retrieve\\nfrom such a huge knowledge base and also hurts\\nthe retrieval precision. An interesting and crucial\\ndirection is to study how to build and evaluate\\nthe quality of a knowledge base used for efficient\\nand effective retrieval.\\nIt is noteworthy that the above two limitations\\nalso apply to the traditional studies on retrieval-\\naugmented generation (RAG). The last limitation\\nof RAT is that we follow CoT to solve the problems\\nin a explicit step-by-step fashion. Sometimes step-\\nby-step thinking may be redundant for straight-\\nforward questions, while some questions require\\nmore complex reasoning structures (e.g., tree-of-\\nthoughts (Yao et al., 2023)). It is also interesting\\nto explore the better reasoning methods for LLMs\\nin our future work.\\nEthics Statement\\nAll datasets and models are publicly accessible\\nexcept for OpenAI’s GPT series and the text em-\\nbedding APIs. We have not identified any signif-\\n10\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nicant ethical considerations associated with this\\nwork. We believe our newly proposed RAT can\\nimprove the generation of LLMs in various fields\\nand reduce LLMs’ hallucinations.\\nReferences\\nA. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi.\\nSelf-rag: Learning to retrieve, generate, and\\ncritique through self-reflection. arXiv preprint\\narXiv:2310.11511, 2023.\\nJ. Austin,\\nA. Odena,\\nM. Nye,\\nM. Bosma,\\nH. Michalewski, D. Dohan, E. Jiang, C. Cai,\\nM. Terry, Q. Le, et al.\\nProgram synthesis\\nwith large language models.\\narXiv preprint\\narXiv:2108.07732, 2021.\\nJ. Baek, A. F. Aji, and A. Saffari. Knowledge-\\naugmented language model prompting for\\nzero-shot knowledge graph question answering.\\narXiv preprint arXiv:2306.04136, 2023.\\nB. Baker, I. Akkaya, P. Zhokhov, J. Huizinga,\\nJ. Tang, A. Ecoffet, B. Houghton, R. Sampedro,\\nand J. Clune. Video pretraining (vpt): Learn-\\ning to act by watching unlabeled online videos.\\narXiv preprint arXiv:2206.11795, 2022.\\nM. Besta, N. Blach, A. Kubicek, R. Gerstenberger,\\nL. Gianinazzi, J. Gajda, T. Lehmann, M. Pod-\\nstawski, H. Niewiadomski, P. Nyczyk, et al.\\nGraph of thoughts: Solving elaborate problems\\nwith large language models.\\narXiv preprint\\narXiv:2308.09687, 2023.\\nT. Brown, B. Mann, N. Ryder, M. Subbiah, J. D.\\nKaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\\nG. Sastry, A. Askell, et al. Language models\\nare few-shot learners. Advances in neural in-\\nformation processing systems, 33:1877–1901,\\n2020.\\nS. Cai, Z. Wang, X. Ma, A. Liu, and Y. Liang. Open-\\nworld multi-task control through goal-aware\\nrepresentation learning and adaptive horizon\\nprediction. 2023 IEEE/CVF Conference on Com-\\nputer Vision and Pattern Recognition (CVPR),\\npages 13734–13744, 2023a.\\nS. Cai, B. Zhang, Z. Wang, X. Ma, A. Liu, and\\nY. Liang. Groot: Learning to follow instructions\\nby watching gameplay videos. arXiv preprint\\narXiv:2310.08235, 2023b.\\nM. Chen, J. Tworek, H. Jun, Q. Yuan, H. P.\\nd. O. Pinto, J. Kaplan, H. Edwards, Y. Burda,\\nN. Joseph, G. Brockman, et al.\\nEvaluating\\nlarge language models trained on code. arXiv\\npreprint arXiv:2107.03374, 2021.\\nK. Cobbe, V. Kosaraju, M. Bavarian, M. Chen,\\nH. Jun, L. Kaiser, M. Plappert, J. Tworek,\\nJ. Hilton, R. Nakano, C. Hesse, and J. Schulman.\\nTraining verifiers to solve math word problems.\\narXiv preprint arXiv:2110.14168, 2021.\\nA. Creswell and M. Shanahan. Faithful reasoning\\nusing large language models. arXiv preprint\\narXiv:2208.14271, 2022.\\nA. Creswell, M. Shanahan, and I. Higgins.\\nSelection-inference: Exploiting large language\\nmodels for interpretable logical reasoning.\\narXiv preprint arXiv:2205.09712, 2022.\\nS. Dhuliawala, M. Komeili, J. Xu, R. Raileanu,\\nX. Li, A. Celikyilmaz, and J. Weston. Chain-\\nof-verification reduces hallucination in large\\nlanguage models.\\narXiv preprint arXiv:\\n2309.11495, 2023.\\nZ. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin.\\nRetrieval-generation synergy augmented large\\nlanguage models.\\nArXiv, abs/2310.05149,\\n2023a.\\nZ. Feng, X. Feng, D. Zhao, M. Yang, and\\nB. Qin.\\nRetrieval-generation synergy aug-\\nmented large language models. arXiv preprint\\narXiv:2310.05149, 2023b.\\nL. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu,\\nY. Yang, J. Callan, and G. Neubig.\\nPal:\\nProgram-aided language models. arXiv preprint\\narXiv:2211.10435, 2022.\\nY. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai,\\nJ. Sun, and H. Wang. Retrieval-augmented gen-\\neration for large language models: A survey.\\narXiv preprint arXiv:2312.10997, 2023.\\nJ. Gu, Y. Wang, K. Cho, and V. O. Li. Search\\nengine guided neural machine translation. In\\nProceedings of the AAAI Conference on Artificial\\nIntelligence, 2018.\\n11\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nD. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong,\\nW. Zhang, G. Chen, X. Bi, Y. Wu, Y. K. Li, F. Luo,\\nY. Xiong, and W. Liang. Deepseek-coder: When\\nthe large language model meets programming\\n– the rise of code intelligence. arXiv preprint\\narXiv:2401.14196, 2024.\\nR. Herbrich, T. Minka, and T. Graepel. Trueskill™:\\na bayesian skill rating system. Advances in neu-\\nral information processing systems, 19, 2006.\\nK. J. Holyoak and R. G. Morrison. The Oxford\\nhandbook of thinking and reasoning. Oxford\\nUniversity Press, 2012.\\nW. Huang, P. Abbeel, D. Pathak, and I. Mordatch.\\nLanguage models as zero-shot planners: Ex-\\ntracting actionable knowledge for embodied\\nagents. ICML, 2022.\\nZ. Ke, H. Lin, Y. Shao, H. Xu, L. Shu, and B. Liu.\\nContinual training of language models for few-\\nshot learning. arXiv preprint arXiv:2210.05549,\\n2022a.\\nZ. Ke, Y. Shao, H. Lin, H. Xu, L. Shu, and B. Liu.\\nAdapting a language model while preserving\\nits general knowledge. In Proceedings of the\\n2022 Conference on Empirical Methods in Natu-\\nral Language Processing, pages 10177–10188,\\n2022b.\\nZ. Ke, Y. Shao, H. Lin, T. Konishi, G. Kim, and\\nB. Liu. Continual pre-training of language mod-\\nels. In The Eleventh International Conference on\\nLearning Representations, 2023.\\nT. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwa-\\nsawa. Large language models are zero-shot\\nreasoners. Advances in neural information pro-\\ncessing systems, 35:22199–22213, 2022.\\nP. Lewis,\\nE. Perez,\\nA. Piktus,\\nF. Petroni,\\nV. Karpukhin, N. Goyal, H. Küttler, M. Lewis,\\nW.-t. Yih, T. Rocktäschel, et al.\\nRetrieval-\\naugmented generation for knowledge-intensive\\nnlp tasks. Advances in Neural Information Pro-\\ncessing Systems, 33:9459–9474, 2020a.\\nP. Lewis,\\nE. Perez,\\nA. Piktus,\\nF. Petroni,\\nV. Karpukhin, N. Goyal, H. Küttler, M. Lewis,\\nW.-t. Yih, T. Rocktäschel, et al.\\nRetrieval-\\naugmented generation for knowledge-intensive\\nnlp tasks. Advances in Neural Information Pro-\\ncessing Systems, 33:9459–9474, 2020b.\\nC. Li, J. Liang, A. Zeng, X. Chen, K. Hausman,\\nD. Sadigh, S. Levine, L. Fei-Fei, F. Xia, and\\nB. Ichter.\\nChain of code: Reasoning with\\na language model-augmented code emulator,\\n2023a.\\nX. Li, R. Zhao, Y. K. Chia, B. Ding, S. Joty, S. Poria,\\nand L. Bing. Chain-of-knowledge: Grounding\\nlarge language models via dynamic knowledge\\nadapting over heterogeneous sources. In The\\nTwelfth International Conference on Learning\\nRepresentations, 2023b.\\nS. Lifshitz, K. Paster, H. Chan, J. Ba, and\\nS. McIlraith. Steve-1: A generative model for\\ntext-to-behavior in minecraft. arXiv preprint\\narXiv:2306.00937, 2023.\\nH. Lin, Z. Wang, J. Ma, and Y. Liang.\\nMcu:\\nA task-centric framework for open-ended\\nagent evaluation in minecraft. arXiv preprint\\narXiv:2310.08367, 2023.\\nH. Lin, B. Huang, H. Ye, Q. Chen, Z. Wang, S. Li,\\nJ. Ma, X. Wan, J. Zou, and Y. Liang. Selecting\\nlarge language model to fine-tune via rectified\\nscaling law. arXiv preprint arXiv:2402.02314,\\n2024.\\nC. Liu, X. Li, L. Shang, X. Jiang, Q. Liu, E. Y. Lam,\\nand N. Wong. Gradually excavating external\\nknowledge for implicit complex question an-\\nswering. In Conference on Empirical Methods in\\nNatural Language Processing, 2023a.\\nJ. Liu, C. S. Xia, Y. Wang, and L. Zhang.\\nIs\\nyour code generated by chatGPT really correct?\\nrigorous evaluation of large language models\\nfor code generation. In Thirty-seventh Confer-\\nence on Neural Information Processing Systems,\\n2023b.\\nS. Lu, N. Duan, H. Han, D. Guo, S.-w. Hwang, and\\nA. Svyatkovskiy. Reacc: A retrieval-augmented\\ncode completion framework. In Proceedings\\nof the 60th Annual Meeting of the Association\\nfor Computational Linguistics (Volume 1: Long\\nPapers), pages 6227–6240, 2022.\\n12\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nN. Nashid, M. Sintaha, and A. Mesbah. Retrieval-\\nbased prompt selection for code-related few-\\nshot learning. In Proceedings of the 45th In-\\nternational Conference on Software Engineering\\n(ICSE’23), 2023.\\nM.\\nNye,\\nA.\\nJ.\\nAndreassen,\\nG.\\nGur-Ari,\\nH. Michalewski, J. Austin, D. Bieber, D. Dohan,\\nA. Lewkowycz, M. Bosma, D. Luan, et al.\\nShow your work: Scratchpads for intermediate\\ncomputation with language models.\\narXiv\\npreprint arXiv:2112.00114, 2021.\\nOpenAI. Gpt-4 technical report, 2023.\\nL. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L.\\nWainwright, P. Mishkin, C. Zhang, S. Agarwal,\\nK. Slama, A. Ray, et al. Training language mod-\\nels to follow instructions with human feedback.\\narXiv preprint arXiv:2203.02155, 2022.\\nV. Rawte, A. Sheth, and A. Das. A survey of hal-\\nlucination in large foundation models. arXiv\\npreprint arXiv:2309.05922, 2023.\\nN. Reimers and I. Gurevych. Sentence-bert: Sen-\\ntence embeddings using siamese bert-networks.\\narXiv preprint arXiv:1908.10084, 2019.\\nD. Ribeiro, S. Wang, X. Ma, R. Dong, X. Wei,\\nH. Zhu, X. Chen, Z. Huang, P. Xu, A. Arnold,\\net al. Entailment tree explanations via iterative\\nretrieval-generation reasoner. arXiv preprint\\narXiv:2205.09224, 2022.\\nB. Rozière, J. Gehring, F. Gloeckle, S. Sootla,\\nI. Gat, X. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin,\\nA. Kozhevnikov, I. Evtimov, J. Bitton, M. P.\\nBhatt, C. C. Ferrer, A. Grattafiori, W. Xiong,\\nA. D’efossez, J. Copet, F. Azhar, H. Touvron,\\nL. Martin, N. Usunier, T. Scialom, and G. Syn-\\nnaeve. Code llama: Open foundation models\\nfor code. ArXiv, abs/2308.12950, 2023.\\nN. Shinn, B. Labash, and A. Gopinath.\\nRe-\\nflexion: an autonomous agent with dynamic\\nmemory and self-reflection.\\narXiv preprint\\narXiv:2303.11366, 2023.\\nS. Siriwardhana, R. Weerasekera, E. Wen, T. Kalu-\\narachchi, R. Rana, and S. Nanayakkara. Im-\\nproving the domain adaptation of retrieval aug-\\nmented generation (rag) models for open do-\\nmain question answering. Transactions of the\\nAssociation for Computational Linguistics, 11:\\n1–17, 2023.\\nG. P. Team.\\nPalm:\\nScaling language mod-\\neling with pathways.\\narXiv preprint arXiv:\\n2204.02311, 2022.\\nH. Touvron, L. Martin, K. Stone, P. Albert,\\nA. Almahairi, Y. Babaei, N. Bashlykov, S. Ba-\\ntra, P. Bhargava, S. Bhosale, et al. Llama 2:\\nOpen foundation and fine-tuned chat models.\\narXiv preprint arXiv:2307.09288, 2023.\\nH. Trivedi, N. Balasubramanian, T. Khot, and\\nA. Sabharwal. Interleaving retrieval with chain-\\nof-thought reasoning for knowledge-intensive\\nmulti-step questions. ArXiv, abs/2212.10509,\\n2022a.\\nH. Trivedi, N. Balasubramanian, T. Khot, and\\nA. Sabharwal.\\nInterleaving retrieval with\\nchain-of-thought reasoning for knowledge-\\nintensive multi-step questions. arXiv preprint\\narXiv:2212.10509, 2022b.\\nX. Wang and D. Zhou.\\nChain-of-thought rea-\\nsoning without prompting.\\narXiv preprint\\narXiv:2402.10200, 2024.\\nX. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi,\\nS. Narang, A. Chowdhery, and D. Zhou. Self-\\nconsistency improves chain of thought rea-\\nsoning in language models.\\narXiv preprint\\narXiv:2203.11171, 2022.\\nX. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H.\\nChi, S. Narang, A. Chowdhery, and D. Zhou.\\nSelf-consistency improves chain of thought rea-\\nsoning in language models. In The Eleventh\\nInternational Conference on Learning Represen-\\ntations, ICLR 2023, 2023a.\\nZ. Wang, S. Cai, A. Liu, Y. Jin, J. Hou, B. Zhang,\\nH. Lin, Z. He, Z. Zheng, Y. Yang, X. Ma, and\\nY. Liang.\\nJarvis-1: Open-world multi-task\\nagents with memory-augmented multimodal\\nlanguage models.\\nArXiv, abs/2311.05997,\\n2023b.\\nZ. Wang, S. Cai, A. Liu, X. Ma, and Y. Liang. De-\\nscribe, explain, plan and select: Interactive\\nplanning with large language models enables\\n13\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nopen-world multi-task agents. arXiv preprint\\narXiv:2302.01560, 2023c.\\nJ. Wei, X. Wang, D. Schuurmans, M. Bosma,\\nE. Chi, Q. Le, and D. Zhou. Chain of thought\\nprompting elicits reasoning in large language\\nmodels. 36th Conference on Neural Information\\nProcessing Systems (NeurIPS 2022), 2022.\\nZ. Wen, Z. Tian, W. Wu, Y. Yang, Y. Shi, Z. Huang,\\nand D. Li. Grove: a retrieval-augmented com-\\nplex story generation framework with a forest\\nof evidence. arXiv preprint arXiv:2310.05388,\\n2023.\\nS. Yao, J. Zhao, D. Yu, N. Du, I. Shafran,\\nK. Narasimhan, and Y. Cao. React: Synergiz-\\ning reasoning and acting in language models.\\narXiv preprint arXiv:2210.03629, 2022.\\nS. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths,\\nY. Cao, and K. Narasimhan. Tree of thoughts:\\nDeliberate problem solving with large language\\nmodels, 2023.\\nH. Yuan, C. Zhang, H. Wang, F. Xie, P. Cai,\\nH. Dong,\\nand Z. Lu.\\nPlan4mc:\\nSkill\\nreinforcement learning and planning for\\nopen-world minecraft tasks.\\narXiv preprint\\narXiv:2303.16563, 2023.\\nH. Yuan, Z. Mu, F. Xie, and Z. Lu. Pre-training\\ngoal-based models for sample-efficient rein-\\nforcement learning. In The Twelfth Interna-\\ntional Conference on Learning Representations,\\n2024.\\nE. Zelikman, Y. Wu, J. Mu, and N. Goodman. Star:\\nBootstrapping reasoning with reasoning. Ad-\\nvances in Neural Information Processing Systems,\\n35:15476–15488, 2022.\\nC. Zhang, K. Yang, S. Hu, Z. Wang, G. Li, Y. Sun,\\nC. Zhang, Z. Zhang, A. Liu, S.-C. Zhu, et al.\\nProagent: Building proactive cooperative ai\\nwith large language models.\\narXiv preprint\\narXiv:2308.11339, 2023.\\nR. Zhao, H. Chen, W. Wang, F. Jiao, X. L. Do,\\nC. Qin, B. Ding, X. Guo, M. Li, X. Li, and\\nS. R. Joty. Retrieving multimodal information\\nfor augmented generation: A survey. ArXiv,\\nabs/2303.10868, 2023.\\nD. Zhou, N. Schärli, L. Hou, J. Wei, N. Scales,\\nX. Wang, D. Schuurmans, C. Cui, O. Bousquet,\\nQ. Le, et al. Least-to-most prompting enables\\ncomplex reasoning in large language models.\\narXiv preprint arXiv:2205.10625, 2022a.\\nD. Zhou, N. Schärli, L. Hou, J. Wei, N. Scales,\\nX. Wang, D. Schuurmans, C. Cui, O. Bousquet,\\nQ. V. Le, and E. H. Chi. Least-to-most prompting\\nenables complex reasoning in large language\\nmodels. In The Eleventh International Confer-\\nence on Learning Representations, ICLR 2023,\\n2023.\\nS. Zhou, U. Alon, F. F. Xu, Z. Jiang, and G. Neubig.\\nDocprompting: Generating code by retrieving\\nthe docs. In The Eleventh International Confer-\\nence on Learning Representations, 2022b.\\n14\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nA. Task Details\\nA.1. Code Generation\\nBenchmarks.\\nWe select HumanEval (Chen et al., 2021), HumanEval+ (Liu et al., 2023b),\\nMBPP (Austin et al., 2021), and MBPP+ (Liu et al., 2023b) as the code generation evaluation\\nbenchmark. These benchmarks are commonly used to test the performance of code generation models,\\nwhich are briefly introduced below:\\n• HumanEval consists of 164 Python programming problems, each with a function signature,\\ndocstring, body, and multiple unit tests (Chen et al., 2021).\\n• HumanEval+ includes the same programming problems as HumanEval, but with an additional\\n80 times more unit tests for each of the 164 problems (Liu et al., 2023b).\\n• MBPP is a collection of approximately 1,000 Python programming problems that are intended\\nto be solvable by beginner programmers. Each problem includes an English task description, a\\ncode solution, and three automated test cases. We assess the sample test set from index 11 to\\n175 (Austin et al., 2021).\\n• MBPP+ consists of 399 tasks (Liu et al., 2023b), which are a subset of the original MBPP dataset.\\nAdditionally, MBPP+ includes extra unit tests for each of the 399 problems (35 times more than\\nthe original MBPP). We utilized the first 164 questions as our test set.\\nThese benchmarks encompass a wide range of programming problems, from simple function imple-\\nmentations to more complex algorithmic challenges, providing a robust testbed for assessing the\\ngenerative capabilities of various models.\\nMetrics. We adopt the pass@k metric for evaluating the efficacy of various code generation algorithms,\\nfollowing the methodology proposed by Chen et al. (2021) and extended by Liu et al. (2023b). This\\nmetric quantifies the rate at which generated code snippets successfully execute and pass all test cases,\\nwhere 𝑘 represents the number of attempts or samples generated by the model for each problem.\\nThis approach allows us to rigorously assess the precision and reliability of code generation models in\\nproducing functionally correct code across a diverse set of programming challenges.\\nBaselines. To establish a comprehensive and equitable comparison landscape, we incorporate a suite\\nof baseline methods and diverse code generation models. Our baselines include the original code\\ngeneration language models, referred to as DIRECT, and the Retrieval-Augmented Generation (RAG)\\nmethodology with 𝑛 retrieved examples, instantiated in both single-shot (1 shot) and multi-shot (5\\nshots) configurations, as documented by Lewis et al. (2020b). Additionally, we examine the zero-shot\\nCoT (CoT) approach, as conceptualized by Kojima et al. (2022), which simulates a step-by-step\\nreasoning process to facilitate complex problem-solving tasks under zero demonstration. To ensure\\na fair comparison, none of the methods used examples from the benchmark as demonstrations for\\nin-context learning.\\nThe diversity of our evaluation is further enriched by testing across various language mod-\\nels with differing capacities, including CodeLlama-7b (Rozière et al., 2023), along with Chat-\\nGPT(gpt-3.5-turbo) (Ouyang et al., 2022), and the more advanced GPT-4(gpt-4) model (Ope-\\nnAI, 2023). Recognizing the potential format discrepancies in code outputs, especially considering\\nthat models like gpt-3.5-turbo and gpt-4 may produce code in markdown format which is not\\nimmediately executable, we implement post-processing steps to convert the original language model\\noutputs into a form that can be executed within a sandbox environment. This normalization ensures\\nthat all models are evaluated under uniform execution conditions, thereby facilitating a fair and\\ndirect comparison of their code generation capabilities. Through this methodological framework,\\n15\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nwe aim to provide a detailed and nuanced understanding of the performance landscape across a\\nspectrum of LLM-driven code generation approaches.\\nRAG Settings. RAT leverages the capabilities of Retrieval-Augmented Generation methods, which\\nenhance the performance of language models by integrating external knowledge sources. Specifically,\\nwe employed the codeparrot/github-jupyter dataset as our primary search vector library. This\\ndataset is a comprehensive compilation of 452k markdown and code pairs, meticulously extracted\\nfrom Jupyter notebooks hosted on GitHub BigQuery, representing a rich repository of programming\\nknowledge and examples. We utilized OpenAI’s text-embedding-ada-002 API service for all\\nembedding calculations across different methods and base models.\\nA.2. Mathematical Reasoning\\nBenchmarks. Our evaluation framework for assessing mathematical reasoning capabilities leverages\\ntwo primary benchmarks: the GSM8K dataset, which comprises over 8,000 multi-step mathematical\\nproblems (Cobbe et al., 2021), and the GSM-HARD dataset, an adaptation of GSM8K where numbers\\nin the questions are replaced with larger values to increase problem complexity (Gao et al., 2022).\\nThis study employs the PAL methodology to scrutinize the mathematical reasoning results, involving\\nthe utilization of Large Language Models (LLMs) to parse natural language problems, generate inter-\\nmediary programmatic solutions, and subsequently execute these solutions via a Python interpreter.\\nThe test set for each benchmark consists of samples ranging from index 1 to 200. Uniquely, our\\napproach does not use any examples for in-context learning, differing from the original PAL methods.\\nMetrics and Baselines. Accuracy serves as our principal metric for evaluation, aligning with the\\nestablished metric for the GSM8K benchmark. Each question undergoes three execution attempts,\\nwith the average score recorded as the final result. The baselines, including DIRECT, CoT, RAG\\n(1 shot), and RAG (5 shots), are consistent with those outlined in code generation, facilitating a\\ncomprehensive and comparative analysis across different code generation benchmarks. The RAG\\nsettings are consistent with the code generation tasks.\\nA.3. Embodied Planning\\nWe further conduct experiments on embodied planning benchmarks on open-ended environments\\nMinecraft (Lin et al., 2023).\\nBenchmarks. The complexity and vast item interconnectivity within the open-world Minecraft\\npresent an ideal testbed for evaluating the LLM’s capability to generate long-horizon plans (Wang\\net al., 2023b,c; Yuan et al., 2023). With thousands of items and intricate relationships between them,\\nobtaining a specific item in survival mode from scratch may involve dozens of intermediate items and\\ntheir quantitative relationships, such as crafting 1 crafting table from 4 planks. This setting rigorously\\ntests the planning abilities of LLMs instead of low-level control policies (Baker et al., 2022; Cai et al.,\\n2023a,b; Lifshitz et al., 2023; Yuan et al., 2024). Moreover, Wang et al. (2023b) have identified\\ninstances of hallucinations about Minecraft knowledge in OpenAI’s ChatGPT and a general scarcity of\\nMinecraft-related knowledge in open-source language models, making this task a suitable benchmark\\nfor assessing the RAG algorithm’s effectiveness.\\nThe planning prompts are aligned with those used in DEPS (Wang et al., 2023c), structured as\\nPython templates and evaluated using MC-TextWorld as detailed by Lin et al. (2023). A set of\\n100 tasks were randomly selected for the test set, ranging from simple objectives like obtaining a\\ncrafting table to more complex goals such as crafting an iron helmet and even challenging making an\\nenchanting table. The task instruction is formulated as:\\n16\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\n• Give you nothing in the inventory, generate a step-by-step plan for the task of obtaining a\\n{placeholder:acacia_boat} in Minecraft survival mode, and describe the object Minecraft item\\nand its number at every step. For every step, start with ’STEP’ as start.\\n• Give you nothing in the inventory, generate a step-by-step plan for the task of obtaining a {place-\\nholder:diamond_pickaxe} boat in Minecraft survival mode, and describe the object Minecraft\\nitem and its number at every step. For every step, start with ’STEP’ as start.\\nThere are over 100 tasks involving different Minecraft items.\\nRAG Settings. For the retrieval component of the RAG algorithm, we utilized the Minecraft Wiki3 and\\nDigMinecraft4 websites as the information sources accessible to the LLMs. Data from these websites\\nwas cleaned and formatted into markdown text, then segmented into trunks not exceeding 2000\\ntokens each, with embedding calculations performed using OpenAI’s text-embedding-ada-002\\nAPI service.\\nEvaluation Metrics. Based on the methodology of Huang et al. (2022), our evaluation of open-ended,\\nlong-horizon planning in Minecraft focuses on both executability and plausibility. Executability pri-\\nmarily examines whether a plan can be carried out, including the accuracy of each step’s preconditions\\nand effects. The executability is automatically calculated using MC-TextWorld (Lin et al., 2023).\\nHowever, executability only evaluates if an objective-level plan can be executed, without considering\\nthe specific details involved in executing individual objectives. For instance, crafting a wooden pickaxe\\nrequires placing a crafting table and arranging three planks and two sticks in a particular pattern,\\nwhich are important details for human execution but not assessed by MC-TextWorld. Therefore, we\\ncomplement our evaluation with human ratings to assess the plausibility of plans.\\nA.4. Creative Writing\\nTo further understand the potential of Retrieval-Augmented Generation (RAG) models in enhancing\\nthe creativity and relevance of generated content, we extend our investigation to open-ended text\\ngeneration tasks within the realm of creative writing.\\nBenchmarks. The versatility of RAT was tested through a series of creative writing tasks, each chosen\\nto highlight different aspects of open-ended text generation. These tasks include:\\n• Write\\na\\nsurvey\\npaper\\nto\\nsummarize\\nthe\\nplaceholder:Retrieval-augmented\\nGeneration methods for Large Language Models.\\n• Describe of placeholder:Jin-Yong’s life.\\n• Summarize the placeholder:American Civil War according to the timeline.\\nFor each task, three variants for placeholder were created to ensure a comprehensive evaluation\\nof the model’s performance across different contexts and requirements.\\nRAG Settings. Differing from previous tasks, creative writing is categorized as an open-ended\\ngeneration task, demanding a broader scope of information retrieval to aid content generation. To\\naccommodate this, Google was utilized as the search engine, with the top-k web pages converted into\\nmarkdown text to assist the LLM in generating outputs. This approach allowed LLM to leverage a\\nwide array of information sources.\\nBaselines and Evaluations. To benchmark RAT’s performance, we compared it against DIRECT,\\nRAG-1 shot, and RAG-5 shot methods, all based on the gpt-3.5-turbo model. The evaluation\\n3https://minecraft.wiki/\\n4https://www.digminecraft.com/\\n17\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nwas conducted by human experts, employing the TrueSkill rating system (Herbrich et al., 2006) to\\ncalculate scores for each method. This evaluation framework enabled a comprehensive assessment of\\neach model’s creative output quality, accuracy, relevance, and innovativeness.\\nB. Prompt Details\\nOur prompts consist of three parts: prompt for generating initial answer, prompt for generating search\\nquery, and prompt for revising answers according to retrieved context.\\nPrompt B.1: Prompt for generating initial answers in creative writing tasks\\n{user}\\n##Question:\\n{question}\\n##Instruction:\\nTry to answer this question/instruction with step-by-step thoughts and make the answer more structural.\\nUse /n/n to split the answer into several paragraphs.\\nJust respond to the instruction directly. DO NOT add additional explanations or introducement in the answer unless you\\nare asked to.\\n{assistant}\\n...\\nThe process of query generation is omitted in code generation tasks. Instead, we use the generated\\ncode draft as a query and compute the embedding of it based on OpenAI Embedding services. For\\nembodied planning and creative writing tasks, we will generate an additional query.\\nPrompt B.2: Prompt for generating open-search query in creative writing tasks\\n##Question:\\n{question}\\n##Content:\\n{answer}\\n##Instruction:\\nI want to verify the content correctness of the given question, especially the last sentences.\\nPlease summarize the content with the corresponding question.\\nThis summarization will be used as a query to search with Bing search engine.\\nThe query should be short but need to be specific to promise Bing can find related knowledge or pages.\\nYou can also use search syntax to make the query short and clear enough for the search engine to find relevant language\\ndata.\\nTry to make the query as relevant as possible to the last few sentences in the content.\\n**IMPORTANT**\\nJust output the query directly. DO NOT add additional explanations or introducement in the answer unless you are\\nasked to.\\n{assistant}\\n...\\n18\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nPrompt B.3: Prompt for revising answer according to retrieved materials in creative writing tasks\\n{user}\\n##Existing Text in Wiki Web:\\n{content}\\n##Question:\\n{question}\\n##Answer:\\n{answer}\\n##Instruction:\\nI want to revise the answer according to retrieved related text of the question in WIKI pages.\\nYou need to check whether the answer is correct.\\nIf you find some errors in the answer, revise the answer to make it better.\\nIf you find some necessary details are ignored, add it to make the answer more plausible according to the related text.\\nIf you find the answer is right and do not need to add more details, just output the original answer directly.\\n**IMPORTANT**\\nTry to keep the structure (multiple paragraphs with its subtitles) in the revised answer and make it more structural\\nfor understanding. Split the paragraphs with /n/n characters. Just output the revised answer directly. DO NOT add\\nadditional explanations or annoucement in the revised answer unless you are asked to.\\n{assistant}\\n...\\nC. TrueSkill Evaluation Framework\\nPart of the tasks in “Embodied planning” and “creative writing” involve using humans for labeling.\\nHuman labelers have 4 choices: “A is better”, “B is better”, “Tie” or “Both are bad”. In this case,\\n“Tie” and “Both are bad” will be counted as a tie. For each task group, we have selected more than\\n10 professional annotators to provide labels. We use the Python “trueskill” package to calculate\\nthe win rate and score. The default score for every method is set as 25. In order to facilitate user\\nunderstanding and selection, we also provide prompts when entering the system.\\n# Chatbot Arena : Benchmarking LLMs in the Wild\\n##Rules\\n- Refresh to obtain the question and its corresponding answers from two anonymous models.\\n- Vote for the better answer. And then click \"New Round\" to get a new question.\\n- If both answers are bad, vote for \"Both are bad\".\\n- If you want to skip, click \"Skip\".\\n## Principle\\nYou can evaluate the performance of the model from the following aspects:\\n1. **Relevance**: Does it answer the question accurately?\\n2. **Accuracy**: Is it accurate? For example, a crafting table is made by combining 4 wooden planks, not 4 logs; a\\ndiamond axe requires 3 diamonds and 2 sticks to craft, not 3 sticks and 2 diamonds.\\n3. **Completeness**: Is it complete? For example, crafting a wooden pickaxe from logs requires first crafting wooden\\nplanks and then crafting sticks before finally being able to craft the pickaxe. The intermediate steps cannot be ignored.\\n4. **Readability**: Is it coherent?\\n5. **Executability**: Considering the characteristics of the game, is it executable?\\n## Vote now!\\nD. Disscussions on Benchmark Contamination\\nTo avoid the code library containing solutions to the exact problems being evaluated) in code\\ngeneration benchmarks, we adopted a rigorous pre-processing methodology as described by Guo\\net al. (2024). This process was meticulously designed to remove any direct matches or overly similar\\n19\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nFigure C.1 | The human evaluation UI. We will display responses from two different methods for the same\\ninstruction on the page simultaneously. The source of the response will be marked as [MASK], and after human\\nlabeling, [MASK] will be replaced with the specific method name.\\ncode snippets from our search vector library, thereby ensuring that our evaluation remains fair and\\nuncontaminated by pre-existing solutions. This examination aims to underscore the importance of\\nmaintaining the integrity of the evaluation process while utilizing external knowledge sources to\\naugment the capabilities of language models in code-generation tasks.\\nTable 5 | Benchmark contamination study based on CodeLlama-7b-Python models. We find using the code\\ncorpus finetuning the CodeLlama models directly will damage model performance on the code generation\\nbenchmark, while using RAT for in-context generation yields better performance.\\nMethod\\nHumanEval\\nHumanEval+\\npass@1\\npass@5\\npass@1\\npass@5\\nDIRECT\\n40.85%\\n53.65%\\n37.43%\\n48.78%\\nFINETUNE\\n29.02%\\n40.24%\\n26.34%\\n35.98%\\nRAT\\n45.73%\\n59.75%\\n43.29%\\n53.66%\\nTo further explore the potential benchmark contamination, we also conducted additional finetuning\\non CodeLLaMA-7B-Python using the code corpus in Table 5.\\n20\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nE. More Results\\nE.1. Emboddied Planning\\nEmbodied planning involves multiple steps, each of which relies on specific world knowledge and\\ncausal knowledge (i.e., preceding steps are usually preconditions for subsequent steps), including\\nrecipes for items in Minecraft, tools for performing related actions, and quantity restrictions. Therefore,\\nalthough the plan generated by ChatGPT may appear complete and correct, there are often errors\\nwithin the steps that can affect the proper execution of the plan.\\nWe mark the errors found in the generated plan in red.\\nResponse E.1: Response from Zero-Shot CoT(based on ChatGPT-3.5) in embodied planning tasks\\n{instruction}\\nGive you nothing in the inventory, generate a step-by-step plan for the task of obtaining a golden apple in Minecraft\\nsurvival mode, and describe the object Minecraft item and its number at every step. For every step, start with ’STEP’ as\\nstart.\\n{response from Original ChatGPT}\\nSTEP 1: Start by punching trees to gather at least 4 logs. - Minecraft item: 4x Logs\\nSTEP 2: Craft the logs into a crafting table. - Minecraft item: 1x Crafting Table\\nSTEP 3: Place the crafting table on the ground and right-click on it to open the crafting interface.\\nSTEP 4: Use the crafting interface to turn 4 of the oak planks into a wooden pickaxe.\\n- Minecraft item: Wooden Pickaxe\\nSTEP 5: Find a cave or dig into the ground to gather some stone. Mine at least 8 blocks of stone using your wooden\\npickaxe. - Minecraft item: 8x Cobblestone\\nSTEP 6: Craft the cobblestone into a furnace using the crafting table. - Minecraft item: 1x Furnace\\nSTEP 7: Place the furnace on the ground and right-click on it to open the furnace interface.\\nSTEP 8: Use the furnace interface to smelt some iron ore. Place at least 3 iron ore in the top slot of the furnace and use\\nwooden planks as fuel in the bottom slot. - Minecraft item: 3x Iron Ingots\\nSTEP 9: Craft the iron ingots into a bucket using the crafting table. - Minecraft item: 1x Bucket\\nSTEP 10: Find a water source (such as a lake or a river) and right-click on it while holding the bucket to fill it with\\nwater. - Minecraft item: 1x Water Bucket\\nSTEP 11: Look for an apple tree in a forest biome. Break some leaves until you find an apple. - Minecraft item: 1x Apple\\nSTEP 12: Combine the water bucket and the apple in the crafting table to craft a golden apple. - Minecraft item: 1x\\nGolden Apple\\nCongratulations! You have successfully obtained a golden apple in Minecraft survival mode.\\nAlthough the Zero-shot CoT has generated a step-by-step plan overall, there are many factual errors\\nwithin it. These include recipe errors in STEP 2, where the crafting table requires planks instead of\\nwood; missing raw materials in STEP 4, as the wooden pickaxe needs 2 sticks but lacks the relevant\\nstep in the plan; absence of instructions to use a stone pickaxe to mine iron ore in STEP 8; and an\\nincorrect recipe for golden apple in STEP 12, which should include gold ingots and an apple rather\\nthan a water bucket.\\n21\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nResponse E.2: Response from RAT(based on ChatGPT-3.5) in embodied planning tasks\\n{instruction}\\nGive you nothing in the inventory, generate a step-by-step plan for the task of obtaining a golden apple in Minecraft\\nsurvival mode, and describe the object Minecraft item and its number at every step. For every step, start with ’STEP’ as\\nstart.\\n{response from Original ChatGPT}\\nSTEP 1: Find a tree and chop it down to get wood. You need at least 4 Oak Logs.\\n- Minecraft items: 4x Oak Logs\\nSTEP 2: Craft the oak log into oak planks.\\n- Minecraft items: 16x Oak Planks\\nSTEP 3: Convert some oak planks into sticks.\\n- Minecraft items: 4x Stick\\nSTEP 4: Use the crafting table to create a wooden pickaxe.\\n- Minecraft items: 1x Wooden Pickaxe\\nSTEP 5: Start digging down to find stone and gather at least three pieces of cobblestone.\\n- Minecraft items: 3x Cobblestone\\nSTEP 6: Use the crafting table to create a stone pickaxe.\\n- Minecraft items: 1x Stone Pickaxe\\nSTEP 7: Explore caves and mineshafts to find iron ore. Collect 3 iron ore for crafting an iron pickaxe.\\n- Minecraft items: 3x Iron Ore\\nSTEP 8: Smelt the iron ore using a furnace to obtain iron ingot.\\n- Minecraft items: 3x Iron Ingot\\nSTEP 9: Use the crafting table to create an iron pickaxe.\\n- Minecraft items: 1x iron pickaxe\\nSTEP 10: Explore caves and mineshafts to find gold ore. Use an iron pickaxe or higher to mine the gold ore block.\\nCollect as much gold ore as needed for crafting a golden apple.\\n- Minecraft items: 8x Gold Ore\\nSTEP 11: Smelt the raw gold using a furnace to obtain a gold ingot.\\n- Minecraft items: 8x Gold Ingot\\nSTEP 12: Find an oak tree and chop it down until an apple falls.\\n- Minecraft items: 1x Apple\\nSTEP 13: Open the crafting menu and place the items in the correct pattern to craft a Golden Apple. In the 3x3 crafting\\ngrid, place 8 Gold Ingots in the first and third rows, leaving the middle square empty. In the second row, place 1 Gold\\nIngot in the first and third squares, and place an Apple in the middle square.\\n- Minecraft items: 1x Golden Apple\\nCongratulations! You have successfully obtained a golden apple in Minecraft survival mode.\\nThere are still errors in the plan generated by RAT, such as the lack of tools before \"STEP 8: smelt\\niron ore into iron ingots\", which should be “Mine 8 cobblestone to craft 1 furnace”. However, compared\\nto the errors in ChatGPT, the error rate in the plan has been significantly reduced.\\nWe have also listed the links of the retrieved pages involved in different steps. We can see that the\\ntext sources retrieved in each step generated by RAT are usually highly related to the synthesized\\nitem of that step. Traditional RAG uses instructions for retrieval and can only find the final step. While\\nRAT can retrieve all links related to intermediate items, which improves the accuracy and plausibility\\ngreatly.\\n22\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nTable 6 | Page link of retrieved text in embodied Minecraft planning tasks.\\nStep\\nItem\\nRecipe\\nLink\\n1\\n4x Oak Log\\n-\\nhttps://minecraft.fandom.com/wiki/Log\\n2\\n16x Oak Planks\\n4x Oak Log\\nhttps://www.digminecraft.com/basic_recipes/make_oak_wood_plank.php\\n3\\n4x Stick\\n2x Oak Planks\\nhttps://www.digminecraft.com/basic_recipes/make_stick.php\\n4\\n1x Wooden Pickaxe\\n3x Oak Planks, 2 Stick\\nhttps://www.digminecraft.com/tool_recipes/make_wooden_pickaxe.php\\n5\\n3x Cobblestone\\nWooden Pickaxe\\nhttps://minecraft.fandom.com/wiki/Cobblestone\\n6\\n1x Stone Pickaxe\\n3x Cobblestone, 2 Stick\\nhttps://www.digminecraft.com/tool_recipes/make_stone_pickaxe.php\\n7\\n3x Iron Ore\\nStone Pickaxe\\nhttps://minecraft.fandom.com/wiki/Iron_Ore\\n8\\n3x Iron Ingot\\n3x Iron Ore\\nhttps://www.digminecraft.com/basic_recipes/make_iron_ingot.php\\n9\\n1 Iron Pickaxe\\n3x Iron Ingot, 2x Stick\\nhttps://www.digminecraft.com/tool_recipes/make_iron_pickaxe.php\\n10\\n8x Gold Ore\\nIron Pickaxe\\nhttps://minecraft.fandom.com/wiki/Gold_Ore\\n11\\n8x Gold Ingot\\n8x Gold Ore\\nhttps://www.digminecraft.com/basic_recipes/make_gold_ingot.php\\n12\\n1x Apple\\n-\\nhttps://minecraft.fandom.com/wiki/Apple\\n13\\n1x Golden Apple\\n8x Gold Ingot, 1x Apple\\nhttps://www.digminecraft.com/food_recipes/make_golden_apple.php\\nE.2. Creative Writing\\nResponse E.3: Response from ORIGINAL ChatGPT-3.5 in creative writing tasks\\n{instruction}\\nDescribe the history of the United States. {response from Original ChatGPT}\\nThe history of the United States dates back thousands of years, with indigenous peoples such as the Native Americans\\ninhabiting the land long before the arrival of European settlers. However, the official history of the United States begins\\nin 1776 when the Founding Fathers declared independence from Great Britain. This marked the start of the American\\nRevolution, a conflict that ultimately led to the creation of the United States as an independent nation.\\nAfter gaining independence, the United States went through a period of rapid expansion in the 19th century. The country\\nacquired vast amounts of territory, including the Louisiana Purchase and the annexation of Texas. This expansion was\\naccompanied by conflicts, such as the Mexican-American War and the Civil War, which tested the unity of the nation.\\nIn the 20th century, the United States emerged as a global superpower. The country played a significant role in both\\nWorld War I and World War II, eventually becoming the leader of the free world during the Cold War with the Soviet\\nUnion. The United States experienced social and cultural shifts during this time, including the Civil Rights Movement\\nand the rise of consumerism.\\nToday, the United States remains a powerful nation, with a diverse population and a complex history that continues to\\nshape its identity.\\n23\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nResponse E.4: Response from Zero-shot CoT in creative writing tasks\\n{instruction}\\nDescribe the history of the United States.\\n{response from Zero-shot CoT}\\n**Pre-Columbian Era**\\nThe history of the United States begins long before the arrival of European explorers in the 15th century. The land was\\ninitially inhabited by diverse Native American tribes, such as the Apache, Sioux, Iroquois, and Cherokee. These societies\\nhad rich cultures, with their own languages, traditions, and social structures. They lived off the land, flourishing through\\nhunting, fishing, farming, and trade. However, the indigenous populations faced significant challenges, including\\nconflicts, displacement, and diseases brought by the European settlers.\\n**Colonial Period**\\nIn the 16th century, European powers began to claim territories in what is now the United States. The Spanish were the\\nfirst to establish colonies, initially focusing on Central and South America. Later, English, French, and Dutch explorers\\narrived, establishing their own colonies along the Atlantic coast. These colonies varied in purpose and organization, with\\nthe English colonies primarily seeking economic opportunities and religious freedom. Over time, thirteen British colonies\\nemerged, forging their own identities, developing local governments, and experiencing an increase in population due to\\nimmigration.\\n**American Revolution and Beyond**\\nTensions between the British colonies and their colonial masters grew, leading to the American Revolution in 1775. The\\ncolonies, unified under the Continental Congress, fought for independence from British rule. The war lasted several years,\\nuntil the signing of the Treaty of Paris in 1783, which granted the newly formed United States of America independence.\\nAfter achieving independence, the founding fathers convened to draft the Constitution, establishing the framework for\\nthe new nation’s government.\\nThis is just a brief overview, and the history of the United States is vast and complex. However, these steps provide a\\nsimplified understanding of how the nation evolved from Native American civilizations to a group of British colonies, to\\nan independent country.\\nResponse E.5: Response from RAG(1-shot) in creative writing tasks\\n{instruction}\\nDescribe the history of the United States.\\n{response from RAG-1}\\nThe history of the United States is a complex and rich tapestry that spans over four centuries. The story begins with the\\narrival of European explorers and settlers in the 16th century. In 1492, Christopher Columbus reached the Americas,\\nwhich led to subsequent expeditions and colonization by the Spanish, French, Dutch, and English. The first successful\\nEnglish settlement was established at Jamestown, Virginia in 1607.\\nOver the next few centuries, the colonies grew and developed their own unique cultures, economies, and systems of\\ngovernment. Tensions rose between the American colonies and the British Crown, leading to the American Revolutionary\\nWar in 1775. The colonies declared their independence in 1776 and formed the United States of America, which became\\na republic based on democratic ideals and principles.\\nThe young nation faced numerous challenges in its early years, including establishing a central government, expanding\\nwestward, and dealing with the issue of slavery. The 19th century saw rapid westward expansion, the Industrial\\nRevolution, and the Civil War. The United States emerged from the Civil War as a more unified and powerful nation,\\nwith the abolition of slavery and the preservation of the Union. In the 20th century, the United States became a global\\nsuperpower, playing a crucial role in both World Wars and the Cold War. It witnessed significant social movements for\\ncivil rights and equality, as well as advancements in technology and innovation.\\nToday, the United States is a diverse and influential country with a strong economy, global military presence, and a\\ncomplex political landscape. Its history continues to shape its present and future, as the nation grapples with ongoing\\nsocial, economic, and political challenges.\\n24\\nRetrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation\\nResponse E.6: Response from RAG(5-shot) in creative writing tasks\\n{instruction}\\nDescribe the history of the United States.\\n{response from RAG-5}\\nThe history of the United States dates back to the colonization of the Americas by European explorers in the 16th century.\\nThe first permanent English settlement was established in Jamestown, Virginia in 1607. This marked the beginning of\\nBritish colonization in North America.\\nOver the next century, more British colonies were established along the eastern seaboard, including Massachusetts, New\\nYork, Pennsylvania, and Georgia. These colonies grew and developed their own distinct cultures and economies.\\nTensions between the colonies and the British government grew in the mid-18th century, leading to the American\\nRevolutionary War in 1775. The colonists, led by figures such as George Washington, Thomas Jefferson, and Benjamin\\nFranklin, fought for their independence from British rule.\\nIn 1776, the Second Continental Congress adopted the Declaration of Independence, which declared the thirteen\\nAmerican colonies to be independent states. This marked the birth of the United States of America.\\nFollowing the Revolutionary War, the Founding Fathers drafted the Constitution of the United States, which established\\na federal government and outlined the rights and freedoms of American citizens. The Constitution was ratified in 1788\\nand is still the supreme law of the land.\\nSince its founding, the United States has experienced significant growth and development. It expanded westward\\nthrough the Louisiana Purchase and the annexation of Texas, and it eventually stretched from coast to coast. The country\\nalso faced significant challenges, such as the Civil War, the Great Depression, and the Civil Rights Movement.\\nToday, the United States is a global superpower with a diverse population and a strong economy. It is known for its\\ndemocratic system of government, individual freedoms, and cultural influence.\\nResponse E.7: Response from RAT in creative writing tasks\\n{instruction}\\nDescribe the history of the United States.\\n{response from RAT}\\nThe history of the United States is characterized by several significant phases. The pre-colonial period witnessed\\ndiverse Native American populations with unique cultures inhabiting the land. This era transitioned into colonialism\\nthrough European exploration and settlement by powers such as the Spanish, French, Dutch, and British, leading to the\\nestablishment of colonies along the East Coast with distinct economic and political frameworks.\\nA pivotal moment in American history was the American Revolution, beginning in 1775, as the colonies sought indepen-\\ndence from British rule. The Declaration of Independence in 1776 marked the nation’s founding on principles of liberty\\nand democracy, establishing autonomy from Great Britain. This revolutionary period not only birthed a republic based\\non the will of the people but also forged American national identity, fostering a collective ethos entrenched in history\\nand culture, inspiring revolutions worldwide and aiding in the establishment of republican governments elsewhere.\\nThe United States stands out as the first modern nation to achieve independence through a national war of liberation,\\narticulating its motives and aspirations in a declaration of independence. This event had global reverberations, spreading\\nfundamental values like liberty, equality, natural and civil rights, and civic duty. The formative years were shaped by the\\ndrafting of the Constitution in 1787, defining the federal government’s framework. The subsequent ratification of the\\nBill of Rights further cemented individual freedoms and outlined governance principles that have endured across the\\nnation’s history, ensuring a system of checks and balances that protect citizens’ rights.\\nThe 19th century in the United States witnessed significant developments, including westward expansion, industrializa-\\ntion, and conflicts like the Civil War (1861-1865), which decisively addressed issues of slavery and reinforced federal\\nauthority over the states. The late 19th and early 20th centuries were marked by rapid industrial growth, extensive\\nimmigration, urbanization, and overseas expansion, including involvement in conflicts such as the Spanish-American War\\nand World War I. The 20th century saw the United States emerge as a global superpower after World War II, engaging\\nin the Cold War with the Soviet Union and participating in conflicts like the Korean and Vietnam Wars, significantly\\nimpacting the nation’s foreign policy and global standing.\\nRecent history includes social movements for civil rights, gender equality, and environmental protection, as well as\\neconomic shifts, advancements in technology, and challenges in areas such as healthcare and international relations.\\n25\\n', metadata={'Published': '2024-03-08', 'Title': 'RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation', 'Authors': 'Zihao Wang, Anji Liu, Haowei Lin, Jiaqi Li, Xiaojian Ma, Yitao Liang', 'Summary': \"We explore how iterative revising a chain of thoughts with the help of\\ninformation retrieval significantly improves large language models' reasoning\\nand generation ability in long-horizon generation tasks, while hugely\\nmitigating hallucination. In particular, the proposed method --\\n*retrieval-augmented thoughts* (RAT) -- revises each thought step one by one\\nwith retrieved information relevant to the task query, the current and the past\\nthought steps, after the initial zero-shot CoT is generated. Applying RAT to\\nGPT-3.5, GPT-4, and CodeLLaMA-7b substantially improves their performances on\\nvarious long-horizon generation tasks; on average of relatively increasing\\nrating scores by 13.63% on code generation, 16.96% on mathematical reasoning,\\n19.2% on creative writing, and 42.78% on embodied task planning. The demo page\\ncan be found at https://craftjarvis.github.io/RAT\"}),\n",
       " Document(page_content='Can Large Language Models Reason and Plan?\\nSubbarao Kambhampati\\nSchool of Computing & Augmented Intelligence\\nArizona State University\\nemail: rao@asu.edu\\nA version appears in the Annals of The New York Academy of Sciences:\\nhttps://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.15125\\nLarge Language Models (LLMs), essentially n-gram mod-\\nels on steroids* that have been trained on web-scale lan-\\nguage corpora (or, effectively, our civilizational knowl-\\nedge), have caught our collective imagination with linguis-\\ntic behaviors that no one expected text completion systems\\nto possess3. By training and operation, LLMs are perhaps\\nbest seen as giant non-veridical memories akin to an ex-\\nternal System 12 for us all (see Figure 1). Their seem-\\ning versatility has however led many researchers to wonder\\nwhether they can also do well on planning and reasoning\\ntasks typically associated with System 2 competency.\\nNothing in the training and use of LLMs would seem\\nto suggest remotely that they can do any type of princi-\\npled reasoning (which, as we know, often involves com-\\nputationally hard inference/search). What LLMs are good\\nat is a form of universal approximate retrieval.\\nUnlike\\ndatabases that index and retrieve data exactly, LLMs, as n-\\ngram models, probabilistically reconstruct completions for\\nthe prompt word by word–a process we shall refer to as\\napproximate retrieval. This means that LLMs can’t even\\nguarantee memorizing complete answers, something that\\nis the flip side of their appeal about constructing “novel”\\nprompt completions on the fly. The boon (“creativity”) and\\nbane (“hallucination”) of LLMs is that n-gram models will\\nnaturally mix and match–and have almost as much trouble\\nstrictly memorizing as we do. It is indeed the very basis of\\ntheir appeal.\\n*LLMs are trained to predict the distribution of the n-th to-\\nken given n-1 previous tokens. GPT3.5 that powered the origi-\\nnal ChatGPT is, for example, a roughly 3001-gram model of lan-\\nguage.\\nFigure 1. An informal account of viewing LLM as a giant external\\nnon-veridical memory that acts as a pseudo System 1\\nDespite this, the “Large Language Models are Zero-Shot\\n⟨insert-your-reasoning-task ⟩” has almost become a meme\\npaper title! At some level, this trend is perhaps inevitable as\\nin the era of LLMs, AI has become a form of ersatz natural\\nscience5–driven by observational studies of capabilities of\\nthese behemoth systems.\\nSo, are these n-gram models on steroids really capable of\\nplanning and reasoning? In the summer of 2022, when my\\nresearch group wanted to better answer this question, most\\nreasoning claims were still somewhat anecdotal. So, we set\\nout to evaluate GPT3 on a set of planning instances derived\\nfrom the domains typically used in the International Plan-\\nning Competition (IPC) –including the well known Blocks\\nWorld†. Our results13 were contrary to the anecdotal claims\\nabout the planning abilities of LLMs, and when we made\\nthem public, received significant attention in the AI circles.\\nBy the beginning of 2023, with the wide-spread public re-\\n†https://en.wikipedia.org/wiki/Blocks world\\n1\\narXiv:2403.04121v2  [cs.AI]  8 Mar 2024\\nlease of ChatGPT, and later, GPT4, there were a slew of ad-\\nditional claims, including in refereed papers, about LLM’s\\nabilities to reason and plan. So we decided to repeat our\\ntests on both GPT3.5 and GPT412. Initial results showed\\nthat there was some improvement in the accuracy of gen-\\nerated plans from GPT3 to GPT3.5 to GPT4, with GPT4\\nreaching 30% empirical accuracy in the Blocks World (al-\\nbeit still lower in other domains). We then wanted to know\\nwhether the modest improvement is because of the im-\\nproved approximate retrieval abilities or whether GPT4 is\\nactually doing/searching for plans.\\nLet us pause to note that my interest here is not whether\\nLLMs can fake reasoning (by giving correct answers to\\nreasoning tasks from memory and pattern finding), but\\nwhether they can actually do principled reasoning.\\nOf\\ncourse, seeing patterns in reasoning problems is not any-\\nthing to be sneezed at. After all, our interest in master-\\ning it is what is behind much of “street fighting” math\\n(e.g. George P´olya’s ”How to Solve it”). But finding ap-\\nproximate shortcuts over provably correct reasoning proce-\\ndures is obviously not equivalent to doing reasoning–unless\\nyou have an ability to establish from first principles that\\nyour hunch is actually correct. It is challenging to decide\\nwhether a system (or a human, for that matter) is memoriz-\\ning or solving a problem from scratch–especially as the sys-\\ntems (or humans) get trained on larger and larger “question\\nbanks.” This is a challenge that most instructors and inter-\\nviewers are acutely aware of. Think of that infamous “Why\\nare manhole covers round?” interview question. While it\\nmay well have given the interviewer an insight into the\\ncandidate’s analytical reasoning skills the very first time it\\nwas asked, all it does with high probability now is to con-\\nfirm whether the candidate trained on the interview ques-\\ntion banks!\\nConsidering that the LLMs don’t suffer some of the nor-\\nmal limitations of humans–such as having a life on the\\nside, and thus not having the time or inclination to focus\\nexclusively on the test/interview preparation for long peri-\\nods, they can support approximate retrieval over webscale\\ncorpora. My research group wanted to check if the im-\\nproved performance of GPT4 is because of approximate re-\\ntrieval from a larger training corpus, or really comes from\\nits ability to plan. One way of checking this for planning\\ntasks is to reduce the effectiveness of approximate retrieval\\nby obfuscating the names of the actions and objects in the\\nplanning problem. When we did this for test domains12,11,\\nGPT4’s empirical performance plummeted precipitously,\\ndespite the fact that none of the standard off-the-shelf AI\\nplanners have any trouble with such obfuscation.‡\\nPerhaps they can’t do planning autonomously straight out\\nof the box, but can they do it with a little nudge? There\\nare broadly two popular techniques for such nudging. The\\nfirst, called “fine tuning,” is rather straightforward: take a\\ngeneral LLM and fine tune it on planning problems (i.e.,\\ninstances and their solutions), with the hope that they will\\nsubsequently make better guesses (see the left-hand side\\nof Figure 1). While our own limited experiments didn’t\\nshow any significant improvement through fine tuning, it\\nis possible that with even more fine tuning data and ef-\\nfort, the quality of LLM guesses may well improve. But\\nall that such fine tuning is doing is converting the planning\\ntask into a memory-based approximate retrieval (akin to the\\nmemorization/compilation from System 2 to System 1; see\\nFigure 1). It doesn’t prove that LLMs are able to plan.\\nThe second way to improve planning (and reasoning) per-\\nformance is to prompt an LLM back with hints/suggestions\\nabout how it can improve its initial plan guess. The crucial\\nquestions here are (a) whether this back prompting is man-\\nual or automated (b) who is certifying the correctness of the\\nfinal answer and (c) whether the prompts inject additional\\nproblem knowledge or are just merely exhorting the LLM\\nto try again.\\nThe cleanest approach–one we advocate12,6–is to let an ex-\\nternal model-based plan verifier do the back prompting and\\nto certify the correctness of the final solution. In general,\\nsuch LLM-Modulo frameworks6 can gainfully leverage the\\namazing idea generation capabilities of LLMs with sound\\nexternal verifiers in a generate-test-critique framework with\\ngurantees.\\nIn contrast, by far the more popular methodology is to\\nhave the human in the loop prompt the LLM iteratively.\\nThe problem with this is that it is highly susceptible to the\\n‡As these results came about at the height of sparks of\\nAGI/existential risk angst, we couldn’t resist the tongue-in-cheek\\neditorializing that if GPT4 ever goes rogue, you can stymie it by\\nthrowing a simple planning problem at it! Humor aside, nothing\\nin our studies showed that GPT4 is capable of generating exe-\\ncutable plans autonomously.\\n2\\nFigure 2. Claimed reasoning capabilities of LLMs are sometimes\\ndue to the subconscious helpful iterative prompting by the humans\\nin the loop (graphic adapted from https://xkcd.com/2347/ under\\nCreative Commons License)\\nClever Hans effect§, where the LLM is merely generating\\nguesses, and it is the human in the loop, with the knowledge\\nof right vs. wrong solutions, who is steering the LLM–even\\nif they didn’t set out to do so deliberately. The credit and\\nblame for the ensuring accuracy, if any, falls squarely on\\nthe human in the loop. The relevance of such a frame-\\nwork becomes questionable when the human-in-the-loop\\ndoesn’t know (or is unable to verify) the answer to the rea-\\nsoning/planning problem themselves. Thus the tongue-in-\\ncheek characterization of LLM reasoning abilities in Fig-\\nure 2.\\nA variation on the second approach is to have the LLM it-\\nself “critique” the guesses it generates and iteratively self-\\nimprove. Although some papers seem to swear by such a\\n“self-improvement” capability of LLMs, the plausibility of\\nsuch a claim hinges on the belief that the LLMs are bet-\\nter at verifying their solutions than they are at generating\\nthem. While never explicitly justified, the assumption rests\\n§https://en.wikipedia.org/wiki/Clever Hans\\non either analogies to humans or indirect nods to compu-\\ntational complexity arguments. While humans sometimes\\ndo show the capability of correcting their own erroneous\\nguesses with self-critiquing, there seems to be no basis for\\nthat assumption in the case of LLMs. And while for many\\ncomputational tasks (e.g. those in class NP¶), the verifica-\\ntion is often of lower complexity than generation, that fact\\ndoesn’t seem particularly relevant for LLMs which are gen-\\nerating (approximately retrieving) guesses, rather than ac-\\ntually solving the problem with guarantees. Indeed two re-\\ncent studies from my lab–one on plan verification10 and the\\nother on constraint verification9–seem to throw cold water\\non this optimism by showing that with “self-verification”\\nperformance actually worsens. This is because LLMs hal-\\nlucinate both false positives and false negatives while ver-\\nifying the solutions they generate. One reason this is not\\nrecognized in earlier literature is that there self-verification\\nclaims are often made in the context of tacit knowledge\\ntasks for which there is little possibility of a verifier (e.g.\\nwriting/improving essays), making it harder to evaluate\\nwhether LLM’s critiquing actually helped. Paradoxically,\\nthe fact that it is infeasible to write sound verifiers for tacit\\nknowledge tasks also makes it easier to mistake LLMs for\\nbeing as reasonable a critic as any!|| In other cases, an ex-\\nternal simulator winds up playing the role of sound verifi-\\ncation.\\nWhile the foregoing questions the claims that LLMs are\\ncapable of planning/reasoning, it is not meant to imply that\\nLLMs don’t have any constructive roles to play in solving\\nplanning/reasoning tasks. In particular, their uncanny abil-\\nity to generate ideas/potential candidate solutions–albeit\\nwith no guarantees about those guesses–can still be valu-\\nable in the “LLM-Modulo” setups6, in conjunction with\\neither model-based verifiers or expert humans in the loop.\\nThe trick to avoiding ascribing autonomous reasoning ca-\\npabilities to LLMs is to recognize that LLMs are generating\\npotential answers that still need to be checked by external\\nverifiers.\\nThe skeptical reader might now ask: But what about all\\n¶NP stands for nondeterministic polynomial, and covers the\\nclass of computational problems whose solutions can be verified\\nin polynomial time.\\n||In other words, LLMs can be as good as that Peloton instruc-\\ntor in confidently critiquing Christopher Nolan movies.\\n3\\nthose papers at high profile AI conferences that claim to\\nshow planning abilities of LLMs? To analyze those claims,\\nwe need to first understand that solving planning tasks re-\\nquires (a) having the necessary planning domain knowl-\\nedge–the actions and their preconditions, effects; the stan-\\ndard hierarchical recipes (e.g. task reduction schemas in\\nHierarchical Task Network planning), past cases/plans etc.\\nand (b) being able to assemble this knowledge into an ex-\\necutable plan that takes care of any subgoal/resource inter-\\nactions. The first can be called the knowledge acquisition\\npart, and the second reasoning/planning part. Many of the\\npapers claiming planning abilities of LLMs, on closer ex-\\namination, wind up confusing general planning knowledge\\nextracted from the LLMs for executable plans. When all we\\nare looking for are abstract plans, such as “wedding plans,”\\nwith no intention of actually executing said plans directly,\\nit is easy to confuse them for complete executable plans.\\nIndeed, our close examination of several papers claiming\\nplanning capabilities7 for LLMs suggests that they either\\nare evaluating in domains/tasks where subgoal interactions\\ncan be safely ignored, or delegating the interaction resolu-\\ntion (reasoning) to the humans in the loop (who, through\\nrepeated prompting, have to “correct” the plan). Some-\\ntimes, in common sense domains, or with enough fine tun-\\ning, the “assembling” part may also be obviated by having\\nseen a case that pretty much corresponds to the problem\\nthat needs to be solved. Without these assumptions or mit-\\nigations, the plans that come out of LLMs may look rea-\\nsonable to the lay user, but lead to execution time interac-\\ntions and errors. These issues are illustrated in part by a\\nrecent news story about the proliferation of travel planning\\nbooks8, mostly auto-extracted from LLMs, and the ensu-\\ning disappointment of the unsuspecting end users who buy\\nthem mistaking them for usable plans!\\nThe fact that LLMs are often good at extracting planning\\nknowledge can indeed be gainfully leveraged. As we have\\nargued in recent work1, LLMs can be a rich source of\\napproximate models of world/domain dynamics and user\\npreferences, as long as the humans (and any specialized\\ncritics) in the loop verify and refine the models, and give\\nthem over to model-based solvers. This way of using LLMs\\nhas the advantage that the humans need only be present\\nwhen the dynamics/preference model is being teased out\\nand refined, with the actual planning after that being left to\\nsound frameworks with correctness guarantees6.\\nFigure 3. Viewing LLMs as an approximate knowledge source\\ntrained over civilizational knowledge\\nSuch a framework has striking similarities to knowledge-\\nbased AI systems of yore, with LLMs effectively replac-\\ning the “knowledge engineer” (Figure 3). Given the rather\\nquixotic and dogmatic shift of AI away from approaches\\nthat accept domain knowledge from human experts, some-\\nthing I bemoaned in “P´olanyi’s revenge and AI’s new ro-\\nmance with tacit knowledge”4 this new trend of using\\nLLMs as knowledge sources can be viewed as a form of\\navenging Polanyi’s revenge (by bringing explicit knowl-\\nedge back to AI systems, if only as gleaned from LLMs).**\\nIndeed, LLMs make it easy to get problem-specific knowl-\\nedge, as long as we are willing to relax correctness require-\\nments of that knowledge. In contrast to the old knowledge\\nengineering approaches, LLMs offer this without making it\\nlook like we are inconveniencing any specific human (we\\nare, instead, just leveraging everything humans have told\\neach other!). So the million dollar question for reasoning\\ntasks becomes: “how would you do planning if you have\\nsome doddering know-it-all ready to give you any kind of\\nknowledge?” The LLM-Modulo framework6 is a princi-\\npled method for tackling this challenge.\\nTo summarize, nothing that I have read, verified, or done\\ngives me any compelling reason to believe that LLMs do\\nreasoning/planning, as normally understood. What they do\\ninstead, armed with web-scale training, is a form of uni-\\nversal approximate retrieval, which, as I have argued, can\\n**There is rich irony here: If you give what you know about\\na toy world to the computer, and have it solve new instances, it\\nwould be derisively called “Good Old Fashioned AI,” but if you\\ncapture all that the humanity knows about everything (as exported\\nto the Internet), train your LLM on it, and then ask it to provide\\napproximate task relevant knowledge, then it becomes “modern\\nAI.”\\n4\\nsometimes be mistaken for reasoning capabilities. LLMs\\ndo excel in idea generation for any task–including those\\ninvolving reasoning, and as I pointed out, this can be ef-\\nfectively leveraged to support reasoning/planning in LLM-\\nModulo frameworks6. In other words, LLMs already have\\nenough amazing approximate retrieval abilities that can be\\ngainfully leveraged, that we don’t need to ascribe question-\\nable reasoning/planning capabilities to them.††\\nReferences\\n[1] Lin Guan, Karthik Valmeekam, Sarath Sreedharan,\\nand Subbarao Kambhampati. Leveraging pre-trained\\nlarge language models to construct and utilize world\\nmodels for model-based task planning.\\nIn Thirty-\\nseventh Conference on Neural Information Process-\\ning Systems, 2023.\\n[2] Daniel Kahneman. Thinking, fast and slow. macmil-\\nlan, 2011.\\n[3] Subbarao Kambhampati. Language imitation games\\nand the arrival of broad and shallow AI. CACM Blog,\\n2021.\\n[4] Subbarao Kambhampati. Polanyi’s revenge and AI’s\\nnew romance with tacit knowledge. Communications\\nof the ACM, 64(2):31–32, 2021.\\n[5] Subbarao Kambhampati. AI as (an ersatz) natural sci-\\nence? Communications of the ACM, 65(9):8–9, 2022.\\n[6] Subbarao Kambhampati, Karthik Valmeekam, Lin\\nGuan, Kaya Stechly, Mudit Verma, Siddhant Bham-\\nbri, Lucas Saldyt, and Anil Murthy. LLMs can’t plan,\\nbut can help planning in LLM-Modulo frameworks.\\narXiv preprint 2402.01817, 2024.\\n[7] Subbarao.\\nKambhampati,\\nKarthik.\\nValmeekam,\\nMatthew. Marquez, and Lin. Guan.\\nOn the role\\n††Although we focused on planning and reasoning tasks, the\\ndiscussion here has implications to LLM-based code generation.\\nThere too, while LLMs can help as “co-pilots” to human pro-\\ngrammers, there is never any guarantee that the code they gen-\\nerate is correct. The fact that code generation capabilities come\\nfrom github data, that is of higher quality than the general web\\ndata, and the fact that incremental interpreters in the loop can pin-\\npoint any syntax errors in the generated code, helps the utility of\\nthe suggested code snippets for human programmers.\\nof large language models in planning, July 2023.\\nTutorial presented at the International Conference\\non Automated Planning and Scheduling (ICAPS),\\nPrague.\\n[8] Seth Kugel and Stephen Hiltner. A new frontier for\\ntravel scammers: A.I.-Generated Guidebooks. New\\nYork Times, August 2023.\\n[9] Kaya Stechly, Matthew Marquez, and Subbarao\\nKambhampati. GPT-4 Doesn’t Know It’s Wrong: An\\nAnalysis of Iterative Prompting for Reasoning Prob-\\nlems. In NeurIPS 2023 Foundation Models for Deci-\\nsion Making Workshop, 2023.\\n[10] Karthik Valmeekam, Matthew Marquez, and Sub-\\nbarao Kambhampati. Can large language models re-\\nally improve by self-critiquing their own plans?\\nIn\\nNeurIPS 2023 Foundation Models for Decision Mak-\\ning Workshop, 2023.\\n[11] Karthik Valmeekam, Matthew Marquez, Alberto\\nOlmo, Sarath Sreedharan, and Subbarao Kambham-\\npati. Planbench: An extensible benchmark for evalu-\\nating large language models on planning and reason-\\ning about change. In Thirty-seventh Conference on\\nNeural Information Processing Systems Datasets and\\nBenchmarks Track, 2023.\\n[12] Karthik Valmeekam,\\nMatthew Marquez,\\nSarath\\nSreedharan, and Subbarao Kambhampati.\\nOn the\\nplanning abilities of large language models - a crit-\\nical investigation.\\nIn Thirty-seventh Conference on\\nNeural Information Processing Systems, 2023.\\n[13] Karthik Valmeekam, Alberto Olmo, Sarath Sreedha-\\nran, and Subbarao Kambhampati.\\nLarge language\\nmodels still can’t plan (a benchmark for llms on plan-\\nning and reasoning about change).\\narXiv preprint\\narXiv:2206.10498, 2022.\\n5\\n', metadata={'Published': '2024-03-08', 'Title': 'Can Large Language Models Reason and Plan?', 'Authors': 'Subbarao Kambhampati', 'Summary': 'While humans sometimes do show the capability of correcting their own\\nerroneous guesses with self-critiquing, there seems to be no basis for that\\nassumption in the case of LLMs.'}),\n",
       " Document(page_content='Empowering Large Language Model Agents through Action Learning\\nHaiteng Zhao 1 Chang Ma 2 Guoyin Wang 3 Jing Su 3\\nLingpeng Kong 2 Jingjing Xu 3 Zhi-Hong Deng 1 Hongxia Yang 3\\nAbstract\\nLarge Language Model (LLM) Agents have re-\\ncently garnered increasing interest yet they are\\nlimited in their ability to learn from trial and error,\\na key element of intelligent behavior. In this work,\\nwe argue that the capacity to learn new actions\\nfrom experience is fundamental to the advance-\\nment of learning in LLM agents. While humans\\nnaturally expand their action spaces and develop\\nskills through experiential learning, LLM agents\\ntypically operate within fixed action spaces, lim-\\niting their potential for growth. To address these\\nchallenges, our study explores open-action learn-\\ning for language agents. We introduce a frame-\\nwork LearnAct with an iterative learning strat-\\negy to create and improve actions in the form of\\nPython functions. In each iteration, LLM revises\\nand updates the currently available actions based\\non the errors identified in unsuccessful training\\ntasks, thereby enhancing action effectiveness. Our\\nexperimental evaluations across Robotic Planning\\nand Alfworld environments reveal that after learn-\\ning on a few training task instances, our approach\\nto open-action learning markedly improves agent\\nperformance for the type of task—by 32% in\\nAlfWorld compared to ReAct+Reflexion, for in-\\nstance— highlighting the importance of experien-\\ntial action learning in the development of more\\nintelligent LLM agents. The code is available at\\nhttps://github.com/zhao-ht/LearnAct.\\n1. Introduction\\nLanguage agents, which employ the large language model\\n(LLM) as the policy model to control agents to iteratively\\ntake actions and interact with environments, have recently\\ngarnered increasing interest (Yao et al., 2023a; Brohan et al.,\\n2023; Wang et al., 2023a; Xie et al., 2023; Song et al.,\\n2023; Xu et al., 2023). The underlying reason is that LLMs\\noffer a fresh angle to address the commonsense issue that\\nis difficult to tackle in the reinforcement learning paradigm\\n1Peking University 2The University of Hong Kong 3ByteDance.\\nwhich learns the agent policy solely from trial and error.\\nReasoning and planning of agents are often derived from\\nprior knowledge in the particular environment, precisely\\nwhere LLMs excel.\\nResearchers increasingly recognize that, while leveraging\\nLLMs for agent control shows promise, it is far from per-\\nfect due to their limited ability to learn from experience\\n(Yao et al., 2023b; Shinn et al., 2023; Huang et al., 2023).\\nThe substantial scale of LLMs makes direct policy model\\nfinetuning impractical. Instead, LLMs depend on incorpo-\\nrating historical interactions into prompts to leverage past\\nexperiences for future action planning (Yao et al., 2023a;\\nShinn et al., 2023; Sun et al., 2023; Madaan et al., 2023).\\nHowever, these approaches are often constrained in their\\ncapacity to learn from long-term experiences and typically\\ndraw experience on single-instance examples (Wang et al.,\\n2023c; Ma et al., 2024; Wang et al., 2023a).\\nWhile humans naturally expand their action spaces and de-\\nvelop skills through experiential learning, LLM agents typi-\\ncally operate within predetermined action spaces (Qin et al.,\\n2023; Schick et al., 2023), limiting their potential for growth.\\nIn this work, we propose a novel learning paradigm for LLM\\nagents that focuses on learning to expand and refine the ac-\\ntion space, thereby aligning tasks more closely with the\\nagents’ planning abilities. By adapting the action space to\\nfit the LLM’s planning, we address the limitations imposed\\nby fixed action spaces, such as the misalignment between\\ncommonsense knowledge-guided planning and actions, and\\nthe prevalence of action errors due to unmet prerequisites or\\nineffective strategies(Gu et al., 2022; Ma et al., 2024; Ahn\\net al., 2022). This approach not only mitigates bottlenecks\\nin language agent performance but also allows transferring\\nexperience across different tasks.\\nFor a more illustrative view, we could look at the example\\nwhere an LLM agent is asked to make cocktails. With\\na learnable and open action space, LLMs may naturally\\ninstruct the agent to gather all the components in a specific\\norder and mix them, while the closed action space may only\\ninvolve basic handling, such as moving to different places\\nand grabbing bottles, which greatly increases the difficulty\\nof the task for LLM agent. On the other hand, it is necessary\\nto update existing actions to accommodate changing factors\\n1\\narXiv:2402.15809v1  [cs.AI]  24 Feb 2024\\nEmpowering Open Action Language Agents through Learning Actions\\nAct Agent\\nmove(\\n!\\n, \\n\"\\n)\\ncarry_two_to(\\n\"\\n, \\n!\\n,\\n#\\n,\\n#\\n)\\ncarry_to(\\n\"\\n, \\n!\\n, \\n$\\n,\\n%\\n)\\npick(\\n$\\n,\\n\"\\n,\\n%\\n)\\nDrop:  drop(\\n#\\n,\\n!\\n,\\n%\\n)\\nError: You already have a \\nball in hand, cannot pick \\nup another ball.\\nError\\nFeedback\\n[Instruction]:  You can use the following action: pick, \\nmove, drop, carry_to, carry_two_to……\\nUser\\n[History]:  Init obs: Ball1 is a ball.  Ball1 is at rooma.  Ball10 is a \\nball.  Ball10 is at rooma…… Left is a gripper.  Left is free.  Right is \\na gripper.  Right is free.  Robby is at roomb. rooma is a room. \\nroomb is a room.\\nAction: move(\\'roomb\\',\\'rooma\\')\\nObs: Ball1 is a ball.  Ball1 is at rooma ……Robby is at rooma.\\nAction: carry_to(\\'ball1\\',\\'rooma\\',\\'right\\')\\nObs: Ball1 is a ball. Ball1 is at roomb ……\\nAction: carry_to(\\'ball2\\',\\'rooma\\',\\'right’)\\nObs: Ball1 is a ball. Ball1 is at roomb. Ball2 is a ball. Ball2 \\nis at roomb……\\nTest Stage：Using Learned Actions        with \\nAct Prompting \\nTrain Stage: Create/Revise Learnable Actions \\nAssess Agent on Training Instances\\nMove:  move(\\n\"\\n,\\n!\\n)\\nAction Learner\\nCarry:  carry_to(\\n\"\\n, \\n!\\n,\\n#\\n,\\n%\\n)\\ndef carry_to(room1,room2,obj,gripper):\\n      try:\\n            move(room2,room1)\\n      except:\\n            pass\\n      pick(obj,room1,gripper)\\n      move(room1,room2)\\n      drop(obj,room2,gripper)\\nPickup:  pick(\\n#\\n,\\n\"\\n,\\n%\\n)\\nAdapted \\nPolicy Model\\nAugmented \\nAction Space\\n[Goal]: You should perform actions to accomplish the goal: \\nball1 is at roomb…ball10 is at roomb\\nFigure 1: Illustration of the training and test stage of LearnAct: Left: During the training stage, LearnAct expands the action\\nspace by first creating actions and then optimizing them based on the execution feedback. Right: The test stage uses learned\\naction space to facilitate sequential decision-making. The prompting format follows the Act (Yao et al., 2023a) agent.\\nin the environment. Still, in the cocktail example, when\\nmaking an Old Fashioned cocktail, muddling sugar is often\\nthe standard practice. However, if only syrup is available,\\nthe agent should adapt its pre-set actions to prevent repeated\\nfailures despite being competent to accomplish the task.\\nTo solve these issues, we conduct an extensive exploration of\\naction learning in LLM agents. We introduce a framework\\nLearnAct, designed to dynamically generate new action\\ntypes as APIs. The newly generated action types are in the\\nform of Python functions, leveraging the LLM’s extensive\\nprior knowledge and code generation ability to devise a\\ndiverse and representative action space. Furthermore, Lear-\\nnAct stands out due to its iterative learning strategy, which\\ncontinuously refines actions through a feedback loop. In\\neach cycle, the LLM evaluates the effectiveness of current\\nactions using training examples, identifying and rectifying\\nerrors in failed instances. The learning strategy leverages\\nexperience in environments to progressively deepen task\\nunderstanding and improve learnable actions.\\nOur experimental results demonstrate that this method of\\niterative refinement not only creates complex and user-\\nfriendly action types but also achieves more effective and\\nefficient learning compared to previous state-of-the-art meth-\\nods such as Reflexion (Shinn et al., 2023). By learning on\\na few problem instances, LearnAct can generalize to a gen-\\neral type of task with strong performance. In summary, our\\ncontributions are as follows.\\n• We propose the action learning framework by generat-\\ning and updating learnable actions based on experience,\\nenabling language agents to learn customized action\\nspace that better fits the LLM’s planning capacity.\\n• To implement the action learning framework, our\\nmethod LearnAct employs Python functions to gen-\\nerate new actions, enabling flexible definitions of ac-\\ntion types. Our iterative learning strategy incorporates\\nLLM to autonomously refine and updates the currently\\navailable actions based on errors in failed tasks.\\n• Our experimental results demonstrate that LearnAct ef-\\nfectively learns action spaces within a few trials, acquir-\\ning transferable capabilities in diverse environments.\\nThrough action learning, LearnAct outperforms SOTA\\nagents by a significant margin, showcasing the poten-\\ntial of action learning for LLM agents.\\n2. Related Work\\n2.1. LLM Agent Learning\\nRecent research has advanced the use of large language\\nmodels (LLMs) in embodied agents (Duan et al., 2022;\\nHuang et al., 2022a; Ahn et al., 2022; Huang et al., 2022b;\\nYao et al., 2023a; Park et al., 2023; Wu et al., 2023; Sun et al.,\\n2023; Ma et al., 2024). These methods differ from previous\\nreasoning-centered methods like Chain-of-Thought (Wei\\net al., 2022; Chen et al., 2022; Liang et al., 2023; Wang\\net al., 2023b) as they iteratively incorporate environment\\nfeedback to modify subsequent plans. This closed-loop\\nverification then refine process is centered on the ability of\\nLLM agents to learn from environment.\\nThe majority of previous work on multi-turn reflection con-\\ncentrates on learning from environment feedback within the\\n2\\nEmpowering Open Action Language Agents through Learning Actions\\nTable 1: The comparison of our method and other open action agents. !\\n–\\nVoyager used a curriculum learning pipeline\\ntailored for Minedojo to learn new actions.\\nClosed Loop\\nAction Type\\nLearnable\\nTransferable\\nLearnable Module\\nReAct\\n✔\\nNatural language\\n✗\\n-\\n-\\nReAct+Reflexion\\n✔\\nNatural language\\n✔\\n✗\\nPolicy\\nCodeAsPolicy\\n✗\\nCode\\n✗\\n-\\n-\\nVoyager\\n✔\\nCode\\n!\\n–\\n✔\\nAction\\nLearnAct\\n✔\\nCode\\n✔\\n✔\\nAction\\nsame problem (Lai et al., 2023; Le et al., 2022; Chen et al.,\\n2023; Liu & Abbeel, 2023; Singh et al., 2023). ReAct (Yao\\net al., 2023a) propose a basic framework for using thought\\nto enforce the LLM reflect on previous behaviors within\\nthe same trial. Reflexion (Shinn et al., 2023; Park et al.,\\n2023), on the other hand, uses a multi-trial approach to\\nperform reflection. By summarizing historical experiences\\nand identifying reasons for failure, LLM is prompted to\\ngenerate insights for more effective agent instruction. Simi-\\nlarly, ExpeL (Zhao et al., 2023) facilitates a general learning\\nsystem that extracts insights and past experiences with re-\\ntrieval. Retroformer (Yao et al., 2023b) propels introduce\\nprompt-based training to enhance LLM reflections.\\nOur method differs from this line of work in two points\\n(1) LearnAct performs direct learning in the action space,\\nwhich substantially improves the reliability and utility of\\ngenerated actions. (2) LearnAct does not target a single\\nproblem instance but learns experience from a few training\\ninstances and is tested on a general type of task. A more\\ndetailed comparison is provided in Table 1.\\n2.2. Hierarchical Reinforcement Learning\\nLearnAct generates new action types based on atomic ac-\\ntions to enable more informative and applicable actions,\\nsimilar to the approach in hierarchical reinforcement learn-\\ning (Erol et al., 1994; Kulkarni et al., 2016; Bacon et al.,\\n2017), where a high-level executor plan with high-level ac-\\ntion types, and then executes the seed actions according to\\nthe high-level plan (Yao et al., 2023a; Sharma et al., 2022;\\nWang et al., 2023a; Sun et al., 2023). Our approach also\\ndiffers from hierarchical reinforcement learning by not only\\nusing code-based action space, providing stronger capacity\\ndue to the code statements such as conditions and loops (Cai\\net al., 2023; Qian et al., 2023), but also avoiding the typi-\\ncal imposition of a strict two-level structure, using flexible\\nmixed-level actions instead.\\n3. Problem Statement\\nThe task of a language agent can be succinctly modeled as\\na Partially Observable Markov Decision Process (POMDP),\\nwhich is defined by a tuple ⟨S, O, A, T , R⟩, with S repre-\\nsenting the set of all possible states, O being the observation\\nspace through which the agent perceives the state, A denot-\\ning the action space, T : S × A → S being the state\\ntransition function, and R : S × A → {0, 1} being the\\nreward function.\\nAt step t, the language agent G takes an action step at\\nbased on policy π (policy prompt), problem E (problem\\ninstructions), and previous observation-action trajectory\\nht = [o1, a1, . . . , ot−1, at−1, ot], i.e,\\nat = G(π, E, ht)\\n(1)\\nπ, E, and ht correspond to the instruction, goal, and history\\nin Figure 1 (right), respectively. Action at is successfully\\ngrounded (executable) only if it is within the action space,\\ni.e. at ∈ A. Even successfully grounded action may be in-\\nvalid due to unmet conditions or has no effect in the current\\nstate. The agent aims to maximize the final reward r. In our\\nproblem setup, we use an outcome-based reward mechanism\\n(ORM) (Uesato et al., 2022) that assigns a binary indicator\\nas a reward signal, depending on whether the task has been\\nsuccessfully completed.\\nIn this work, we try to answer the question How to learn\\nfrom experience and apply them to other decision-making\\nproblems? We focus on the training-testing setting, where\\nfor each task, our LLM agent optimizes its action space\\nand corresponding policy on the training set Dtrain =\\n{E1, . . . , EM}, before trying to accomplish problems in the\\ntest set Dtest = {EM+1, . . . , EM+N}. These problems share\\nthe same original action spaces and rules, though requiring\\nvaried policies to solve them as they have different scenarios\\nand goals. This setting poses a challenge for the agent to\\ndevelop a general capacity through learning to accumulate\\nexperience and accomplish tasks of this general type.\\nTo address this problem, we introduce an action-learning\\nframework designed for language agents, enabling them\\nto autonomously enhance their skills by learning from in-\\nteractions within their environment, as shown in Figure 1.\\nThe framework considers the action space, denoted as A,\\nto be an open set capable of learning and expanding. More\\nspecifically, we define the original action space as A0 and\\naugment it with newly learned action type (API) A′, repre-\\nsented as A0 ∪ A′. Also, instruction for using these new\\nactions πA′ is updated to the original policy instructions π0,\\n3\\nEmpowering Open Action Language Agents through Learning Actions\\nAlgorithm 1 Training Process of LearnAct\\nInput: Training Set Dtrain = {E1, . . . , EM}, Language\\nAgent G, Learner LLM F.\\nInput: Original Actions A0, Basic Task Instruction π0\\n# Assess action space\\nfunction SolveProblem(π, E, A, G)\\nfor t = 1 to maxsteps do\\nat = G(π, E, ht)\\nExecute at, add observation or fail info to ht\\nend for\\nreturn IsSolved(E, ht)\\nend function\\n# Training Procedure\\nA1, πA1 = ActionCreation(π0, F)\\nfor i = 1 to maxiter do\\nresults = SolveProblem(π0 + πAi, Em, A0 ∪\\nAi, G), m = 1 to M\\ns1:T , a1:T , r = SelectErrorCase(results)\\nAi+1, πAi+1 = ActionLearn(Ai, s1:T , a1:T , r, F)\\nend for\\nReturn Alast, πAlast\\ni.e. the new policy is denoted as π0 + πA′. Consequently,\\nsubsequent actions by this LLM agent are characterized\\nas at = G(π0 + πA′, E, ht), at ∈ A0 ∪ A′, as depicted\\nin Figure 1 (right), where the agent is guided to generate\\nboth origin and learned actions. The details of the learning\\nalgorithm are introduced in the following section.\\n4. Method\\nThe overall pipeline of LearnAct is illustrated in Figure 1\\nand Algorithm 1. The training stage of LearnAct involves\\nfirst creating new actions and then refine them based on\\nthe error feedback on training samples. After learning the\\naction space and policy instructions in the training stage, the\\nrefined agent perform actions from the augmented action\\nspace and try to accomplish the problem step by step. The\\ntraining stage is specified in §4.1, and test stage is detailed\\nin §4.2.\\n4.1. Training Stage\\n1. Expanding Action Space by Action Creation.\\nWe\\ndevelop a set of enhanced action types, akin to an API, to\\nenable LLMs to interact with environment more seamlessly.\\nThese newly crafted action types are implemented as code\\nfunctions, thereby unlocking the potential for more intri-\\ncate logical expressions that leverage the foundational APIs\\nthrough constructs such as conditional statements (if-else),\\nloops, and assertions. ActionCreation involves two steps:\\n(1) Generating Action Function A′: Upon receiving detailed\\ninstructions and problem specifics, the LLM, denoted as F,\\nis prompted to summarize high-level actions to complete\\nthis task in the form of Python functions for agent use. The\\ndetailed prompt is in the Appendix. These functions can\\ncall multiple basic or defined actions to complete subtasks.\\nAfter generation, functions are parsed and added to the\\naction space. See detailed prompt in Appendix.\\n(2) Generating Policy Instruction πA′ for Using New Action:\\nAfter generating new action functions, we then update the\\nagent with information about their potential applications.\\nAs the basic instruction contains action descriptions and\\nusage examples, the updated policy guidance includes both\\na description of each function and a usage example.\\nFirst, the LLM F is prompted to provide a comprehensive\\ndescription of each new function. The purpose of this de-\\nscription is to offer the agent an overview of the anticipated\\noutcomes and necessary conditions, along with the input-\\noutput format of the new action. Second, the language\\nmodel generates illustrative usage examples for the new\\nfunctions. This is crucial for guiding LLM to use the new\\naction in the appropriate scenario, as indicated by previous\\nwork (Schick et al., 2023). Prompts are in Appendix.\\nWe denote this process by the ActionCreation:\\nA1, πA1 = ActionCreation(π0, F),\\n(2)\\n2. Learning Actions Based on Error Feedback\\nAfter\\ncreating the initial set of actions, there’s a possibility that\\nthese actions may have errors, misunderstand the task, over-\\nlook certain task scenarios, or possibility for misuse. To\\naddress this, we devise the training phase that allows the\\nlanguage model to learn through trial and error, as shown\\nin Figure 2. In this phase, the agent is executed in the\\ntraining instances, identifies action failures, and then itera-\\ntively updates the action set, until successfully solving all\\nthe instances with no action errors or exceeding maximum\\noptimization steps.\\nDuring the learning process, the agent first tries to solve\\nproblems in the training set with the current available ac-\\ntion space A and policy instruction πA, denoted as the\\nSolveProblem process. Then a failed problem with ac-\\ntion error is sampled with SelectErrorCase operator\\nand then the ActionLearn either fixes it by revising the\\nused action or writing note as an annotation. We present\\neach of them below:\\n(1) SolveProblem: The assessment of current policy\\nand action space is done by trying to solve problems in the\\ntraining set. We follow the simple Act(Yao et al., 2023a)\\nagent and ask the agent to solve the current problem by\\ninteracting with the environment and generating actions\\nbased on history.\\n(2) SelectErrorCase:\\nThis step identifies error-\\n4\\nEmpowering Open Action Language Agents through Learning Actions\\nLLM-\\nAgent\\nFind Failed Case\\n   Sample Best     ,         \\nEnvironment\\nAction\\nObservation\\nResults \\nRevised Samples of \\nAction Space and Policy\\nAction Learner\\nFunction \\nUpdating\\nWrite \\nNotes for \\nFunctions\\nAssess Revised Action Space  \\nTrajectory & Error Feedback\\nAction Space\\nFigure 2: During the learning stage, action usage by agent\\nand action optimization are repeatedly executed. The im-\\nproved action is evaluated on the training instances, identi-\\nfying the failed case for the subsequent learning step. Ac-\\ntions are improved through either updating the functions or\\nwriting notes. Multiple samples are produced during the\\nlearning, and upon evaluation against training instances, the\\noptimal one is selected for the next iteration.\\ninducing steps in action sequences based on the environ-\\nment’s feedback, such as invalid actions due to unmet pre-\\nconditions, ineffective actions, or errors in action names or\\nparameters. In multi-step complex actions, it evaluates each\\natomic step for error signals.\\n(3) ActionLearn: We address errors by implementing\\neither function updates or writing notes. Function updates\\nrefines the Python function to correct the misunderstanding\\nand overlooking of tasks, whereas writing notes entails en-\\nhancing the function’s description to guide the agent toward\\nmore accurate use. The two options are both available and\\nLLM F is free to choose one of them, as shown in Figure\\n3. When function updates are made, the corresponding ac-\\ntion instructions πAi are also updated later to adapt to the\\nnew actions. Although function updating is triggered for\\na specific action function, it is not restricted to modifying\\njust this single action. By accessing all action functions\\nvia prompt, LLM could choose by itself the actions to re-\\nvise and could also incorporate new actions. Consequently,\\nActionLearn can freely update the entire action space in\\neach iteration. The detailed prompt is in the Appendix.\\n3. Augment Action Learning with Sampling In prac-\\ntice, the action learner could generate low-quality actions\\nthat can greatly affect the efficiency of the overall opti-\\nmization process.\\nAlso, some action revisions may be\\nspurious. Thus to enhance the stability of the learning\\nprocess and improve the quality of each step, we sample\\nK times with ActionLearn, yielding K revised results\\n{Ak\\ni , πk\\nAi}k=1,...,K. During the learning iteration, each\\ndef pour_shot_to_shaker(shot, ingredient, \\nshaker, hand1, level1, level2):\\n     pour_shot_to_clean_shaker(shot, \\ningredient, shaker, hand1, level1, level2)\\n    clean_shot(shot, ingredient, hand1, hand2)\\n    leave(hand1, shot)\\nInstruc,on:\\nYou can take following ac=ons:\\n……\\npour_shot_to_shaker(shot, ingredient, shaker, \\nhand1, level1, level2): This ac=on pour the \\ningredient…… \\n……\\n……\\na: ﬁll_shot(\\'shot1\\',\\'ingredient3\\',\\'right\\',\\'leC\\',\\'dispenser3\\')\\no: Shot1 contains ingredient3.\\na: pour_shot_to_shaker(‘shot1’, ‘ingredient3’, ‘shaker1’, ‘right’, ‘l1’, ‘l2’)\\no: The ac=on is not valid.\\n……\\nInstruc,on:\\nYou can take following ac=ons:\\n……\\npour_shot_to_shaker(shot, ingredient, shaker, \\nhand1, level1, level2): This ac=on pour the \\ningredient…… Note that this ac=on can only be \\nused to pour ingredient into clean shaker that \\ncontains no other ingredients.\\n……\\ndef pour_shot_to_shaker(shot, ingredient, \\nshaker, hand1, level1, level2):\\n    if level1 == \\'l0\\':\\n        pour_shot_to_clean_shaker(shot, \\ningredient, shaker, hand1, level1, level2)\\n    else:\\n        pour_shot_to_used_shaker(shot, \\ningredient, shaker, hand1, level1, level2)\\n    clean_shot(shot, ingredient, hand1, hand2)\\n    leave(hand1, shot)\\nFunction Updating\\nWrite Notes for Functions\\nor\\nFigure 3: Case example of action updating and note writing.\\nThe action update addresses previous shortcomings by refin-\\ning functions for improved issue resolution. Conversely, the\\nnote writing advises agents on proper action usage. LLMs\\nhave the freedom to select from two learning options.\\naction-policy pair is evaluated on the training set, and the\\nbest one is chosen, as shown in Figure 2 and Appendix.\\nWe select the best action based on the results obtained with\\nthe agent. The score µ for a sample Ak\\ni , πk\\nAi is as follows:\\nµ = psucc + pstepacc,\\n(3)\\nHere, psucc denotes the success rate of the agent in training\\ninstances, and pstepacc refers to the ratio of successfully exe-\\ncuted actions to the total number of steps taken by the agent,\\nindicating the practicality of generated actions. Based on\\nthese selection criteria, we identify the most beneficial and\\nfeasible action sample Ai, πAi.\\n4.2. Testing Stage\\nAfter completing the learning phase, the agent possesses\\nan updated action space and refined policy instructions. In\\nthe testing phase, the agent attempts to solve problems in\\nthe same procedure as the SolveProblem process used\\nduring training. Notably, whereas most prior research (Sun\\net al., 2023; Shinn et al., 2023) has concentrated on the\\nlearning loop within a single problem instance, LearnAct is\\ndesigned to facilitate the transfer to this general type.\\n5. Experiment\\n5.1. Tasks\\nRobotic Planning (Ma et al., 2024) We conducted experi-\\nments on four challenging Robotic Planning tasks, namely\\n5\\nEmpowering Open Action Language Agents through Learning Actions\\nTable 2: Performance of LearnAct and baselines on Robotic Planning tasks.\\nGPT-3.5\\nGPT-4\\nblockworld\\ngripper\\nbarman\\ntyreworld\\nAvg.\\nblockworld\\ngripper\\nbarman\\ntyreworld\\nAvg.\\nAct\\n0.0\\n5.9\\n0.0\\n10.0\\n4.0\\n57.1\\n58.7\\n64.7\\n62.1\\n60.7\\nReAct\\n0.0\\n5.9\\n9.8\\n0.0\\n3.9\\n71.4\\n45.1\\n70.5\\n66.4\\n63.3\\nAct+Reflexion\\n0.0\\n11.8\\n4.0\\n0.0\\n3.9\\n62.1\\n58.8\\n70.6\\n37.1\\n57.2\\nReAct+Reflexion\\n4.3\\n9.9\\n11.8\\n4.3\\n7.6\\n72.2\\n57.1\\n74.4\\n63.1\\n66.7\\nCodeAsPolicy\\n0.0\\n0.0\\n1.9\\n5.0\\n1.7\\n23.6\\n41.2\\n17.6\\n29.3\\n27.9\\nVoyager\\n18.6\\n2.0\\n6.0\\n19.3\\n11.5\\n66.4\\n76.5\\n80.5\\n65.0\\n72.1\\nLearnAct\\n10.0\\n34.8\\n15.0\\n32.9\\n23.2\\n73.9\\n82.5\\n87.4\\n87.6\\n82.8\\nTable 3: Performance of LearnAct and baselines on Alfworld tasks.\\nGPT-3.5\\nGPT-4\\nPut\\nClean\\nHeat\\nCool\\nLook\\nPut 2\\nAvg.\\nPut\\nClean\\nHeat\\nCool\\nLook\\nPut 2\\nAvg.\\nAct\\n34.7\\n15.1\\n13.0\\n14.2\\n48.1\\n23.6\\n24.8\\n77.7\\n50.5\\n13.0\\n42.8\\n40.8\\n66.6\\n48.6\\nReAct\\n25.4\\n8.3\\n3.2\\n13.1\\n11.1\\n36.1\\n16.2\\n73.9\\n61.9\\n30.5\\n46.4\\n59.7\\n49.8\\n53.7\\nAct+Reflexion\\n44.5\\n22.6\\n24.9\\n26.2\\n33.6\\n11.8\\n27.3\\n71.4\\n47.5\\n6.8\\n35.1\\n80.2\\n52.4\\n48.9\\nReAct+Reflexion\\n41.4\\n11.9\\n3.2\\n7.1\\n8.9\\n39.3\\n18.6\\n61.8\\n54.0\\n39.9\\n62.9\\n57.6\\n52.3\\n54.7\\nCodeAsPolicy\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\nVoyager\\n31.5\\n27.4\\n11.7\\n7.2\\n22.6\\n9.6\\n18.3\\n84.1\\n60.8\\n27.9\\n49.7\\n68.6\\n57.1\\n58.0\\nLearnAct\\n65.1\\n36.1\\n30.3\\n42.0\\n24.1\\n16.9\\n35.8\\n85.6\\n76.2\\n53.2\\n72.0\\n64.5\\n81.5\\n72.2\\nGripper, Blockworld, Barman, and Tyreworld. We followed\\nthe environment implementation of AgentBoard (Ma et al.,\\n2024) and LLM+P (Liu et al., 2023). These tasks involve\\nlong-horizon robot planning problems, such as creating\\ncocktails based on customer orders using available ingredi-\\nents and containers, moving objects between different rooms\\nusing two grippers, or rearranging piles of blocks to achieve\\na specified target configuration. The complexity of these\\ntasks puts a significant demand on the agent’s long-term\\nplanning capabilities.\\nAlfWorld (Shridhar et al., 2020) We also test agents on Alf-\\nWorld tasks, which simulate six types of objectives within\\na household. For instance, agents are required to locate an\\napple within the house, heat it, and then place it in a target\\narea. These tasks push the agent to explore the house sys-\\ntematically, given that the complete state of the environment\\nremains unknown until the agent observes a specific loca-\\ntion. Additionally, the agent’s ability to execute the essential\\nsteps to accomplish the task is crucial.\\n5.2. Baselines\\nIn our experiment, we compare LearnAct with several\\nlanguage agent baselines.\\nOur training-testing setting\\nemphasizes learning to solve a general type of task from\\na limited number of instances, deviating from the original\\nsettings of some baseline. As a result, we re-implement the\\nbaselines in our study if necessary.\\nAct & ReAct (Yao et al., 2023a): The basic agent, Act, is\\nprompted to iteratively take actions and obtain observations\\nin the environment. Based on Act, the ReAct agent employs\\n“Think” as an additional action.\\nReflexion (Shinn et al., 2023): Reflexion is a learning\\nmethod for language agents that utilize language as a learned\\npolicy. The original Reflexion is designed for learning in-\\ndividual policies in each instance. In our study, we adapt\\nReflexion for the training-testing setting, where policies are\\ndesigned to be not instance-specific, facilitating transferabil-\\nity. Details are in the Appendix.\\nCodeAsPolicy (Liang et al., 2023): The method utilizes\\ncode to generate the entire solution for the task in an open-\\nloop way.\\nAs the method does not interact with envi-\\nronments, we only report the results of CodeAsPolicy on\\nRobotic policy tasks. This is because the ALfWorld task\\nnecessitates exploration in the environment to obtain infor-\\nmation, and CodeAsPolicy cannot generate a code solution\\nwithout access to the complete environmental information.\\nVoyager (Wang et al., 2023a): Voyager proposes functions\\nas actions to solve tasks in a closed-loop agent manner.\\nThe original Voyager is specifically designed for Minedojo\\n(Fan et al., 2022), emphasizing skill acquisition through a\\nstructured hierarchical task curriculum. For comparison, we\\nreimplement it as Wong et al. (2023), which creates skills\\nvia code with basic verification. It can be seen as an ablation\\nof our method without iterative learning.\\n5.3. Setting\\nWe test on both GPT-4 and GPT-3.5 Turbo models as the\\nLLM during testing. We employ GPT-4 throughout our\\nlearning for action creation and improvement, as well as the\\nlearning of Reflexion and Voyager. We set the temperature\\n6\\nEmpowering Open Action Language Agents through Learning Actions\\nbarman\\nblockworld\\ngripper\\ntyreworld\\nclean\\ncool\\nexamine\\nheat\\nput\\nputtwo\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\nInitial\\nLearned\\nAction Calling Rate\\nbarman\\nblockworld\\ngripper\\ntyreworld\\nclean\\ncool\\nexamine\\nheat\\nput\\nputtwo\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nInitial\\nLearned\\nAction Success Rate\\nFigure 4: The frequency of use and accuracy of learned\\nactions before and after learning. Post-learning, there is a\\nmarked increase in the action usage frequency and accuracy,\\nindicating their enhanced reliability and utility for the agent.\\nas 0.0 for consistency and reproducibility in our experiments.\\nThe sampling number in our method is set to 4. For each\\ntask, we randomly select 3 instances for the training set,\\nwith the remaining instances used for testing. We report\\ntest set results for our LearnAct and all baseline models.\\nThe primary evaluation metric was the task success rate.\\nEach experiment is conducted three times per task, and we\\npresent the average results. We ensure a fair comparison\\nby providing a single in-context example to LearnAct and\\nall baselines. CodeAsPolicy and Voyager’s action creation\\nutilize the identical code example as ours.\\n5.4. Main Results\\nWe present a comparison of LearnAct with baseline models\\nin Tables 2 and 3. LearnAct outperforms the baselines in\\nvarious tasks, utilizing both GPT-3.5 Turbo and GPT-4 as\\nbackbones. We further analyze the performance and discuss\\nthe conclusions drawn from the comparison.\\nA well-designed action space enhances the language\\nagent’s ability to plan and solve tasks. LearnAct markedly\\nsurpasses the Act baseline in performance, highlighting the\\ncrucial role of the action space. It is noteworthy that, after\\nits learning phase, LearnAct is also an Act type agent except\\nwith a developed action space. This supports our hypothesis\\nthat the limitation of language agents lies in the effective\\nintegration of the planning process with the action space,\\nand an adaptable action space can substantially unlock the\\nlatent planning capabilities of LLM. Additionally, LearnAct\\nsurpasses ReAct in both Robotic Planning and AlfWorld,\\ndemonstrating that while “Think” improves planning, it\\nsuffers from ill alignment with the action space.\\nAction learning outperforms the verbal policy learning.\\nIn the realms of Robotic Planning and AlfWorld, Lear-\\nnAct markedly outperforms both Act+Reflexion and Re-\\nAct+Reflexion. Reflexion writes policy prompts during the\\nlearning process to assist the agent in task-solving. This\\napproach does yield improvements over the Act and ReAct\\nmethods; however, these enhancements are considerably\\nless pronounced than those achieved by LearnAct, which\\nfocuses on learning within the action space. While learned\\nverbal policies and prompts can aid in enhancing the agent’s\\nplanning capabilities, possessing proficient skills is essential\\nfor the agent to fully realize its potential.\\nAction learning is important for the action quality.\\nLearnAct outperforms coding baselines such as CodeA-\\nsPolicy and Voyager. CodeAsPolicy directly generates code\\nin open loop without interacting with the environment, lead-\\ning to inferior performance compared to closed-loop agent\\nbaselines. Notably, while Voyager generates actions using\\na method similar to LearnAct, it lacks the component of\\niterative action learning. This highlights the significance of\\naction learning in achieving superior performance; without\\nthis learning phase, the created actions are constrained by\\ninsufficient understanding of the task.\\n5.5. Analysis of the Learning Process\\nLearning enhances performance through action relia-\\nbility and utility. We further analyze action utilization to\\nexplain why action learning enhances agent performance.\\nWe assess the frequency of use and accuracy at both the\\ninitial stage of learning and the post-learning. These results\\nare presented in Figure 4. It is evident that, compared to the\\ninitial action values, the actions post-learning demonstrate\\nsignificantly higher correctness, indicating their enhanced\\nreliability and utility for the agent. This is a direct conse-\\nquence of our learning method, which focuses on correcting\\nerrors encountered during usage. Additionally, it is ob-\\nservable that the rate of action usage also improves after\\nlearning. It is possible because the agent is more inclined to\\nemploy these actions upon recognizing their usefulness, i.e.,\\nobserving valid effects after calling the action.\\nTable 4: The ratio of two learning choices.\\nRobotic Planning\\nAlfworld\\nFunction Updating\\n0.86\\n0.92\\nNote Writing\\n0.14\\n0.08\\nTable 5: The average number of learned actions.\\nRobotic Planning\\nAlfWorld\\nInitial\\n3.75\\n3.44\\nAfter Learning\\n3.83\\n3.50\\nLearnAct learns action by updating functions, writing\\n7\\nEmpowering Open Action Language Agents through Learning Actions\\n1\\n2\\n3\\n4\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\nOurs\\nReAct+Reﬂexion\\nno learning\\nalfworld gpt3.5\\nIteration Steps\\nSuccess rate\\n1\\n2\\n3\\n4\\n0.4\\n0.45\\n0.5\\n0.55\\n0.6\\n0.65\\n0.7\\n0.75\\n0.8\\nOurs\\nReAct+Reﬂexion\\nno learning\\nalfworld gpt4\\nIteration Steps\\nSuccess rate\\n1\\n2\\n3\\n4\\n0\\n0.05\\n0.1\\n0.15\\n0.2\\n0.25\\n0.3\\n0.35\\n0.4\\nOurs\\nReAct+Reﬂexion\\nno learning\\nrobotic gpt3.5\\nIteration Steps\\nSuccess rate\\n1\\n2\\n3\\n4\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\nOurs\\nReAct+Reﬂexion\\nno learning\\nrobotic gpt4\\nIteration Steps\\nSuccess rate\\nFigure 5: The performance with different maximum learn-\\ning iteration steps. The performance varies with different\\nmaximum learning iteration steps. LearnAct’s performance\\nnotably improves with the application of learning, partic-\\nularly at step two. Although ReAct+Reflexion also shows\\nimprovement, its progress is less significant and stable.\\nnotes, and generating new actions. We analyze the learn-\\ning choices and learned action numbers. The strategies for\\nlearning encompass function updates and writing notes. We\\nfind that the model prefers to update functions. As shown\\nin Table 4, function updating occurs for about 90 % in the\\nlearning. This may be due to the model’s ability to cir-\\ncumvent most invalid executions through code adjustments.\\nAdditionally, the process of updating functions can lead to\\nthe creation of new functions. As shown in Table 5, the\\naverage number of actions learned ranges from 3 to 4 for\\nboth Robotic Planning and AlfWorld, and the number of\\nactions tend to increase post-learning, showing that new\\nactions could be innovated while updating existing ones.\\nThe iteration number influences the performance of the\\nmodel.\\nWe illustrate the impact of learning iterations on\\nLearnAct and ReAct+Reflexion in Figure 5. It is evident\\nthat in both AlfWorld and Robotic Planning tasks, Learn-\\nAct’s learning markedly enhances performance, achieving\\noptimal results within just two iterations. The enhancement\\nfrom our learning approach is notably more substantial than\\nthat observed with Reflexion. While ReAct+Reflexion also\\nshows performance gains, its impact is less consistent and\\ndisplays more negative effects.\\nWhy does prolonged learning with LearnAct detrimentally\\naffect performance? We observe that it cannot be avoided\\nfor agents to make mistakes, and excessive optimization for\\nthese mistakes can lead to overfitting to specific training\\ncases, and misunderstanding the task rule. See failed cases\\nin Appendix.\\n5.6. Ablation Study\\nWe conducted ablation experiments to demonstrate the sig-\\nnificance of various components in our method. First, we\\nevaluated the action format of our method, including de-\\nscriptions and usage examples of actions. The results of\\nemploying GPT-4 as the agent in Robotic Planning and Alf-\\nworld are presented in Table 6. It was observed that both\\nthe description and usage examples contribute to the perfor-\\nmance, with the usage examples having a more pronounced\\nimpact compared to the descriptions. Interestingly, we dis-\\ncovered that the usage examples are often incorrect. Despite\\nthis, they still encourage the agent to utilize the learned\\nactions. The descriptive aspect also plays a crucial role in\\nRobotic Planning tasks. This could be attributed to that the\\nactions have many pre-conditions, so the descriptions of the\\nlearned actions aid the agent in their correct usage.\\nTable 6: The ablation study on the form of actions, specifi-\\ncally the description and usage examples.\\nRobotic Planning\\nAlfworld\\nLearnAct\\n82.8\\n72.2\\nw.o. description\\n78.5\\n72.4\\nw.o. usage example\\n77.4\\n65.4\\nTable 7: The ablation study of the learning method.\\nRobotic Planning\\nAlfworld\\nLearnAct\\n82.8\\n72.2\\nsampling only\\n73.4\\n60.2\\nw.o. updating function\\n75.3\\n62.0\\nw.o. writing notes\\n80.8\\n71.5\\nw.o. sampling\\n73.2\\n62.4\\nNext, we examine the components of our learning algorithm,\\nwhich includes two types of learning: updating function\\nand writing notes, as well as sampling during the learning\\nprocess. The results are presented in Table 7. It is evident\\nthat function updating plays a crucial role in action learning,\\nand writing notes for actions further enhances performance.\\nOur observations indicate that function updating occurs\\napproximately 90% of the time during learning, suggesting\\nthat the learner predominantly opts to modify functions to\\nimprove actions rather than merely adjusting notations for\\nmore accurate action use.\\nMoreover, sampling is vital for the effectiveness of the learn-\\ning process. In the absence of sampling, the learner gen-\\nerates only a single action proposal for the next iteration,\\nwhich is highly prone to errors and can negatively impact\\noverall performance. However, note that sampling alone\\n8\\nEmpowering Open Action Language Agents through Learning Actions\\n(w.o. learning) is ineffective in learning actions as LearnAct\\ndoes, highlighting the importance of our learning algorithm.\\n6. Conclusion\\nIn conclusion, our research advances LLM agents by equip-\\nping them with the ability to learn and refine actions through\\ndirect interaction with the environment.\\nOur proposed\\nframework LearnAct demonstrates a significant improve-\\nment in agent performance by enabling open-action learning,\\nwhich aligns closely with how humans acquire and enhance\\nskills. The empirical success of our methods in Robotic\\nPlanning and Alfworld environments underscores the po-\\ntential of action learning in developing more intelligent and\\ncapable LLM agents.\\n7. Impact Statement\\nThis paper presents work whose goal is to advance the field\\nof Machine Learning. There are many potential societal\\nconsequences of our work, none of which we feel must be\\nspecifically highlighted here.\\nReferences\\nAhn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O.,\\nDavid, B., Finn, C., Fu, C., Gopalakrishnan, K., Hausman,\\nK., et al. Do as i can, not as i say: Grounding language\\nin robotic affordances. arXiv preprint arXiv:2204.01691,\\n2022.\\nBacon, P.-L., Harb, J., and Precup, D. The option-critic\\narchitecture. In Proceedings of the AAAI conference on\\nartificial intelligence, volume 31, 2017.\\nBrohan, A., Chebotar, Y., Finn, C., Hausman, K., Herzog,\\nA., Ho, D., Ibarz, J., Irpan, A., Jang, E., Julian, R., et al.\\nDo as i can, not as i say: Grounding language in robotic\\naffordances. In Conference on Robot Learning, pp. 287–\\n318. PMLR, 2023.\\nCai, T., Wang, X., Ma, T., Chen, X., and Zhou, D.\\nLarge language models as tool makers. arXiv preprint\\narXiv:2305.17126, 2023.\\nChen, W., Ma, X., Wang, X., and Cohen, W. W. Program\\nof thoughts prompting: Disentangling computation from\\nreasoning for numerical reasoning tasks, 2022.\\nChen, X., Lin, M., Sch¨arli, N., and Zhou, D. Teaching\\nlarge language models to self-debug.\\narXiv preprint\\narXiv:2304.05128, 2023.\\nDuan, J., Yu, S., Tan, H. L., Zhu, H., and Tan, C. A sur-\\nvey of embodied ai: From simulators to research tasks.\\nIEEE Transactions on Emerging Topics in Computational\\nIntelligence, 6(2):230–244, 2022.\\nErol, K., Hendler, J., and Nau, D. S. Htn planning: com-\\nplexity and expressivity. In Proceedings of the Twelfth\\nAAAI National Conference on Artificial Intelligence, pp.\\n1123–1128, 1994.\\nFan, L., Wang, G., Jiang, Y., Mandlekar, A., Yang, Y., Zhu,\\nH., Tang, A., Huang, D.-A., Zhu, Y., and Anandkumar, A.\\nMinedojo: Building open-ended embodied agents with\\ninternet-scale knowledge. Advances in Neural Informa-\\ntion Processing Systems, 35:18343–18362, 2022.\\nGu, Y., Deng, X., and Su, Y. Don’t generate, discriminate:\\nA proposal for grounding language models to real-world\\nenvironments. ArXiv preprint, abs/2212.09736, 2022.\\nURL https://arxiv.org/abs/2212.09736.\\nHuang, J., Chen, X., Mishra, S., Zheng, H. S., Yu,\\nA. W., Song, X., and Zhou, D. Large language mod-\\nels cannot self-correct reasoning yet.\\narXiv preprint\\narXiv:2310.01798, 2023.\\nHuang, W., Abbeel, P., Pathak, D., and Mordatch, I. Lan-\\nguage models as zero-shot planners:\\nExtracting ac-\\ntionable knowledge for embodied agents. In Interna-\\ntional Conference on Machine Learning, pp. 9118–9147.\\nPMLR, 2022a.\\nHuang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence,\\nP., Zeng, A., Tompson, J., Mordatch, I., Chebotar, Y.,\\nSermanet, P., Brown, N., Jackson, T., Luu, L., Levine, S.,\\nHausman, K., and Ichter, B. Inner monologue: Embod-\\nied reasoning through planning with language models,\\n2022b.\\nKulkarni, T. D., Narasimhan, K., Saeedi, A., and Tenen-\\nbaum, J. Hierarchical deep reinforcement learning: In-\\ntegrating temporal abstraction and intrinsic motivation.\\nAdvances in neural information processing systems, 29,\\n2016.\\nLai, Y., Li, C., Wang, Y., Zhang, T., Zhong, R., Zettle-\\nmoyer, L., Yih, W.-t., Fried, D., Wang, S., and Yu, T.\\nDs-1000: A natural and reliable benchmark for data sci-\\nence code generation. In International Conference on\\nMachine Learning, pp. 18319–18345. PMLR, 2023.\\nLe, H., Wang, Y., Gotmare, A. D., Savarese, S., and Hoi,\\nS. C. H. Coderl: Mastering code generation through\\npretrained models and deep reinforcement learning. Ad-\\nvances in Neural Information Processing Systems, 35:\\n21314–21328, 2022.\\nLiang, J., Huang, W., Xia, F., Xu, P., Hausman, K., Ichter, B.,\\nFlorence, P., and Zeng, A. Code as policies: Language\\nmodel programs for embodied control. In 2023 IEEE\\nInternational Conference on Robotics and Automation\\n(ICRA), pp. 9493–9500. IEEE, 2023.\\n9\\nEmpowering Open Action Language Agents through Learning Actions\\nLiu, B., Jiang, Y., Zhang, X., Liu, Q., Zhang, S., Biswas,\\nJ., and Stone, P. Llm+ p: Empowering large language\\nmodels with optimal planning proficiency. arXiv preprint\\narXiv:2304.11477, 2023.\\nLiu, H. and Abbeel, P.\\nEmergent agentic transformer\\nfrom chain of hindsight experience.\\narXiv preprint\\narXiv:2305.16554, 2023.\\nMa, C., Zhang, J., Zhu, Z., Yang, C., Yang, Y., Jin, Y.,\\nLan, Z., Kong, L., and He, J. Agentboard: An analytical\\nevaluation board of multi-turn llm agents, 2024.\\nMadaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao,\\nL., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S.,\\nYang, Y., et al. Self-refine: Iterative refinement with\\nself-feedback. arXiv preprint arXiv:2303.17651, 2023.\\nPark, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang,\\nP., and Bernstein, M. S. Generative agents: Interactive\\nsimulacra of human behavior. In Proceedings of the 36th\\nAnnual ACM Symposium on User Interface Software and\\nTechnology, pp. 1–22, 2023.\\nQian, C., Han, C., Fung, Y. R., Qin, Y., Liu, Z., and Ji, H.\\nCreator: Disentangling abstract and concrete reasonings\\nof large language models through tool creation, 2023.\\nQin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., Lin, Y.,\\nCong, X., Tang, X., Qian, B., Zhao, S., Tian, R., Xie,\\nR., Zhou, J., Gerstein, M., Li, D., Liu, Z., and Sun, M.\\nToolllm: Facilitating large language models to master\\n16000+ real-world apis, 2023.\\nSchick, T., Dwivedi-Yu, J., Dess`ı, R., Raileanu, R., Lomeli,\\nM., Zettlemoyer, L., Cancedda, N., and Scialom, T. Tool-\\nformer: Language models can teach themselves to use\\ntools, 2023.\\nSharma, P., Torralba, A., and Andreas, J. Skill induction and\\nplanning with latent language. In Proceedings of the 60th\\nAnnual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers), pp. 1713–1726,\\n2022.\\nShinn, N., Cassano, F., Gopinath, A., Narasimhan, K. R.,\\nand Yao, S. Reflexion: Language agents with verbal\\nreinforcement learning. In Thirty-seventh Conference on\\nNeural Information Processing Systems, 2023.\\nShridhar, M., Yuan, X., Cˆot´e, M.-A., Bisk, Y., Trischler,\\nA., and Hausknecht, M. Alfworld: Aligning text and\\nembodied environments for interactive learning. arXiv\\npreprint arXiv:2010.03768, 2020.\\nSingh, I., Blukis, V., Mousavian, A., Goyal, A., Xu, D.,\\nTremblay, J., Fox, D., Thomason, J., and Garg, A. Prog-\\nprompt: Generating situated robot task plans using large\\nlanguage models. In 2023 IEEE International Conference\\non Robotics and Automation (ICRA), pp. 11523–11530.\\nIEEE, 2023.\\nSong, C. H., Wu, J., Washington, C., Sadler, B. M., Chao,\\nW.-L., and Su, Y. Llm-planner: Few-shot grounded plan-\\nning for embodied agents with large language models. In\\nProceedings of the IEEE/CVF International Conference\\non Computer Vision, pp. 2998–3009, 2023.\\nSun, H., Zhuang, Y., Kong, L., Dai, B., and Zhang, C. Ada-\\nplanner: Adaptive planning from feedback with language\\nmodels, 2023.\\nUesato, J., Kushman, N., Kumar, R., Song, F., Siegel, N.,\\nWang, L., Creswell, A., Irving, G., and Higgins, I. Solv-\\ning math word problems with process-and outcome-based\\nfeedback. arXiv preprint arXiv:2211.14275, 2022.\\nWang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu,\\nY., Fan, L., and Anandkumar, A. Voyager: An open-\\nended embodied agent with large language models. arXiv\\npreprint arXiv:2305.16291, 2023a.\\nWang, H., Gonzalez-Pumariega, G., Sharma, Y., and Choud-\\nhury, S. Demo2code: From summarizing demonstrations\\nto synthesizing code via extended chain-of-thought. arXiv\\npreprint arXiv:2305.16744, 2023b.\\nWang, X., Wang, Z., Liu, J., Chen, Y., Yuan, L., Peng, H.,\\nand Ji, H. Mint: Evaluating llms in multi-turn interac-\\ntion with tools and language feedback. ArXiv preprint,\\nabs/2309.10691, 2023c. URL https://arxiv.org/\\nabs/2309.10691.\\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F.,\\nChi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought\\nprompting elicits reasoning in large language models.\\nAdvances in Neural Information Processing Systems, 35:\\n24824–24837, 2022.\\nWong, L., Mao, J., Sharma, P., Siegel, Z. S., Feng, J., Ko-\\nrneev, N., Tenenbaum, J. B., and Andreas, J. Learning\\nadaptive planning representations with natural language\\nguidance. arXiv preprint arXiv:2312.08566, 2023.\\nWu, Y., Min, S. Y., Prabhumoye, S., Bisk, Y., Salakhutdinov,\\nR., Azaria, A., Mitchell, T., and Li, Y. Spring: Gpt-4 out-\\nperforms rl algorithms by studying papers and reasoning.\\narXiv preprint arXiv:2305.15486, 2023.\\nXie, T., Zhou, F., Cheng, Z., Shi, P., Weng, L., Liu, Y., Hua,\\nT. J., Zhao, J., Liu, Q., Liu, C., et al. Openagents: An\\nopen platform for language agents in the wild. arXiv\\npreprint arXiv:2310.10634, 2023.\\nXu, Y., Su, H., Xing, C., Mi, B., Liu, Q., Shi, W., Hui, B.,\\nZhou, F., Liu, Y., Xie, T., et al. Lemur: Harmonizing\\n10\\nEmpowering Open Action Language Agents through Learning Actions\\nnatural language and code for language agents. arXiv\\npreprint arXiv:2310.06830, 2023.\\nYao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,\\nK., and Cao, Y. React: Synergizing reasoning and acting\\nin language models, 2023a.\\nYao, W., Heinecke, S., Niebles, J. C., Liu, Z., Feng, Y., Xue,\\nL., Murthy, R., Chen, Z., Zhang, J., Arpit, D., et al. Retro-\\nformer: Retrospective large language agents with policy\\ngradient optimization. arXiv preprint arXiv:2308.02151,\\n2023b.\\nZhao, A., Huang, D., Xu, Q., Lin, M., Liu, Y.-J., and Huang,\\nG. Expel: Llm agents are experiential learners. arXiv\\npreprint arXiv:2308.10144, 2023.\\n11\\nEmpowering Open Action Language Agents through Learning Actions\\nA. Appendix\\nA.1. The Action Learning with Sampling\\nAlgorithm 1 illustrates the general framework for the learning iteration. In practice, we include multi-sampling in each\\nlearning iteration, to avoid the misdirection of low-quality solutions to the whole learning. Here we give a detailed algorithm\\nof our learning method with sampling in Algorithm 2.\\nAlgorithm 2 Training Process of LearnAct with Sampling\\nInput: Training set Dtrain = {E1, . . . , EM}, LLM G.\\nInput: Original Actions A0, Basic Task Instruction π0\\nInput: Sampling Number K\\n# Training Procedure\\nAk\\ni , πk\\nAi = ActionCreation(π0), k = 1 to K\\nfor i = 1 to maxiter do\\nresultsk = SolveProblem(π0 + πk\\nAi, Em, A0 ∪ Ak\\ni , G), m = 1 to M, k = 1 to K\\n# Compute score and select the best sample\\nµk = pk\\nsucc + pk\\nstepacc, k = 1 to K\\nkbest = arg maxk µk\\nresults, πAi, Ai = resultskbest, πkbest\\nAi , Akbest\\ni\\ns1:T , a1:T , r = SelectErrorCase(results)\\nAk\\ni+1, πk\\nAi+1 = ActionLearn(Ai, s1:T , a1:T , r), k = 1 to K\\nend for\\nReturn Alast, πAlast\\nA.2. Complexity Analysis\\nThe testing stage of LearnAct follows the standard language agent setting, except that the action space is augmented with\\nmanufactury actions. The overall time complexity is thus the same as the standard Act method. As for the learning stage, the\\ntime complexity is O(MKI), where M is the training instance number, K is the sampling number, and I denotes the max\\niteration number.\\nA.3. A Bayesian View of Open-Action Learning\\nIn this subsection, we present a Bayesian perspective on our learning approach. We express the transition function T\\nand reward function R in probabilistic terms p(st+1|st, at) and p(r|s1:T ), and denote the observation as function of state\\not = o(st). The distribution of a Partially Observable Markov Decision Process trace is as follows:\\npA,πA(s1:T , a1:T ) = p(s1)\\nT −1\\nY\\nt=1\\n[πA(at|o(st))p(st+1|st, at)]πA(aT |o(sT ))\\n(4)\\nThe reward r conditioned on action space A and policy πA follows the distribution:\\np(r|A, πA) = EpA,πA(s1:T ,a1:T )p(r|s1:T )\\n(5)\\nThe objective of POMDP is to maximize the reward, which can be seen as the posterior of action space A and policy πA\\ngiven the maximum reward:\\np(A, πA|r = rmax) =\\np(A, πA)EpA,πA(s1:T ,a1:T )p(r = rmax|s1:T )\\nZrmax\\n(6)\\nwhere Zrmax = Ep(A,πA)EpA,πA(s1:T ,a1:T )p(r = rmax|s1:T ) is the normalization factor. In conventional reinforcement\\nlearning, A is predetermined and remains constant, while the model only learns πA through maximum likelihood rather\\n12\\nEmpowering Open Action Language Agents through Learning Actions\\nthan posterior estimation. This is attributed to the complexity of computing the posterior, which is due to the necessity of\\ndomain knowledge for the prior p(A, πA) and the intractable calculation of the posterior.\\nHowever, leveraging the advanced capabilities of language models, we propose employing them to estimate the posterior\\nof the action space and policy toward the open action space learning. The prior p(A, πA) can be defined as the operator\\nActionCreation, and the posterior updating can be inferred as ActionLearn.\\nA.4. Detailed Prompt\\nWe present the prompt used in our experiment here, due to space limitations of the main text.\\nWe first present the prompts for action learning. The ActionCreation process entails two phases: initially, function\\ngeneration is guided by Prompt 6, followed by the crafting of function descriptions and usage instructions, as directed by\\nPrompt 7 and 8, respectively.\\nDuring the action learning iterations, ActionLearn leverages Prompt 9 to derive results. If the LLM suggests updates to\\naction functions, descriptions and usage instructions are regenerated using the Prompt 7 and 8.\\nPrompt for Action Creation\\n{basic task instruction}\\nPlease propose several high-level steps for this task.\\nEach high-level step should be a Python function encompassing multiple (at least two) basic actions. All the values\\nused in the function should be given as input rather than fixed in the function.\\nThe provided actions are Python functions and can be executed directly, for example, ```python\\n{basic action example}\\n`\\nNo additional interfaces besides the provided actions are available. All the code should be wrapped by```python\\n```\\nHere are examples: {created action example}\\nNow please write your solution:\\nFigure 6: Prompt for action creation.\\nPrompt for Action Description Generation\\n{basic task instruction}\\nNow here are some Python function encompassing multiple basic actions to serve as high-level interface in this task.\\nPlease write interface instruction for the given Python function.\\nHere are examples:\\n{action description examples}\\nNow please write interface instruction for this high-level step {func name}:\\nFunction:\\n```python\\n13\\nEmpowering Open Action Language Agents through Learning Actions\\n{function}\\n```\\nInstruction:\\nFigure 7: Prompt for action description generation.\\nPrompt for Action Usage Example Generation\\n{basic task instruction}\\nNow, here are some Python functions encompassing multiple basic actions to serve as high-level interfaces in this\\ntask. Please complete the task with the interface following the format of the examples. {format instruction}\\nHere are examples:\\n{action usage examples}\\nNow, please complete the task using these interfaces:\\nFunction:\\n```python\\n{function}\\n```Example:\\nFigure 8: Prompt for action usage example generation.\\nPrompt for Action Learning\\n{basic task instruction}\\n{task goal}\\nThe actions provided are Python functions and can be executed directly, for example, ```python\\n{action example}\\n```\\nNo additional actions besides the provided actions are available. All the code should be wrapped by```python\\n```\\nNow here are some high-level steps to complete this task. Each high-level step is a general Python function\\nencompassing multiple (at least two) basic actions. All the values used in the function should be given as input\\nrather than fixed in the function.\\nThe high-level steps are executed but failed. Please analyze why the execution failed, and give one of the following\\nimprovement: Update, Plan. Please respond in the following format:\\nFailed reason: <>\\nImprove: <Update or Plan: [The target function]>\\nContent: <>\\nTest case: <>(This is only for Update case, not for Plan)\\nHere are examples:\\n14\\nEmpowering Open Action Language Agents through Learning Actions\\n{in context example}\\nNow please analyze this case:\\n```python\\n{actions}\\n```\\nThe agent performs this task, and the high-level action {function name} is executed last:\\n{agent trajectory}\\nBut an error is observed in the last call ({error info}). The detailed subprocess of this step is:\\n{error subprocess}\\nFailed reason:\\nFigure 9: Prompt for action learning.\\nWe then show the prompts during the testing stage, i.e. the prompt of our agent. It is the same as the basic Act agent, as\\nshown in the Prompt 10 for the Blockworld task.\\nPrompt Details for Blockworld\\nSystem Prompt\\nYou are a master in planning.\\nInstruction\\nThe domain assumes a world where there are a set of blocks that can be stacked on top of each other, an arm that can\\nhold one block at a time, and a table where blocks can be placed.\\nThe actions defined in this domain include:\\nPickup(block): allows the arm to pick up a block from the table if it is clear and the arm is empty. After the pickup\\naction, the arm will be holding the block, and the block will no longer be on the table or clear.\\nPutdown(block): allows the arm to put down a block on the table if it is holding a block. After the putdown action,\\nthe arm will be empty, and the block will be on the table and clear.\\nStack(block1,block2): allows the arm to stack a block on top of another block if the arm is holding the top block and\\nthe bottom block is clear. After the stack action, the arm will be empty, the top block will be on top of the bottom\\nblock, and the bottom block will no longer be clear.\\nUnstack(block1,block2): allows the arm to unstack a block from on top of another block if the arm is empty and the\\ntop block is clear. After the unstack action, the arm will be holding the top block, the top block will no longer be on\\ntop of the bottom block, and the bottom block will be clear.\\n{learned action instructions}\\nHere are examples:\\nGoal: The goal is to satisfy the following conditions: b1 is on b2., b2 is on b3.\\nObservation: b2 is on b3. b3 is on b1. b1 is on the table. Robot arm is empty. The b2 is clear.\\nAction: Unstack(’b2’,’b3’)\\nObservation: b3 is on b1. b1 is on the table. The b3 is clear. You are holding b2.\\nAction: Putdown(’b2’)\\nObservation: b3 is on b1. b1 is on the table. b2 is on the table. Robot arm is empty. The b2 is clear.\\nAction: Unstack(’b3’,’b1’)\\nObservation: b1 is on the table. b2 is on the table. The b1 is clear. The b2 is clear. Robot arm is empty. You are\\nholding b3.\\nAction: Putdown(’b3’)\\n15\\nEmpowering Open Action Language Agents through Learning Actions\\nObservation: b1 is on the table. b2 is on the table. b3 is on the table. Robot arm is empty. The b1 is clear. The b2 is\\nclear. The b3 is clear.\\nAction: Pickup(’b2’)\\nObservation: b1 is on the table. b2 is on the table. The b1 is clear. The b3 is clear. You are holding b2.\\nAction: Stack(’b2’,’b3’)\\nObservation: b1 is on the table. b2 is on b3. b3 is on the table. Robot arm is empty. The b1 is clear. The b2 is clear.\\nAction: Pickup(’b3’)\\nObservation: The action is not valid and therefore takes no effect. Please remember to satisfy the restriction of\\nactions.\\nAction: Pickup(’b1’)\\nObservation: b2 is on b3. b3 is on the table. The b2 is clear. You are holding b1.\\nAction: Stack(’b1’,’b2’)\\nObservation: b1 is on b2. b2 is on b3. b3 is on the table. Robot arm is empty. The b1 is clear. The goal is satisfied.\\n{usage example for learned actions}\\n{goal of testing task}\\n{history trajectory}\\nAction:\\nFigure 10: Prompt details of agent testing for task Blockworld.\\nA.5. Learned Result Case\\nWe illustrate the learned actions and corresponding instructions in Figure 11. The {learned action instructions} and {usage\\nexample for learned actions} are used in Prompt 10 to inform the agent model about how to use the learned action function.\\nLearned Result Case for Blockworld\\nlearned action function\\n1 def dismantle_stack_until(block_list, block_target):\\n2\\nfor top_block, bottom_block in zip(block_list, block_list[1:]):\\n3\\nif top_block == block_target:\\n4\\nbreak\\n5\\nUnstack(top_block, bottom_block)\\n6\\nPutdown(top_block)\\n7\\n8\\n9 def construct_stack(block_list):\\n10\\nfor top_block, bottom_block in reversed(list(zip(block_list, block_list[1:]))):\\n11\\nPickup(top_block)\\n12\\nStack(top_block, bottom_block)\\nlearned action instructions\\ndismantle stack until(block list, block target): Allows the arm to dismantle a stack of blocks one by one, stopping\\nwhen it reaches a specific target block. ‘dismantle stack until(block list, block target)‘ sequentially unstacks each\\nblock from the block list starting from the top and places it on the table until it reaches the target block. The blocks\\nin the list must be clear and stacked consecutively. If the top block from the list matches the target block, the\\nfunction ends, leaving the arm empty and the blocks dismantled on the table. For example, if blocks b3, b2, and b1\\nare clear with b3 on top of b2 and b2 on top of b1, and the arm is empty, ‘dismantle stack until([’b3’,’b2’,’b1’],\\n’b2’)‘ will unstack b3 from b2 and put b3 on the table without touching b2 or b1.\\nconstruct stack(block list): This function allows the arm to construct a stack of blocks given a list of blocks if\\nthe arm is empty and all the blocks are clear and on the table. It achieves this by iterating from the end of the list,\\n16\\nEmpowering Open Action Language Agents through Learning Actions\\npicking each block starting from the penultimate block and stacking it on the block next to it (assuming the list is\\narranged from bottom block to top block). After the execution of construct stack, all the blocks in the list will be\\nstacked on top of each other in the order they were arranged in the block list, the arm will be empty and only the\\ntop block will be clear. For example, if block1, block2, and block3 are all clear and on the table and the arm is\\nempty, calling construct stack([block1, block2, block3]) will result in block3 being stacked on block2 and block2 on\\nblock1, and the arm will be empty.\\nusage example for learned actions\\nThe goal is to satisfy the following conditions: b1 is on b2, b2 is on b3.\\nObservation: b3 is on b2, b2 is on b1, b1 is on the table. Robot arm is empty. The b3 is clear.\\nAction: dismantle stack until([’b3’,’b2’,’b1’], ’b1’)\\nObservation: b1 is on the table. b2 is on the table. b3 is on the table. Robot arm is empty. The b1 is clear. The b2 is\\nclear. The b3 is clear.\\nAction: construct stack([’b1’,’b2’,’b3’])\\nObservation: b1 is on b2. b2 is on b3, b3 is on the table. Robot arm is empty. The b1 is clear. The goal is satisfied.\\nFigure 11: Prompt details of agent testing for task Blockworld.\\nA.6. Experiment Details\\nA.6.1. BASELINES\\nWe imply baseline Reflexion for our learning-testing setting, where the testing instances are unseen during learning. Original\\nReflexion learns policy on a single instance, which can generate very detailed hints for the next turn, like “In this trial, I was\\nable to find the desklamp on desk 1, but I did not find the bowl under the desklamp. In the next trial, I will go to desk 1, turn\\non the desklamp, then look for the bowl under the desklamp on desk 1 or desk 2. If I still cannot find the bowl, I will check\\nthe shelves and drawers.” The detailed hint helps the agent perform in the same task instance, but can not transfer to different\\ninstances. We imply Reflexion to generate transferable policies based on the failed trial, such as “To accomplish the task,\\nfirst locate the object, then navigate towards the cleaning location, clean the object, and finally deposit it at the specified\\nreceptacle. Follow the action sequence: locate - navigate - clean - store. Ensure to recheck your inventory to confirm the\\nsuccess of your actions.”. The general policy can improve agent performance to some degree, as shown in Table 2 and 3.\\nA.6.2. SETTING\\nWe use language models GPT-4 and GPT-3.5 Turbo through interface openai.ChatCompletion.create via Azure platform.\\nFor all the learnable models, including LearnAct, Reflexion, and Voyager, GPT-4 serves as the learner for both GPT-4 and\\nGPT-3.5 Turbo agents. This choice is driven by the necessity for substantial model capacity to facilitate agent learning,\\naligning with original papers of baselines where learning is implied by strong language models.\\nA.6.3. CASE STUDY FOR FAILED LEARNING\\nFigure 5 demonstrates that excessive iterations can degrade performance, likely due to overfitting and misinterpretations of\\nthe learning task. Failed cases involving LearnAct and Reflexion are shown in Figure 12, in which the learner inaccurately\\ndiagnoses failure causes, resulting in misguided actions or policies that further impair performance.\\n17\\nEmpowering Open Action Language Agents through Learning Actions\\ndef find_and_take(obj, recep):\\nobservation = goto(recep)\\nobject_name = parse_object_name(obj, observation)\\nif object_name is not None:\\nobservation = take(object_name, recep)\\nreturn observation\\nError: The action is not valid. The cabinet 2 is closed.\\nUpdate:\\ndef find_and_take(obj, recep):\\nobservation = goto(recep)\\nif not any([recep.startswith(location) for \\nlocation in [\\'shelf\\', \\'countertop\\']]):\\nobservation = open(recep)\\nif \\'is open\\' in observation:\\nobject_name = parse_object_name(obj, \\nobservation)\\nif object_name is not None:\\nobservation = take(object_name, recep)\\nreturn observation\\nTo find the object I need, I should explore \\ndifferent receptacles.\\nFailed Trail. In the trial, saw a closed cabinet but do not open it.\\nReflexion:\\nBefore attempting to interact with the \\nreceptacle, ensure that it is open or \\naccessible in the first place. Validate \\nobject\\'s existence and accessibility in the \\nsaid location.\\nFigure 12: The failed cases of LearnAct (left) and Reflexion (right). The learning overfits the current task instance with\\nmisunderstanding. Left: The agent causes error when using action find and take because the action does not consider\\nthe case that the cabinet is closed. However, the learner updates action find and take by adding a conditional based on\\nthe receptacle name, which is not the correct condition to open the receptacle. Right: The agent failed in a trial in which it\\nsaw a closed cabinet but did not open it. The Reflexion learner advises the misleading policy “before attempting to interact\\nwith the receptacle, ensure that it is open or accessible in the first place”.\\n18\\n', metadata={'Published': '2024-02-24', 'Title': 'Empowering Large Language Model Agents through Action Learning', 'Authors': 'Haiteng Zhao, Chang Ma, Guoyin Wang, Jing Su, Lingpeng Kong, Jingjing Xu, Zhi-Hong Deng, Hongxia Yang', 'Summary': 'Large Language Model (LLM) Agents have recently garnered increasing interest\\nyet they are limited in their ability to learn from trial and error, a key\\nelement of intelligent behavior. In this work, we argue that the capacity to\\nlearn new actions from experience is fundamental to the advancement of learning\\nin LLM agents. While humans naturally expand their action spaces and develop\\nskills through experiential learning, LLM agents typically operate within fixed\\naction spaces, limiting their potential for growth. To address these\\nchallenges, our study explores open-action learning for language agents. We\\nintroduce a framework LearnAct with an iterative learning strategy to create\\nand improve actions in the form of Python functions. In each iteration, LLM\\nrevises and updates the currently available actions based on the errors\\nidentified in unsuccessful training tasks, thereby enhancing action\\neffectiveness. Our experimental evaluations across Robotic Planning and\\nAlfworld environments reveal that after learning on a few training task\\ninstances, our approach to open-action learning markedly improves agent\\nperformance for the type of task (by 32 percent in AlfWorld compared to\\nReAct+Reflexion, for instance) highlighting the importance of experiential\\naction learning in the development of more intelligent LLM agents.'}),\n",
       " Document(page_content='Knowledge Conflicts for LLMs: A Survey\\nRongwu Xu∗1, Zehan Qi∗1, Cunxiang Wang2, Hongru Wang3, Yue Zhang2, Wei Xu1\\n1 Tsinghua University, 2 Westlake University, 3 The Chinese University of Hong Kong\\n{xrw22, qzh23}@mails.tsinghua.edu.cn\\n{wangcunxiang, zhangyue}@westlake.edu.cn\\nhrwang@se.cuhk.edu.hk, weixu@tsinghua.edu.cn\\nAbstract\\nThis survey provides an in-depth analysis of\\nknowledge conflicts for large language models\\n(LLMs), highlighting the complex challenges\\nthey encounter when blending contextual and\\nparametric knowledge. Our focus is on three\\ncategories of knowledge conflicts: context-\\nmemory, inter-context, and intra-memory con-\\nflict. These conflicts can significantly impact\\nthe trustworthiness and performance of LLMs,\\nespecially in real-world applications where\\nnoise and misinformation are common. By cat-\\negorizing these conflicts, exploring the causes,\\nexamining the behaviors of LLMs under such\\nconflicts, and reviewing available solutions,\\nthis survey aims to shed light on strategies for\\nimproving the robustness of LLMs, thereby\\nserving as a valuable resource for advancing\\nresearch in this evolving area.\\n1\\nIntroduction\\nLarge language models (LLMs) (Brown et al.,\\n2020; Touvron et al., 2023; Achiam et al., 2024)\\nare renowned for encapsulating a vast repository\\nof world knowledge (Petroni et al., 2019; Roberts\\net al., 2020), referred to as parametric knowledge.\\nThese models excel in knowledge-intensive tasks\\nincluding QA (Petroni et al., 2019), fact-checking\\n(Gao et al., 2023a), knowledge generation (Chen\\net al., 2023c), inter alia. In the meantime, LLMs\\ncontinue to engage with external contextual knowl-\\nedge after deployed (Pan et al., 2022), including\\nuser prompts (Liu et al., 2023a), interactive dia-\\nlogues (Zhang et al., 2020), or retrieved documents\\nfrom the Web (Lewis et al., 2020; Shi et al., 2023c),\\nand tools (Schick et al., 2023; Zhuang et al., 2023).\\nIntegrating contextual knowledge into LLMs en-\\nables them to keep abreast of current events (Ka-\\nsai et al., 2022) and generate more accurate re-\\nsponses (Shuster et al., 2021), yet it risks conflict-\\ning due to the rich knowledge sources. The dis-\\ncrepancies among the contexts and the model’s\\n*The first two authors contributed equally.\\nBrazil holds the\\nrecord for the\\nmost FIFA World\\nCup wins…\\n…I think Argentina\\nhas won the most\\nchampionships.\\nItaly is the most successful national team\\nin the history of the World Cup, having\\nwon four titles (1934, 1938, 1982, 2006).\\nAs of my last update in April 2023, the\\nnational team with the most FIFA World\\nCup championships is Brazil. They have\\nwon the tournament a total of five times.\\nI. Contextual Knowledge (Context)\\nII. Parametric Knowledge (Memory)\\nRetrieved Documents\\nUser Prompt\\nDialogue\\nQuestion: Which team has won the most FIFA World Cup championships?\\n…, Germany has \\nofficially claimed\\nthe title of the\\nmost successful\\nnational team…\\nWith a staggering\\ntotal of five\\nWorld Cup \\ntriumphs, the\\nBrazilian…\\nInter-context conflict\\nIntra-memory conflict\\nContext-memory conﬂict\\nFigure 1: An LLM may encounter three distinct types\\nof knowledge conflicts, stemming from knowledge\\nsources—either contextual (I. Context, yellow chat-\\nboxes) or inherent to the LLM’s parameters (II. Memory,\\nblue chatboxes). When confronted with a user’s ques-\\ntion (purple chatbox) entailing knowledge of complex\\nconflicts, the LLM is required to resolve these discrep-\\nancies to deliver accurate responses.\\nparametric knowledge are referred to as knowledge\\nconflicts (Chen et al., 2022; Xie et al., 2023). In\\nthis paper, we categorize three distinct types of\\nknowledge conflicts, as characterized in Figure 1.\\nAs the example shown in Figure 1, when utiliz-\\ning an LLM to respond to a user question, users\\nmay provide the LLM with supplementary prompts,\\nwhile the LLM also leverages search engines to\\ngather relevant documents from the Web to en-\\nhance its knowledge (Lewis et al., 2020). This\\ncombination of user prompts, dialogue history, and\\nretrieved documents constitutes contextual knowl-\\nedge (context). Contextual knowledge can conflict\\nwith the parametric knowledge (memory) encapsu-\\nlated within the LLM’s parameters (Longpre et al.,\\n2021; Xie et al., 2023), a phenomenon we term as\\ncontext-memory conflict (CM, § 2). In real-world\\nscenarios, the external document might be fraught\\nwith noise (Zhang and Choi, 2021) or even delib-\\narXiv:2403.08319v1  [cs.CL]  13 Mar 2024\\nTemporal Misalign\\nMisinformation\\n…\\nKnowledge \\nConﬂicts\\nFaithful to Context\\n…\\nDesired Behavior\\nMay be factually incorrect\\nCauses\\nPhenomenon\\nBehaviors\\nFaithful to Memory\\nI. Causes\\nIII-i. Objective\\nII. Analysis\\ninduce\\ninduce\\nBias in Corpora\\n💥\\nIII-ii. Solu3on\\npre-hoc\\npost-hoc\\n🌟\\n⏳\\n😈\\n⚖\\n🙌\\n💭\\nFigure 2: We view knowledge conflict not only as a standalone phenomenon but also as a nexus that connects\\nvarious causal triggers (causes) with the behaviors of LLMs. While existing literature mainly focuses on II.\\nAnalysis, our survey involves systematically observing these conflicts, offering insights into their emergence and\\nimpact on LLMs’ behavior, along with the desirable behaviors and related solutions.\\nerately crafted misinformation (Du et al., 2022b;\\nPan et al., 2023a), complicating their ability to pro-\\ncess and respond accurately (Chen et al., 2022).\\nWe term the conflict among various pieces of con-\\ntextual knowledge as inter-context conflict (IC,\\n§ 3). To reduce uncertainties in responses, the user\\nmay pose the question in various forms. There-\\nfore, the LLM’s parametric knowledge may yield\\ndivergent responses to these differently phrased\\nquestions. This variance can be attributed to the\\nconflicting knowledge embedded within the LLM’s\\nparameters, which stem from the inconsistencies\\npresent in the complex and diverse pre-training data\\nsets (Huang et al., 2023). This gives rise to what\\nwe term as intra-memory conflict (IM, § 4).\\nKnowledge conflict is originally rooted in open-\\ndomain QA research. The concept gained atten-\\ntion in Longpre et al. (2021) that focused on the\\nentity-based conflicts between parametric knowl-\\nedge and external passages. Concurrently, discrep-\\nancies among multiple passages were also scruti-\\nnized subsequently (Chen et al., 2022). Knowledge\\nconflicts attract significant attention with the recent\\nadvent of LLMs. For instance, recent studies find\\nthat LLMs exhibit both adherence to parametric\\nknowledge and susceptibility to contextual influ-\\nences (Xie et al., 2023), which can be problematic\\nwhen this external knowledge is factually incor-\\nrect (Pan et al., 2023b). Given the implications for\\nthe trustworthiness (Du et al., 2022b), real-time\\naccuracy (Kasai et al., 2022), and robustness of\\nLLMs (Ying et al., 2023), it is imperative to delve\\ndeeper into understanding and resolving knowledge\\nconflicts (Xie et al., 2023; Wang et al., 2023g).\\nAs of the time of writing, to the best of our\\nknowledge, there is no systematic survey dedicated\\nto the investigation of knowledge conflicts. Ex-\\nisting reviews (Zhang et al., 2023d; Wang et al.,\\n2023a; Feng et al., 2023) touch upon knowledge\\nconflicts as a subtopic within their broader contexts.\\nWhile Feng et al. (2023) offer a more systematic\\nexamination of knowledge conflicts, categorizing\\nthem into external and internal conflicts. How-\\never, their survey provides only a brief overview\\nof relevant works and primarily focuses on specific\\nscenarios. To fill the gap, we aim to provide a com-\\nprehensive review encompassing the categorization,\\ncause and behavior analysis, and solutions for ad-\\ndressing various kinds of knowledge conflicts.\\nThe methodology of our survey is illustrated in\\nFigure 2, we conceptualize lifecycle of knowledge\\nconflicts as both a cause leading to various behav-\\niors in the model, and an effect emerges from the\\nintricate nature of knowledge. Knowledge conflicts\\nserve as a crucial intermediary between causes and\\nmodel behaviors. For instance, they significantly\\ncontribute to the model generating factually incor-\\nrect information, a.k.a., hallucinations (Ji et al.,\\n2023; Zhang et al., 2023d). Our research, in a man-\\nner akin to Freudian psychoanalysis, underscores\\nthe significance of understanding the origins of\\nthese conflicts. Although existing analyses (Chen\\net al., 2022; Xie et al., 2023; Wang et al., 2023g)\\ntend to construct such conflicts artificially, we posit\\nthat these analyses do not sufficiently address the\\ninterconnectedness of the issue.\\nGoing beyond reviewing and analyzing causes\\nand behaviors, we delve deeper to provide a sys-\\ntematic review of solutions, which are employed to\\nminimize the undesirable consequences of knowl-\\nKnowledge Conflicts\\nContext-Memory\\nConflict (§ 2)\\nCauses\\n(§ 2.1)\\nTemporal Misalignment\\nLazaridou et al. (2021), Luu et al. (2021), Jang et al. (2021),\\nJang et al. (2022), Liska et al. (2022), Dhingra et al. (2022),\\nKasai et al. (2022), Margatina et al. (2023), Cheang et al. (2023)\\nMisinformation Pollution\\nDu et al. (2022b), Pan et al. (2023a), Pan et al. (2023b),\\nXu et al. (2023), Weller et al. (2022)\\nAnalysis\\n(§ 2.2)\\nOpen-domain QA\\nLongpre et al. (2021), Chen et al. (2022), Tan et al. (2024)\\nGeneral\\nXie et al. (2023), Wang et al. (2023g), Ying et al. (2023),\\nQian et al. (2023), Xu et al. (2023), Jin et al. (2024a)\\nSolution\\n(§ 2.3)\\nFaithful to Context\\nFine-tuning\\nKAFT (Li et al., 2022a)\\n,\\nTrueTeacher (Gekhman et al., 2023)\\n,\\nK-DIAL (Xue et al., 2023)\\nPrompting\\nOPIN (Zhou et al., 2023d)\\nDecoding\\nCAD (Shi et al., 2023a)\\n,\\nKnowledge Plug-in\\nCuQA (Lee et al., 2022a)\\nPre-training\\nICLM (Shi et al., 2023b)\\nPredict Fact Validity\\nZhang and Choi (2023)\\nDiscriminating Misinformation\\n(Faithful to Memory)\\nPrompting\\nPan et al. (2023b)\\n, Xu et al. (2023)\\nQuery Augmentation\\nWeller et al. (2022)\\nTraining Discriminator\\nHong et al. (2023)\\nDisentangling Sources\\nDisentQA (Neeman et al., 2022)\\n, Wang et al. (2023g)\\nImproving Factuality\\nCOMBO (Zhang et al., 2023e)\\n, CD2 (Jin et al., 2024a)\\nInter-Context\\nConflict (§ 3)\\nCauses\\n(§ 3.1)\\nMisinformation\\nChen and Shu (2023b), Vergho et al. (2024), Chen et al. (2023b)\\nOutdated Information\\nZhang and Choi (2021), Kasai et al. (2022)\\nAnalysis\\n(§ 3.2)\\nPerformance Impact\\nChen et al. (2022), Xie et al. (2023), Pan et al. (2023a),\\nZhang and Choi (2021), Du et al. (2022b), Jin et al. (2024a)\\nDetection Ability\\nLi et al. (2023a), Zheng et al. (2022), Wan et al. (2024),\\nSolution\\n(§ 3.3)\\nEliminating Conflict\\nSpecialized Models\\nPCNN (Hsu et al., 2021)\\n, Pielka et al. (2022)\\n,\\nWu et al. (2022)\\nGeneral Models\\nLeite et al. (2023)\\n, Cheung and Lam (2023)\\n,\\nChern et al. (2023)\\nImproving Robustness\\nTraining Approach\\nHong et al. (2023)\\nQuery Augmentation\\nCAR (Weller et al., 2022)\\nIntra-Memory\\nConflict (§ 4)\\nCauses\\n(§ 4.1)\\nBias in Training Corpora\\nWang et al. (2023d), Xu et al. (2022),\\nDecoding Strategy\\nLee et al. (2022b), Huang et al. (2023)\\nKnowledge Editing\\nYao et al. (2023), Li et al. (2023f)\\nAnalysis\\n(§ 4.2)\\nSelf-Inconsistency\\nDong et al. (2023), Zhao et al. (2023b), Manakul et al. (2023),\\nDhuliawala et al. (2023), Zhang et al. (2023c), Mündler et al. (2023),\\nAgrawal et al. (2023), Hase et al. (2023)\\nLatent Representation\\nof Knowledge\\nChuang et al. (2023), Li et al. (2023c)\\nCross-lingual Inconsistency\\nWang et al. (2023e), Qi et al. (2023)\\nSolution\\n(§ 4.3)\\nImproving Consistency\\nFine-tuning\\nElazar et al. (2021)\\n, Li et al. (2023d)\\nPlug-in\\nCRM (Jang and Lukasiewicz, 2023)\\nOutput Ensemble\\nConCoRD (Mitchell et al., 2022)\\n,\\nZhao et al. (2023b)\\nImproving Factuality\\nITI (Li et al., 2023c)\\n, DoLa (Chuang et al., 2023)\\nFigure 3: Taxonomy of knowledge conflicts. We mainly list works in the era of large language models.\\ndenotes\\npre-hoc solution and\\ndenotes post-hoc solution.\\nedge conflicts, i.e., to encourage the model to ex-\\nhibit desired behaviors that conform to specific\\nobjectives (please noted that these objectives may\\ndiffer based on the particular scenario). Based on\\nthe timing relative to potential conflicts, strategies\\nare divided into two categories: pre-hoc and post-\\nhoc strategies. The key distinction between them\\nlies in whether adjustments are made before or\\nafter potential conflicts arise*. The taxonomy of\\nknowledge conflicts is outlined in Figure 3. We\\nsequentially discuss the three kinds of knowledge\\nconflicts, detailing for each the causes, analysis of\\nmodel behaviors, and available solutions organized\\naccording to their respective objectives. Related\\ndatasets can be found in Table 1.\\n*Another interpretation is that a pre-hoc strategy is proac-\\ntive while a post-hoc one is reactive.\\nDatasets\\nApproach1\\nBase2\\nSize\\nConflict\\nXie et al. (2023)\\nGen\\nPopQA (2023), STRATEGYQA ((Geva et al., 2021))\\n20,091 CM3\\nKC (2023g)\\nSub\\nN/A (LLM generated)\\n9,803\\nCM\\nKRE (2023)\\nGen\\nMuSiQue (2022), SQuAD2.0 (2018), ECQA (2021), e-CARE (2022a) 11,684\\nCM\\nFarm (2023)\\nGen\\nBoolQ (2019), NQ (2019), TruthfulQA (2022)\\n1,952\\nCM\\nTan et al. (2024)\\nGen\\nNQ (2019), TriviaQA (2017)\\n14,923\\nCM\\nWikiContradiction (2021) Hum\\nWikipedia\\n2,210\\nIC\\nClaimDiff (2022)\\nHum\\nN/A\\n2,941\\nIC\\nPan et al. (2023a)\\nGen,Sub\\nSQuAD v1.1 (2016)\\n52,189\\nIC\\nCONTRADOC (2023a)\\nGen\\nCNN-DailyMail (2015), NarrativeQA (2018), WikiText (2017)\\n449\\nIC\\nCONFLICTINGQA (2024) Gen\\nN/A\\n238\\nIC\\nPARAREL (2021)\\nHum\\nT-REx (2018)\\n328\\nIM\\n1. Approach refers to how the conflicts are crafted, including entity-level substitution (Sub), generative approaches\\nemploying an LLM (Gen), and human annotation (Hum).\\n2. Base refers to the base dataset(s) that serve as the foundation for generating conflicts, if applicable.\\n3.\\nFor CM datasets, conflicts are derived from a certain model’s parametric knowledge, which can vary between\\nmodels. Therefore, one should select a subset of the dataset that aligns with the tested model’s knowledge when using\\nCM datasets.\\nTable 1: Datasets on evaluating a large language model’s behavior when encountering knowledge conflicts. CM:\\ncontext-memory conflict, IC: inter-context conflict, IM: intra-memory conflict.\\n2\\nContext-Memory Conflict\\nContext-memory conflict emerges as the most ex-\\ntensively investigated among the three types of con-\\nflicts. LLMs are characterized by fixed paramet-\\nric knowledge, a result of the substantial pertain-\\ning process (Sharir et al., 2020; Hoffmann et al.,\\n2022; Smith, 2023). This static parametric knowl-\\nedge stands in stark contrast to the dynamic nature\\nof external information, which evolves at a rapid\\npace (De Cao et al., 2021; Kasai et al., 2022).\\n2.1\\nCauses\\nThe core of context-memory conflict stems from\\na discrepancy between the context and parametric\\nknowledge. We consider two main causes: tempo-\\nral misalignment (Lazaridou et al., 2021; Luu et al.,\\n2021; Dhingra et al., 2022) and misinformation\\npollution (Du et al., 2022b; Pan et al., 2023a).\\nTemporal Misalignment. Temporal misalignment\\nnaturally arises in models trained on data collected\\nin the past, as they may not accurately reflect con-\\ntemporary or future realities (i.e., the contextual\\nknowledge after the deployment) (Luu et al., 2021;\\nLazaridou et al., 2021; Liska et al., 2022). Such\\nmisalignment can degrade the model’s performance\\nand relevancy over time, as it may fail to capture\\nnew trends, shifts in language use, cultural changes,\\nor updates in knowledge. Researchers have noted\\nthat temporal misalignment relegates the model’s\\nperformance on various NLP tasks (Luu et al.,\\n2021; Zhang and Choi, 2021; Dhingra et al., 2022;\\nKasai et al., 2022; Cheang et al., 2023). Further-\\nmore, the issue of temporal misalignment is ex-\\npected to intensify due to the pre-training paradigm\\nand the escalating costs associated with scaling up\\nmodels (Chowdhery et al., 2023; Achiam et al.,\\n2024).\\nPrior work tries to tackle temporal misalignment\\nby focusing on three lines of strategies: Knowl-\\nedge editing (KE) aims to directly update the\\nparametric knowledge of an existing pre-trained\\nmodel (Sinitsin et al., 2020; De Cao et al., 2021;\\nMitchell et al., 2021; Onoe et al., 2023). Retrieval-\\naugmented generation (RAG) leverages a retrieval\\nmodule to fetch relevant documents from external\\nsources (e.g., database, the Web) to supplement\\nthe model’s knowledge without altering its parame-\\nters (Karpukhin et al., 2020; Guu et al., 2020; Lewis\\net al., 2020; Lazaridou et al., 2022; Borgeaud et al.,\\n2022; Peng et al., 2023; Vu et al., 2023). Continue\\nlearning (CL) seeks to update the internal knowl-\\nedge through continual pre-training on new and\\nupdated data (Lazaridou et al., 2021; Jang et al.,\\n2021, 2022). However, these methods of mitigat-\\ning temporal misalignment are not magic bullets.\\nKE can bring in side effects of knowledge conflict,\\nleading to knowledge inconsistency (i.e., a sort of\\nintra-memory conflict) and may even enhance the\\nhallucination of LLMs (Li et al., 2023f; Pinter and\\nElhadad, 2023). For RAG, it is inevitable to en-\\ncounter knowledge conflicts since the model’s pa-\\nrameters are not updated (Chen et al., 2021; Zhang\\nand Choi, 2021). CL suffers from catastrophic\\nforgetting issues and demands significant computa-\\ntional resources (De Lange et al., 2021; He et al.,\\n2021; Wang et al., 2023f).\\nMisinformation Pollution. Misinformation pol-\\nlution emerges as another contributor to context-\\nmemory conflict, particularly for time-invariant\\nknowledge (Jang et al., 2021) that the model has\\naccurately learned. Adversaries exploit this vul-\\nnerability by introducing false or misleading in-\\nformation into the Web corpus of retrieved doc-\\numents (Pan et al., 2023a,b; Weller et al., 2022)\\nand user conversations (Xu et al., 2023).\\nThe\\nlatter poses a practical threat, as adversaries can\\nleverage techniques such as prompt injection at-\\ntacks (Liu et al., 2023b; Greshake et al., 2023; Yi\\net al., 2023). This vulnerability poses a real threat,\\nas models might unknowingly propagate misinfor-\\nmation if they incorporate deceptive inputs without\\nscrutiny (Xie et al., 2023; Pan et al., 2023b; Xu\\net al., 2023).\\nResearchers observe that fabricated, malicious\\nmisinformation can markedly undermine the ac-\\ncuracy of automated fact-checking systems (Du\\net al., 2022b) and open-domain question-answering\\nmodels (Pan et al., 2023a,b). Furthermore, recent\\nstudies also highlight the model’s tendency to align\\nwith user opinions, a.k.a., sycophancy, further exac-\\nerbating the issue (Perez et al., 2022; Turpin et al.,\\n2023; Wei et al., 2023; Sharma et al., 2023). In the\\ncurrent landscape of LLMs, there is growing appre-\\nhension in the NLP community regarding the poten-\\ntial generation of misinformation by LLMs (Ayoobi\\net al., 2023; Kidd and Birhane, 2023; Carlini et al.,\\n2023; Zhou et al., 2023c; Spitale et al., 2023; Chen\\nand Shu, 2023b). Researchers acknowledge the\\nchallenges associated with detecting misinforma-\\ntion generated by LLMs (Tang et al., 2023; Chen\\nand Shu, 2023a; Jiang et al., 2023). This under-\\nscores the urgency of addressing the nuanced chal-\\nlenges posed by LLMs in the context of contextual\\nmisinformation.\\nRemarks. Temporal misalignment and mis-\\ninformation pollution are two separate scenarios\\nthat give rise to context-memory conflicts. For\\nthe former, the up-to-date contextual information\\nis considered accurate. Conversely, for the latter,\\nthe contextual information contains misinformation\\nand is therefore considered incorrect.\\n2.2\\nAnalysis of Model Behaviors\\nHow do LLMs navigate context-memory conflicts?\\nThis section will detail the relevant research, al-\\nthough they present quite different answers. De-\\npending on the scenario, we first introduce the\\nOpen-domain question answering (ODQA) setup\\nand then focus on general setups.\\nODQA. In earlier ODQA literature, Longpre et al.\\n(2021) explore how QA models act when the\\nprovided contextual information contradicts the\\nlearned information. The authors create an auto-\\nmated framework that identifies QA instances with\\nnamed entity answers, then substitutes mentions\\nof the entity in the gold document with an alter-\\nnate entity, thus creating the conflict context. This\\nstudy reveals a tendency of these models to over-\\nrely on parametric knowledge. Chen et al. (2022)\\nrevisit this setup while reporting differing obser-\\nvations, they note that models predominantly rely\\non contextual knowledge in their best-performing\\nsettings. They attribute this divergence in findings\\nto two factors. Firstly, the entity substitution ap-\\nproach used by Longpre et al. (2021) potentially\\nreduces the semantic coherence of the perturbed\\npassages. Secondly, Longpre et al. (2021) based\\ntheir research on single evidence passages, as op-\\nposed to Chen et al. (2022), who utilize multiple\\nones. Recently, with the emergence of really “large”\\nlanguage models such as ChatGPT (Ouyang et al.,\\n2022; OpenAI, 2023) and Llama 2 (Touvron et al.,\\n2023), inter alia, researchers re-examined this is-\\nsue. Tan et al. (2024) examine how LLMs blend\\nretrieved context with generated knowledge in the\\nODQA setup, and discover models tend to favor the\\nparametric knowledge, influenced by the greater re-\\nsemblance of these generated contexts to the input\\nquestions and the often incomplete nature of the\\nretrieved information, especially within the scope\\nof conflicting sources.\\nGeneral. Xie et al. (2023) leverage LLMs to gen-\\nerate conflicting context alongside the memorized\\nknowledge. They find that LLMs are highly recep-\\ntive to external evidence, even when it conflicts\\nwith their parametric, provided that the external\\nknowledge is coherent and convincing. Meanwhile,\\nthey also identify a strong confirmation bias (Nick-\\nerson, 1998) in LLMs, i.e., the models tend to favor\\ninformation consistent with their internal memory,\\neven when confronted with conflicting external evi-\\ndence. Wang et al. (2023g) posit that the desired be-\\nhaviors when an LLM encounters conflicts should\\nbe to pinpoint the conflicts and provide distinct an-\\nswers. They find while LLMs perform well in iden-\\ntifying the existence of knowledge conflicts, they\\nstruggle to determine the specific conflicting seg-\\nments and produce a response with distinct answers\\namidst conflicting information. Ying et al. (2023)\\nanalyze the robustness of LLMs under conflicts\\nwith a focus on two perspectives: factual robustness\\n(the ability to identify correct facts from prompts\\nor memory) and decision style (categorizing LLMs’\\nbehavior as intuitive, dependent, or rational-based\\non cognitive theory). The study finds that LLMs\\nare highly susceptible to misleading prompts, espe-\\ncially in the context of commonsense knowledge.\\nQian et al. (2023) evaluate the potential interaction\\nbetween parametric and external knowledge more\\nsystematically, cooperating knowledge graph (KG).\\nThey reveal that LLMs often deviate from their\\nparametric knowledge when presented with direct\\nconflicts or detailed contextual changes. Xu et al.\\n(2023) study how large language models (LLMs)\\nrespond to knowledge conflicts during interactive\\nsessions. Their findings suggest LLMs tend to fa-\\nvor logically structured knowledge, even when it\\ncontradicts factual accuracy.\\nRemarks. I. Crafting Conflicting Knowledge.\\nModel’s behavior under context-memory conflict is\\nanalyzed by artificially creating conflicting knowl-\\nedge, in early years through entity-level substitu-\\ntions and more recently by employing LLMs to\\ngenerate semantically coherent conflicts.\\nII. What is the conclusion? No definitive rule ex-\\nists for whether a model prioritizes contextual or\\nparametric knowledge. Yet, knowledge that is se-\\nmantically coherent, logical, and compelling is typ-\\nically favored by models over generic conflicting\\ninformation.\\n2.3\\nSolutions\\nSolutions are organized according to their objec-\\ntives, i.e., the desired behaviors we expect from\\nan LLM when it encounters conflicts. Existing\\nstrategies can be categorized into the following\\nobjectives: Faithful to context strategies aim to\\nalign with contextual knowledge, focusing on con-\\ntext prioritization. Discriminating misinformation\\nstrategies encourage skepticism towards dubious\\ncontext in favor of parametric knowledge. Disen-\\ntangling sources strategies treat context and knowl-\\nedge separately and provide disentangled answers.\\nImproving factuality strategies aim for an integrated\\nresponse leveraging both context and parametric\\nknowledge towards a more truthful solution.\\nFaithful to Context.\\nFine-tuning.\\nLi et al.\\n(2022a) argue that an LLM should prioritize con-\\ntext for task-relevant information and rely on in-\\nternal knowledge when the context is unrelated.\\nThey name the two properties controllability and ro-\\nbustness. They introduce Knowledge Aware Fine-\\nTuning (KAFT) to strengthen the two properties\\nby incorporating counterfactual and irrelevant con-\\ntexts to standard training datasets. Gekhman et al.\\n(2023) introduce TrueTeacher, which focuses on\\nimproving factual consistency in summarization\\nby annotating model-generated summaries with\\nLLMs. This approach helps in maintaining faith-\\nfulness to the context of the original documents,\\nensuring that generated summaries remain accu-\\nrate without being misled by irrelevant or incorrect\\ndetails. DIAL (Xue et al., 2023) focuses on im-\\nproving factual consistency in dialogue systems\\nvia direct knowledge enhancement and RLFC for\\naligning responses accurately with provided factual\\nknowledge.\\nPrompting. Zhou et al. (2023d) explores enhancing\\nLLMs’ adherence to context through specialized\\nprompting strategies, specifically opinion-based\\nprompts and counterfactual demonstrations. These\\ntechniques are shown to significantly improve\\nLLMs’ performance in context-sensitive tasks by\\nensuring they remain faithful to relevant context,\\nwithout additional training.\\nDecoding. Shi et al. (2023a) introduce Context-\\naware Decoding (CAD) to reduce hallucinations\\nby amplifying the difference in output probabilities\\nwith and without context, which is similar to the\\nconcept of contrastive decoding (Li et al., 2022c).\\nCAD enhances faithfulness in LLMs by effectively\\nprioritizing relevant context over the model’s prior\\nknowledge, especially in tasks with conflicting in-\\nformation.\\nKnowledge Plug-in. Lee et al. (2022a) propose\\nContinuously-updated QA (CuQA) for improving\\nLMs’ ability to integrate new knowledge. Their\\napproach uses plug-and-play modules to store up-\\ndated knowledge, ensuring the original model re-\\nmains unaffected. Unlike traditional continue pre-\\ntraining or fine-tuning approaches, CuQA can solve\\nknowledge conflicts.\\nPre-training. ICLM (Shi et al., 2023b) is a new\\npre-training method that extends LLMs’ ability to\\nhandle long and varied contexts across multiple\\ndocuments. This approach could potentially aid in\\nresolving knowledge conflicts by enabling models\\nto synthesize information from broader contexts,\\nthus improving their understanding and application\\nof relevant knowledge.\\nPredict Fact Validity. Zhang and Choi (2023) ad-\\ndress knowledge conflict by introducing fact du-\\nration prediction to identify and discard outdated\\nfacts in LLMs. This approach improves model\\nperformance on tasks like ODQA by ensuring ad-\\nherence to up-to-date contextual information.\\nDiscriminating Misinformation (Faithful to\\nMemory). Prompting. To address misinformation\\npollution, Pan et al. (2023b) propose defense strate-\\ngies such as misinformation detection and vigilant\\nprompting, aiming to enhance the model’s ability\\nto remain faithful to factual, parametric informa-\\ntion amidst potential misinformation. Similarly, Xu\\net al. (2023) utilize a system prompt to remind the\\nLLM to be cautious about potential misinforma-\\ntion and to verify its memorized knowledge before\\nresponding. This approach aims to enhance the\\nLLM’s ability to maintain faithfulness.\\nQuery Augmentation. Weller et al. (2022) leverage\\nthe redundancy of information in large corpora to\\ndefend misinformation pollution. Their method\\ninvolves query augmentation to find a diverse set\\nof less likely poisoned passages, coupled with a\\nconfidence method named Confidence from An-\\nswer Redundancy (CAR), which compares the pre-\\ndicted answer’s consistency across retrieved con-\\ntexts. This strategy mitigates knowledge conflicts\\nby ensuring the model’s faithfulness through the\\ncross-verification of answers in multiple sources.\\nTraining Discriminator. Hong et al. (2023) fine-\\ntune a smaller LM as a discriminator and com-\\nbine prompting techniques to develop the model’s\\nability to discriminate between reliable and unreli-\\nable information, helping the model remain faithful\\nwhen confronted with misleading context.\\nDisentangling Sources. DisentQA (Neeman et al.,\\n2022) trains a model that predicts two types of\\nanswers for a given question: one based on contex-\\ntual knowledge and one on parametric knowledge.\\nWang et al. (2023g) introduce a method to improve\\nLLMs’ handling of knowledge conflicts. Their\\napproach is a three-step process designed to help\\nLLMs detect conflicts, accurately identify the con-\\nflicting segments, and generate distinct, informed\\nresponses based on the conflicting data, aiming for\\nmore precise and nuanced model outputs.\\nImproving Factuality.\\nZhang et al. (2023e)\\npropose COMBO, a framework that pairs com-\\npatible generated and retrieved passages to re-\\nsolve discrepancies. It uses discriminators trained\\non silver labels to assess passage compatibil-\\nity, improving ODQA performance by leveraging\\nboth LLM-generated (parametric) and external re-\\ntrieved knowledge. Jin et al. (2024a) introduce\\na contrastive-decoding-based algorithm, namely\\nCD2, which maximizes the difference between var-\\nious logits under knowledge conflicts and calibrates\\nthe model’s confidence in the truthful answer.\\nRemarks. Current mitigation approaches have\\ncontradicted goals because they do not distinguish\\nbetween the two causes of knowledge conflict when\\nconsidering conflict scenarios. Blindly being “faith-\\nful” to context or knowledge is undesirable. Some\\nresearchers regard that LLM should not rely solely\\non either parametric or contextual information but\\ninstead grant LLM users the agency to make in-\\nformed decisions based on distinct answers (Wang\\net al., 2023g; Floridi, 2023).\\n3\\nInter-Context Conflict\\nInter-context conflicts manifest in LLMs when in-\\ncorporating external information sources, a chal-\\nlenge accentuated by the advent of RAG techniques.\\nRAG enriches the LLM’s responses by integrat-\\ning content from retrieved documents into the con-\\ntext. Nonetheless, this incorporation can lead to\\ninconsistencies within the provided context, as the\\nexternal documents may contain information that\\nconflicts with each other (Zhang and Choi, 2021;\\nKasai et al., 2022; Li et al., 2023a).\\n3.1\\nCauses\\nMisinformation. Misinformation has long been a\\nsignificant concern in the modern digital age (Shu\\net al., 2017; Zubiaga et al., 2018; Kumar and Shah,\\n2018; Meel and Vishwakarma, 2020; Fung et al.,\\n2022; Wang et al., 2023b). The emergence of RAG\\nintroduces a novel approach to incorporating exter-\\nnal documents to enhance the generation quality\\nof LLMs. While this method has the potential to\\nenrich content with diverse knowledge sources, it\\nalso poses the risk of including documents con-\\ntaining misinformation, such as fake news (Chen\\net al., 2023b). Moreover, there have been instances\\nwhere AI technologies have been employed to\\ncreate or propagate misinformation (Zhou et al.,\\n2023c; Vergho et al., 2024; Weidinger et al., 2021).\\nThe advanced generative capabilities of LLMs ex-\\nacerbate this issue, leading to an increase in misin-\\nformation generated by these systems. This trend is\\nconcerning, as it not only contributes to the spread\\nof false information but also challenges detecting\\nmisinformation generated by LLMs (Chen and Shu,\\n2023b; Menczer et al., 2023; Barrett et al., 2023;\\nBengio et al., 2023; Wang et al., 2023c; Solaiman\\net al., 2023; Weidinger et al., 2023; Ferrara, 2023;\\nGoldstein et al., 2023).\\nOutdated Information. In addition to the chal-\\nlenge of misinformation, it is important to recog-\\nnize that facts can evolve over time. The retrieved\\ndocuments may contain updated and outdated infor-\\nmation from the network simultaneously, leading\\nto conflicts between these documents (Chen et al.,\\n2021; Liska et al., 2022; Zhang and Choi, 2021;\\nKasai et al., 2022).\\nRemarks. Conflicts in context frequently arise\\nbetween misinformation and accurate information,\\nas well as between outdated and updated informa-\\ntion. These two conflicts exert distinct impacts\\non LLMs and require specified analysis. Distin-\\nguishing from misinformation conflicts, another\\nsignificant challenge involves addressing conflicts\\nthat arise from documents bearing different times-\\ntamps, especially when a user’s prompt specifies a\\nparticular time period.\\n3.2\\nAnalysis of Model Behaviors\\nPerformance Impact. Previous research empiri-\\ncally demonstrates that the performance of a pre-\\ntrained language model can be significantly influ-\\nenced by the presence of misinformation (Zhang\\nand Choi, 2021) or outdated information (Du et al.,\\n2022b) within a specific context. In recent stud-\\nies, Pan et al. (2023a) introduce a misinformation\\nattack strategy involving the creation of a fabri-\\ncated version of Wikipedia articles, which is subse-\\nquently inserted into the authentic Wikipedia cor-\\npus. Their research findings reveal that existing\\nlanguage models are susceptible to misinformation\\nattacks, irrespective of whether the fake articles\\nare manually crafted or generated by models. To\\ngain a deeper understanding of how LLMs behave\\nwhen encountering contradictory contexts, Chen\\net al. (2022) primarily conduct experiments using\\nFusion-in-Decoder on the NQ-Open (Kwiatkowski\\net al., 2019) and TriviaQA (Joshi et al., 2017). They\\nfind that inconsistencies across knowledge sources\\nexert a minimal effect on the confidence levels\\nof models. These models exhibit a tendency to\\nfavor context directly pertinent to the query and\\ncontext that aligns with the model’s inherent para-\\nmetric knowledge. Xie et al. (2023) conduct ex-\\nperiments on both closed-source LLMs and open-\\nsource LLMs in POPQA (Mallen et al., 2022) and\\nSTRATEGYQA (Geva et al., 2021). The results ob-\\ntained are in line with those of Chen et al. (2022),\\nindicating that LLMs exhibit a significant bias to\\nevidence that aligns with the model’s parametric\\nmemory. They also find that LLMs exhibit a predis-\\nposition towards emphasizing information related\\nto entities of higher popularity and answers that\\nare corroborated by a larger volume of documents\\nwithin the given context. Moreover, these models\\ndemonstrate a significant sensitivity to the order in\\nwhich data is introduced. Jin et al. (2024a) discover\\nthat as the number of conflicting hops increases,\\nLLMs encounter increased challenges in reasoning.\\nDetection Ability. In addition to assessing the\\nperformance of LLMs when confronted with con-\\ntradictory contexts, several studies also investi-\\ngate their capacity to identify such contradictions.\\nZheng et al. (2022) examine the performance of\\nvarious models including BERT, RoBERTa, and\\nERNIE in detecting the contradiction within Chi-\\nnese conversations. Their experimental findings\\nreveal that identifying contradictory statements\\nwithin a conversation is a significant challenge for\\nthese models. Li et al. (2023a) analyse the perfor-\\nmance of GPT-4, ChatGPT, PaLM-2, and Llama 2\\nin identifying contradictory documents within news\\narticles (Hermann et al., 2015), stories (Koˇciský\\net al., 2018), and wikipedia (Merity et al., 2017).\\nThe authors find that the average detection accu-\\nracy is subpar. The study also finds that LLMs\\nface specific challenges when addressing certain\\ntypes of contradictions, particularly those involving\\nsubjective emotions or perspectives. Additionally,\\nthe length of documents and the variety of self-\\ncontradictions have a minor influence on the de-\\ntection performance. Wan et al. (2024) investigate\\nthe text features that affect LLMs’ assessment of\\ndocument credibility when faced with conflicting\\ninformation. They discover that existing models\\nheavily prioritize the relevance of a document to\\nthe query but often overlook stylistic features that\\nhumans consider important, such as the presence\\nof scientific references or a neutral tone in the text.\\nJin et al. (2024a) discover that LLMs encounter dif-\\nficulty in distinguishing truthful information from\\nmisinformation. In addition, they find that LLMs\\nfavor evidence that appears most frequently within\\nthe context, and demonstrate confirmation bias for\\nexternal information aligning with their internal\\nmemory.\\nRemarks. When encountering conflict within\\na given context, the exhibited knowledge of the\\nLLMs is significantly influenced. However, deter-\\nmining how the model responds to various con-\\ntextual nuances remains an area requiring further\\nexploration. While different models may share cer-\\ntain commonalities, disparities in behavior arise\\ndue to variations in their training data. Moreover,\\nas the model’s knowledge is totally derived from\\ntextual information, its approach to discerning mis-\\ninformation differs significantly from that of hu-\\nmans.\\n3.3\\nSolutions\\nEliminating Conflict. Specialized Models. Hsu\\net al. (2021) develop a model named Pairwise\\nContradiction Neural Network (PCNN), leveraging\\nfine-tuned Sentence-BERT embeddings to calcu-\\nlate contradiction probabilities of articles. Pielka\\net al. (2022) suggest incorporating linguistic knowl-\\nedge into the learning process based on the discov-\\nery that XLM-RoBERTa struggles to effectively\\ngrasp the syntactic and semantic features that are\\nvital for accurate contradiction detection. Wu et al.\\n(2022) propose an innovative approach that inte-\\ngrates topological representations of text into lan-\\nguage models to enhance the contradiction detec-\\ntion ability and evaluated their methods on the\\nMultiNLI dataset (Williams et al., 2018).\\nGeneral Models. Chern et al. (2023) propose a fact-\\nchecking framework that integrates LLMs with\\nvarious tools, including Google Search, Google\\nScholar, code interpreters, and Python, for detect-\\ning factual errors in texts. Leite et al. (2023) em-\\nploy LLMs to generate weak labels associated with\\npredefined credibility signals for the input text and\\naggregate these labels through weak supervision\\ntechniques to make predictions regarding the verac-\\nity of the input.\\nImproving Robustness. Training Approach. Hong\\net al. (2023) present a novel fine-tuning method that\\ninvolves training a discriminator and a decoder si-\\nmultaneously using a shared encoder. Additionally,\\nthe authors introduce two other strategies to im-\\nprove the robustness of the model including prompt-\\ning GPT-3 to identify perturbed documents before\\ngenerating responses and integrating the discrim-\\ninator’s output into the prompt for GPT-3. Their\\nexperimental results indicate that the fine-tuning\\nmethod yields the most promising results.\\nQuery Augmentation. Weller et al. (2022) explore a\\nquery augmentation technique that prompts GPT-3\\nto formulate new questions derived from the orig-\\ninal inquiry. They then assess the confidence for\\neach question’s answer by referencing the corre-\\nsponding passages retrieved. Based on the con-\\nfidence, they decide whether to rely on the origi-\\nnal question’s prediction or aggregate predictions\\nfrom the augmented questions with high confidence\\nscores.\\nRemarks. Currently, strategies for addressing\\ninter-context conflicts primarily involve relying on\\nmodel knowledge or leveraging external knowl-\\nedge such as retrieved documents. Moreover, aug-\\nmenting LLM capabilities with external tools has\\nemerged as a novel paradigm. Exploring the use of\\nexternal tools to support LLMs in resolving inter-\\ncontext conflicts is a promising approach. In addi-\\ntion, devising a unified and efficient approach to\\nhandle various conflict types remains a formidable\\nchallenge.\\n4\\nIntra-Memory Conflict\\nWith the development of LLMs, LLMs are widely\\nused in knowledge-intensive question-and-answer\\nsystems (Gao et al., 2023b; Yu et al., 2022; Petroni\\net al., 2019; Chen et al., 2023c). A critical aspect\\nof deploying LLMs effectively involves ensuring\\nthat they produce consistent outputs across var-\\nious expressions that share similar meanings or\\nintentions. Despite this necessity, a notable chal-\\nlenge arises with intra-memory conflict—a con-\\ndition where LLMs exhibit unpredictable behav-\\niors and generate differing responses to inputs that\\nare semantically equivalent but syntactically dis-\\ntinct (Chang and Bergen, 2023; Chen et al., 2023a;\\nRaj et al., 2023; Rabinovich et al., 2023; Raj et al.,\\n2022; Bartsch et al., 2023). Intra-memory conflict\\nessentially undermines the reliability and utility of\\nLLMs by introducing a degree of uncertainty in\\ntheir output.\\n4.1\\nCauses\\nIntra-memory conflicts within LLMs can be at-\\ntributed to three primary factors: training corpus\\nbias (Wang et al., 2023d; Xu et al., 2022), decoding\\nstrategies Lee et al. (2022b); Huang et al. (2023),\\nand knowledge editing (Yao et al., 2023; Li et al.,\\n2023f). These factors respectively pertain to the\\ntraining phase, the inference phase, and subsequent\\nknowledge refinement.\\nBias in Training Corpora.\\nRecent research\\ndemonstrates that the primary phase for knowledge\\nacquisition in LLMs predominantly occurs in the\\npre-training stage (Zhou et al., 2023a; Kaddour\\net al., 2023; Naveed et al., 2023; Akyürek et al.,\\n2022; Singhal et al., 2022). Pre-training corpus is\\nprimarily crawled from the internet, which exhibits\\na diverse range of data quality, potentially includ-\\ning inaccurate or misleading information (Bender\\net al., 2021; Weidinger et al., 2021). When LLMs\\nare trained on data containing incorrect knowl-\\nedge, they may memorize and inadvertently am-\\nplify these inaccuracies (Lin et al., 2022; Elazar\\net al., 2022; Lam et al., 2022; Grosse et al., 2023),\\nleading to a situation where conflicting knowledge\\ncoexists within the parameters of LLMs.\\nMoreover, prior works indicate that LLMs tend\\nto encode superficial associations prevalent within\\ntheir training data, as opposed to genuinely com-\\nprehending the underlying knowledge contained\\ntherein (Li et al., 2022b; Kang and Choi, 2023;\\nZhao et al., 2023a; Kandpal et al., 2023). It can\\nresult in LLMs displaying a propensity to generate\\npredetermined responses rooted in spurious corre-\\nlations of training data. Due to the dependency on\\nspurious correlations, LLMs may provide divergent\\nanswers when presented with prompts exhibiting\\ndistinct syntactic structures but conveying equiva-\\nlent semantic meaning.\\nDecoding Strategy. The direct output of LLMs\\nis a probability distribution over potential next to-\\nkens. Sampling is a crucial step in determining the\\ngenerated content from this distribution. Various\\nsampling techniques, including greedy sampling,\\ntop-p sampling, top-k sampling, and others have\\nbeen proposed (Jawahar et al., 2020; Massarelli\\net al., 2020), broadly categorizing into determin-\\nistic and stochastic sampling methods. Stochastic\\nsampling stands as the prevailing decoding strat-\\negy employed by LLMs (Fan et al., 2018; Holtz-\\nman et al., 2020). However, the random nature of\\nstochastic sampling methods introduces uncertainty\\ninto the generated content. Moreover, due to the\\nintrinsic left-to-right generation pattern inherent\\nto LLMs, the selection of the sampling token can\\nwield a significant influence over the subsequent\\ngenerations. The use of stochastic sampling may\\ncause LLMs to produce entirely different content,\\neven when provided with the same context, causing\\nintra-memory conflict (Lee et al., 2022b; Huang\\net al., 2023; Dziri et al., 2021).\\nKnowledge Editing. With the exponential increase\\nof model parameters, fine-tuning LLMs become\\nincreasingly challenging and resource-intensive.\\nIn response to this challenge, researchers explore\\nknowledge editing techniques as a means of ef-\\nficiently modify a small scope of the knowledge\\nencoded in LLMs (Meng et al., 2022; Ilharco et al.,\\n2022; Zhong et al., 2023). Ensuring the consistency\\nof modifications poses a significant challenge. Due\\nto the potential limitations inherent in the editing\\nmethod, the modified knowledge cannot be general-\\nized effectively. This can result in LLMs producing\\ninconsistent responses when dealing with the same\\npiece of knowledge in varying situations (Li et al.,\\n2023f; Yao et al., 2023). Intra-memory conflict is\\nprimarily considered a side effect in the context of\\nknowledge editing.\\nRemarks. Intra-memory conflicts in LLMs\\narise from three distinct causes that occur at dif-\\nferent stages. Among these causes, training cor-\\npus bias stands out as the fundamental catalyst for\\nthese conflicts. Incongruities of knowledge in the\\ntraining dataset result in inconsistencies within the\\nknowledge encoded within the model’s parame-\\nters. Additionally, the decoding strategy indirectly\\ncontributes to exacerbating these conflicts. The\\ninherent randomness of the sampling process dur-\\ning inference amplifies the inconsistencies in the\\nmodel’s responses. Knowledge editing, which aims\\nto post-update the model’s knowledge, can inad-\\nvertently introduce conflicting information into the\\nLLM’s memory.\\n4.2\\nAnalysis of Model Behaviors\\nSelf-Inconsistency. Elazar et al. (2021) develop a\\nmethod for assessing the knowledge consistency of\\nlanguage models, focusing specifically on knowl-\\nedge triples. The authors primarily conduct ex-\\nperiments using BERT, RoBERTa, and ALBERT.\\nTheir findings indicate that these models exhibit\\npoor consistency, with accuracy rates barely rang-\\ning from 50% to 60%. Hase et al. (2023) employ\\nthe same indicators of Elazar et al. (2021), but they\\nutilize a more diverse dataset. Their study also re-\\nveals that the consistency of RoBERTa-base and\\nBART-base within the paraphrase context is lack-\\ning. Zhao et al. (2023b) reformulate questions and\\nthen assess the consistency of the LLM’s responses\\nto these reformulated questions. The findings of\\ntheir research reveal that even GPT-4 exhibits a\\nnotable inconsistency rate of 13% when applied to\\nCommonsense Question-Answering tasks. They\\nfurther find that LLMs are more likely to produce\\ninconsistencies in the face of uncommon knowl-\\nedge. Dong et al. (2023) conduct experiments on\\nmultiple open-source LLMs and find that all of\\nthese models exhibit strong inconsistencies. Li\\net al. (2023d) explore an additional aspect of in-\\nconsistency that LLMs can give an initial answer\\nto a question, but it may subsequently deny the\\nprevious answer when asked if it is correct. The au-\\nthors conduct experiments focusing on Close-Book\\nQuestion Answering and reveal that Alpaca-30B\\nonly displays consistency in 50% of cases.\\nTo further analyze the inconsistency exhibited\\nby LLMs, a study conducted by Li et al. (2022b)\\nreveals that encoder-based models tend to gener-\\nate mis-factual words more relying on positionally\\nclose and highly co-occurring words, rather than\\nknowledge-dependent words. This phenomenon\\narises due to these models’ tendency to overlearn\\ninappropriate associations from the training dataset.\\nKang and Choi (2023) highlight a co-occurrence\\nbias in LLMs, where the models favor frequently\\nco-occurring words over correct answers. espe-\\ncially when recalling facts where the subject and\\nobject rarely co-occur in the pre-training dataset,\\ndespite fine-tuning. Furthermore, their research in-\\ndicates that LLMs face challenges in recalling facts\\nin cases where the subject and object rarely appear\\ntogether in the pre-training dataset, even though\\nthese facts are encountered during fine-tuning.\\nLatent Representation of Knowledge. The multi-\\nlayer transformer architecture inherent to contem-\\nporary LLMs fosters a complex inter-memory con-\\nflict, with distinct knowledge representations scat-\\ntered across various layers. Previous research sug-\\ngests that LLMs store low-level information at shal-\\nlower levels and semantic information at deeper\\nlevels (Tenney et al., 2019; Rogers et al., 2020;\\nWang et al., 2019; Jawahar et al., 2019; Cui et al.,\\n2020). Chuang et al. (2023) explore this aspect\\nwithin the context of LLMs and discover that the\\nfactual knowledge in LLMs is typically concen-\\ntrated within specific transformer layers and differ-\\nent layers of inconsistent knowledge. Moreover,\\nLi et al. (2023c) discover that the correct knowl-\\nedge is indeed stored within the parameters of the\\nmodel, but it may not be accurately expressed dur-\\ning the generation process. The authors conduct\\ntwo experiments on the same LLM, one focused\\non the generation accuracy, and the other utilizing\\na knowledge probe to examine the knowledge con-\\ntainment. The results of these experiments reveal a\\nsubstantial 40% disparity between the knowledge\\nprobe accuracy and the generation accuracy.\\nCross-lingual Inconsistency.\\nThe universality\\nof true knowledge transcends surface form vari-\\nations (Ohmer et al., 2023), a principle that should\\nideally apply to LLMs. However, LLMs main-\\ntain distinct knowledge sets for different languages,\\nleading to inconsistencies (Ji et al., 2023). Wang\\net al. (2023e) investigate the challenges LLMs face\\nin extending edited knowledge across languages,\\nsuggesting that knowledge related to different lan-\\nguages is stored separately within the model pa-\\nrameters. Qi et al. (2023) propose a metric named\\nRankC for evaluating the cross-lingual consistency\\nof LLMs’ factual knowledge. They employ this\\nmetric for analyzing multiple models and reveal a\\npronounced language dependence in the knowledge\\nstored by LLMs, with no observed improvement\\nin cross-lingual consistency with increased model\\nsize.\\nRemarks. The phenomenon of inter-memory\\nconflict in LLMs predominantly manifests through\\ninconsistent responses to semantically identical\\nqueries. This inconsistency is primarily attributed\\nto the suboptimal quality of datasets utilized during\\nthe pre-training phase. Addressing this challenge\\nnecessitates the development of efficient and cost-\\neffective solutions, which remains a significant hur-\\ndle. Additionally, LLMs are characterized by the\\npresence of multiple knowledge circuits, which sig-\\nnificantly influence their response mechanisms to\\nspecific inquiries. The exploration and detailed ex-\\namination of these knowledge circuits within LLMs\\nrepresent a promising avenue for future research.\\n4.3\\nSolutions\\n4.3.1\\nImproving Consistency\\nFine-tuning. Elazar et al. (2021) propose a consis-\\ntency loss function and train the language model\\nwith the combination of the consistency loss and\\nstandard MLM loss. Li et al. (2023d) utilize one\\nlanguage model in dual capacities: as a generator to\\nproduce responses and as a validator to evaluate the\\naccuracy of these responses. The process involves\\nquerying the generator for a response, which is sub-\\nsequently assessed by the validator for accuracy.\\nOnly those pairs of responses deemed consistent\\nare retained. This subset of consistent pairs is then\\nused to fine-tune the model, aiming to increase the\\ngeneration likelihood of consistent response pairs.\\nPlug-in. Jang and Lukasiewicz (2023) leverage\\nthe technique of intermediate training, utilizing\\nword-definition pairs from dictionaries to retrain\\nlanguage models and improve their comprehension\\nof symbolic meanings. Subsequently, they propose\\nan efficient parameter integration approach, which\\namalgamates these enhanced parameters with those\\nof existing language models. This method aims to\\nrectify the models’ inconsistent behavior by bol-\\nstering their capacity to understand meanings.\\nOutput Ensemble. Mitchell et al. (2022) propose a\\nmethod to mitigate the inconsistency of language\\nmodels by leveraging a two-model architecture, in-\\nvolving the utilization of a base model responsible\\nfor generating a set of potential answers, followed\\nby a relation model that evaluates the logical co-\\nherence among these answers. The final answer is\\nselected by considering both the base model’s and\\nthe relation model’s beliefs. Zhao et al. (2023b) in-\\ntroduce a method to detect whether a question may\\ncause inconsistency for LLMs. Specifically, they\\nfirst use LLMs to rephrase the original question and\\nobtain corresponding answers. They then cluster\\nthese answers and examine the divergence. The\\ndetection is determined based on the divergence\\nlevel.\\n4.3.2\\nImproving Factuality\\nChuang et al. (2023) propose a novel contrastive\\ndecoding approach named DoLa. Specifically, the\\nauthors develop a dynamic layer selection strat-\\negy, choosing the appropriate premature layers and\\nmature layers. The next word’s output probabil-\\nity is then determined by computing the differ-\\nence in log probabilities of the premature layers\\nand the mature layers. Li et al. (2023c) propose\\na similar method named ITI. They first identify\\na sparse set of attention heads that exhibit high\\nlinear probing accuracy for truthfulness, as mea-\\nsured by TruthfulQA (Lin et al., 2022). During\\nthe inference phase, ITI shifts activations along\\nthe truth-correlated direction, which is obtained\\nthrough knowledge probing. This intervention is\\nrepeated autoregressively for every token during\\ncompletion. Both DoLa and ITI address the incon-\\nsistency of knowledge across the model’s different\\nlayers to reduce factual errors in LLMs.\\nRemarks. The resolution of inter-memory con-\\nflict in LLMs typically entails three phases: train-\\ning, generation, and post-hoc processing. The train-\\ning phase method mainly focuses on mitigating\\ninternal inconsistencies among model parameters.\\nConversely, the generation and post-hoc phases\\nprimarily involve algorithmic interventions aimed\\nat alleviating occurrences of inconsistent model\\nbehavior. Nevertheless, the challenge persists in\\naddressing the inconsistency of parameter knowl-\\nedge without detrimentally impacting the overall\\nperformance of LLMs.\\n5\\nChallenges and Future Directions\\nIn this section, we provide a summary and highlight\\nthe existing challenges in ongoing research, as well\\nas outline potential future directions in the field of\\nknowledge conflict.\\nKnowledge Conflicts in the Wild. Currently, the\\ncreation of knowledge conflicts predominantly re-\\nlies on the artificial generation of incorrect or mis-\\nleading information. In the real world, one of the\\nmost common situations where knowledge con-\\nflicts arise is in RALMs (Retrieval-Augmented Lan-\\nguage Models), where conflicts are present in doc-\\numents retrieved by the retrieval module directly\\nfrom the Web. Current analysis approaches exist\\na gap in the experimental setup of knowledge con-\\nflict, suggesting that findings from those environ-\\nments (Xie et al., 2023; Wang et al., 2023g) might\\nnot easily transfer to practical applications. Recent\\nstudies have begun to investigate the scenario in the\\nwild by curating conflicting documents based on\\nactual search results from Google for open-ended\\nquestions (Wan et al., 2024). Looking ahead, there\\nis a growing interest in more research that assesses\\nhow well LLMs perform in real-world scenarios\\nrather than artificially created conflicts, to better\\nunderstand their capabilities.\\nSolution at a Finer Resolution. Currently, there\\nis no one-size-fits-all solution to knowledge con-\\nflict due to its inherent complexity. Existing ei-\\nther assume a prior (Shi et al., 2023b) or focus on\\na subclass of conflict (Wang et al., 2023g). We\\nbelieve that addressing this issue requires a more\\nfine-grained approach, taking into account several\\nfactors. Firstly, the nature of the user’s query plays\\na crucial role. Subjective or debatable questions\\nnaturally lead to conflicts as they may have multi-\\nple valid answers (Bjerva et al., 2020; Wan et al.,\\n2024). Secondly, the source of conflicting informa-\\ntion can vary, including misinformation, outdated\\nfacts, or partially correct data (Uscinski and Butler,\\n2013; Guo et al., 2022). Lastly, it is also important\\nto consider user expectations, such as whether they\\nprefer a single definitive answer from the LLM or\\nare open to multiple perspectives (Floridi, 2023).\\nGiven these considerations, future solutions to mit-\\nigate knowledge conflicts must delve into these\\nnuances, recognizing that knowledge conflict en-\\ncompasses a spectrum of problems with diverse\\ncauses, manifestations, and potential resolutions.\\nCollaboration between NLP and HCI researchers is\\nappreciated for conducting thorough investigations\\nand developing effective solutions.\\nEvaluation on Downstream Tasks. The current\\nlandscape of research into knowledge conflicts\\nwithin LLMs predominantly emphasizes evaluat-\\ning their performance on common QA datasets in-\\ncluding NQ-Open, TriviaQA, OPQA, and STRAT-\\nEGYQA. This focus overlooks the broader implica-\\ntions of knowledge conflicts, particularly how they\\ninfluence downstream tasks. Exploring the effects\\nof knowledge conflicts on a wider range of appli-\\ncations beyond QA problems could yield insights\\ninto creating more robust and reliable models. For\\ninstance, in tasks requiring high levels of accu-\\nracy and consistency, such as legal document anal-\\nysis (Shui et al., 2023; Martin et al., 2024), medi-\\ncal diagnosis (Zhou et al., 2023b; Thirunavukarasu\\net al., 2023), financial analysis (Zhang et al., 2023a;\\nLi et al., 2023e) and educational tools (Caines et al.,\\n2023; Milano et al., 2023), the presence of unre-\\nsolved knowledge conflicts could undermine the\\nmodel’s utility.\\nInterplay among the Conflicts. Current research\\nin the knowledge conflict of LLMs primarily con-\\ncentrates on investigating conflicts of a singular\\ntype (Wang et al., 2023g; Chen et al., 2022; Li\\net al., 2023d) or a joint study of inter-context and\\ncontext-memory conflict (Jin et al., 2024a; Xie\\net al., 2023). However, there is a notable dearth of\\nresearch on the interaction between intra-memory\\nconflict and the other two types of conflicts. Several\\npapers have proposed the existence of knowledge\\ncircuits in LLMs (Chughtai et al., 2024; Huang\\net al., 2023), which are closely related to intra-\\nmemory conflict. Addressing this gap is crucial\\nfor understanding the relationship between the in-\\nternal knowledge inconsistency of the model and\\nits behavior in response to the context. Moreover,\\nexploring the synergistic effects of various con-\\nflict types could unveil underlying mechanisms of\\nknowledge representation and processing in LLMs\\nand help us to develop more robust and accurate\\nLLMs in practice.\\nExplainability. Most recent work analyzed LLMs’\\nbehaviors amidst knowledge conflicts at the out-\\nput level (Xie et al., 2023; Wang et al., 2023g).\\nWhile some studies have observed and explored\\nthe model’s confidence in its output, i.e., logits (Xu\\net al., 2023; Jin et al., 2024a), there has been less\\nfocus on the internal mechanism of the model, like\\nspecific attention heads or neuron activations dur-\\ning conflicts. This gap highlights a need for more\\nmicroscopic examinations to better comprehend\\nhow models decide when encounter conflicts. A\\nrecent study conducted by Jin et al. (2024b) ad-\\nvances this by investigating the interpretability of\\nLLMs through information flow analysis, pinpoint-\\ning pivotal points for conflict mitigation. They\\ndiscover there are some attention heads with oppo-\\nsite effects in the later layers, where memory heads\\ncan recall knowledge from internal memory, and\\ncontext heads can retrieve knowledge from the ex-\\nternal context. Inspired by this, a novel technique\\nnamed Pruning Head via Path Patching (PH3) is\\nintroduced to resolve conflicts efficiently without\\nupdating model parameters.\\nMultilinguality.\\nTo date, research on knowl-\\nedge conflict has primarily focused on the En-\\nglish language. Future studies could expand in\\ntwo directions. Firstly, by examining LLMs to ad-\\ndress knowledge conflicts in non-English prompts,\\nleveraging the many advanced non-English mod-\\nels available (e.g., GLM (Zeng et al., 2022) for\\nChinese) or LLMs with multilingual capability\\n(e.g., GPT-4 (Achiam et al., 2024)) and noting dif-\\nferences from English to account for unique lan-\\nguage characteristics. Secondly, addressing inter-\\ncontext conflict where multiple documents in dif-\\nferent languages might be retrieved, potentially in-\\nvolving cross-language knowledge conflicts. So-\\nlutions could include employing translation sys-\\ntems (Dementieva and Panchenko, 2021) or, for\\nlow-resource languages, leveraging high-resource\\nlanguage evidence or employing knowledge distil-\\nlation techniques.\\nMultimodality. Current research on knowledge\\nconflicts has mainly focused on single text modal-\\nity, leaving the study of these conflicts in multi-\\nmodal contexts as a promising area for future ex-\\nploration. As LLMs evolve to process informa-\\ntion across various formats—text, images (Alayrac\\net al., 2022; Li et al., 2023b), video (Ju et al., 2022;\\nZhang et al., 2023b), audio and speech (Borsos\\net al., 2023; Wu et al., 2023)—the potential for con-\\nflicts escalates in growing complexity. For instance,\\ntextual documents might clash with visual data, or\\nthe tone of an audio clip might contradict the con-\\ntent of an accompanying caption. Future research\\non multimodal knowledge conflicts could focus on\\ncrafting advanced LLMs skilled in cross-modal rea-\\nsoning and conflict resolution across diverse data\\ntypes. This effort necessitates the enhancement\\nof models’ capabilities to navigate the complex\\ndynamics between different modalities and the de-\\nvelopment of targeted datasets for effective training\\nand evaluation. Additionally, exploring how users\\nperceive and manage multimodal conflicts, such as\\ndiscrepancies between text and images, will offer\\nvaluable insights into improving LLMs for better\\nhuman interaction.\\n6\\nConclusion\\nThrough this survey, we have extensively investi-\\ngated knowledge conflicts, shedding light on their\\ncategorization, causes, how LLMs respond to these\\nconflicts, and possible solutions. Our findings re-\\nveal that knowledge conflict is a multifaceted is-\\nsue, with a model’s behavior being closely tied to\\nthe particular type of conflicting knowledge. Be-\\nsides, there appears to be a more complex interplay\\namong the three types of conflicts. Furthermore,\\nwe observe that existing solutions primarily ad-\\ndress artificially constructed scenarios, neglecting\\nthe subtleties of conflicts by relying on assumed\\npriors and thus sacrificing granularity and breadth.\\nGiven the growing use of retrieval-augmented lan-\\nguage models (RALMs), we anticipate that knowl-\\nedge conflicts faced by LLMs will only increase in\\ncomplexity, underscoring the need for more com-\\nprehensive research in this area.\\nLimitations\\nConsidering the rapid expansion of research in the\\nfield of knowledge conflict and the abundance of\\nscholarly literature, it is possible that we might\\nhave missed some of the most recent or less rele-\\nvant findings. Nevertheless, we have ensured the\\ninclusion of all essential materials in our survey.\\nEthics Statement\\nNo ethical considerations were necessary for this\\nsurvey.\\nReferences\\nOpenAI: Josh Achiam, Steven Adler, Sandhini Agarwal,\\nLama Ahmad, Ilge Akkaya, Florencia Leoni Ale-\\nman, Diogo Almeida, Janko Altenschmidt, Sam Alt-\\nman, Shyamal Anadkat, Red Avila, Igor Babuschkin,\\nSuchir Balaji, Valerie Balcom, Paul Baltescu, Haim-\\ning Bao, Mohammad Bavarian, Jeff Belgum, Ir-\\nwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro,\\nChristopher Berner, Lenny Bogdonoff, Oleg Boiko,\\nMadelaine Boyd, Anna-Luisa Brakman, Greg Brock-\\nman, Tim Brooks, Miles Brundage, Kevin Button,\\nTrevor Cai, Rosie Campbell, Andrew Cann, Brittany\\nCarey, Chelsea Carlson, Rory Carmichael, Brooke\\nChan, Che Chang, Fotis Chantzis, Derek Chen, Sully\\nChen, Ruby Chen, Jason Chen, Mark Chen, Ben\\nChess, Chester Cho, Casey Chu, Hyung Won Chung,\\nDave Cummings, Jeremiah Currier, Yunxing Dai,\\nCory Decareaux, Thomas Degry, Noah Deutsch,\\nDamien Deville, Arka Dhar, David Dohan, Steve\\nDowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti,\\nTyna Eloundou, David Farhi, Liam Fedus, Niko Felix,\\nSimón Posada Fishman, Juston Forte, Isabella Ful-\\nford, Leo Gao, Elie Georges, Christian Gibson, Vik\\nGoel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-\\nLopes, Jonathan Gordon, Morgan Grafstein, Scott\\nGray, Ryan Greene, Joshua Gross, Shixiang Shane\\nGu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris,\\nYuchen He, Mike Heaton, Johannes Heidecke, Chris\\nHesse, Alan Hickey, Wade Hickey, Peter Hoeschele,\\nBrandon Houghton, Kenny Hsu, Shengli Hu, Xin\\nHu, Joost Huizinga, Shantanu Jain, Shawn Jain,\\nJoanne Jang, Angela Jiang, Roger Jiang, Haozhun\\nJin, Denny Jin, Shino Jomoto, Billie Jonn, Hee-\\nwoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Ka-\\nmali, Ingmar Kanitscheider, Nitish Shirish Keskar,\\nTabarak Khan, Logan Kilpatrick, Jong Wook Kim,\\nChristina Kim, Yongjik Kim, Jan Hendrik Kirch-\\nner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,\\nŁukasz Kondraciuk, Andrew Kondrich, Aris Kon-\\nstantinidis, Kyle Kosic, Gretchen Krueger, Vishal\\nKuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan\\nLeike, Jade Leung, Daniel Levy, Chak Ming Li,\\nRachel Lim, Molly Lin, Stephanie Lin, Mateusz\\nLitwin, Theresa Lopez, Ryan Lowe, Patricia Lue,\\nAnna Makanju, Kim Malfacini, Sam Manning, Todor\\nMarkov, Yaniv Markovski, Bianca Martin, Katie\\nMayer, Andrew Mayne, Bob McGrew, Scott Mayer\\nMcKinney, Christine McLeavey, Paul McMillan,\\nJake McNeil, David Medina, Aalok Mehta, Jacob\\nMenick, Luke Metz, Andrey Mishchenko, Pamela\\nMishkin, Vinnie Monaco, Evan Morikawa, Daniel\\nMossing, Tong Mu, Mira Murati, Oleg Murk, David\\nMély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak,\\nArvind Neelakantan, Richard Ngo, Hyeonwoo Noh,\\nLong Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex\\nPaino, Joe Palermo, Ashley Pantuliano, Giambat-\\ntista Parascandolo, Joel Parish, Emy Parparita, Alex\\nPassos, Mikhail Pavlov, Andrew Peng, Adam Perel-\\nman, Filipe de Avila Belbute Peres, Michael Petrov,\\nHenrique Ponde de Oliveira Pinto, Michael, Poko-\\nrny, Michelle Pokrass, Vitchyr H. Pong, Tolly Pow-\\nell, Alethea Power, Boris Power, Elizabeth Proehl,\\nRaul Puri, Alec Radford, Jack Rae, Aditya Ramesh,\\nCameron Raymond, Francis Real, Kendra Rimbach,\\nCarl Ross, Bob Rotsted, Henri Roussez, Nick Ry-\\nder, Mario Saltarelli, Ted Sanders, Shibani Santurkar,\\nGirish Sastry, Heather Schmidt, David Schnurr, John\\nSchulman, Daniel Selsam, Kyla Sheppard, Toki\\nSherbakov, Jessica Shieh, Sarah Shoker, Pranav\\nShyam, Szymon Sidor, Eric Sigler, Maddie Simens,\\nJordan Sitkin, Katarina Slama, Ian Sohl, Benjamin\\nSokolowsky, Yang Song, Natalie Staudacher, Fe-\\nlipe Petroski Such, Natalie Summers, Ilya Sutskever,\\nJie Tang, Nikolas Tezak, Madeleine B. Thompson,\\nPhil Tillet, Amin Tootoonchian, Elizabeth Tseng,\\nPreston Tuggle, Nick Turley, Jerry Tworek, Juan Fe-\\nlipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya,\\nChelsea Voss, Carroll Wainwright, Justin Jay Wang,\\nAlvin Wang, Ben Wang, Jonathan Ward, Jason Wei,\\nCJ Weinmann, Akila Welihinda, Peter Welinder, Ji-\\nayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner,\\nClemens Winter, Samuel Wolrich, Hannah Wong,\\nLauren Workman, Sherwin Wu, Jeff Wu, Michael\\nWu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim-\\ning Yuan, Wojciech Zaremba, Rowan Zellers, Chong\\nZhang, Marvin Zhang, Shengjia Zhao, Tianhao\\nZheng, Juntang Zhuang, William Zhuk, and Barret\\nZoph. 2024. Gpt-4 technical report.\\nShourya Aggarwal, Divyanshu Mandowara, Vishwa-\\njeet Agrawal, Dinesh Khandelwal, Parag Singla, and\\nDinesh Garg. 2021.\\nExplanations for Common-\\nsenseQA: New Dataset and Models. In Proceedings\\nof the 59th Annual Meeting of the Association for\\nComputational Linguistics and the 11th International\\nJoint Conference on Natural Language Processing\\n(Volume 1: Long Papers), pages 3050–3065, Online.\\nAssociation for Computational Linguistics.\\nAyush Agrawal, Lester Mackey, and Adam Tauman\\nKalai. 2023.\\nDo language models know when\\nthey’re hallucinating references?\\nArXiv preprint,\\nabs/2305.18248.\\nEkin Akyürek, Tolga Bolukbasi, Frederick Liu, Bin-\\nbin Xiong, Ian Tenney, Jacob Andreas, and Kelvin\\nGuu. 2022. Towards tracing knowledge in language\\nmodels back to the training data. In Findings of the\\nAssociation for Computational Linguistics: EMNLP\\n2022, pages 2429–2446.\\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc,\\nAntoine Miech, Iain Barr, Yana Hasson, Karel\\nLenc, Arthur Mensch, Katherine Millican, Malcolm\\nReynolds, et al. 2022. Flamingo: a visual language\\nmodel for few-shot learning. Advances in neural\\ninformation processing systems, 35:23716–23736.\\nNavid Ayoobi, Sadat Shahriar, and Arjun Mukherjee.\\n2023. The looming threat of fake and llm-generated\\nlinkedin profiles: Challenges and opportunities for\\ndetection and prevention. In Proceedings of the 34th\\nACM Conference on Hypertext and Social Media,\\npages 1–10.\\nClark Barrett, Brad Boyd, Elie Bursztein, Nicholas Car-\\nlini, Brad Chen, Jihye Choi, Amrita Roy Chowdhury,\\nMihai Christodorescu, Anupam Datta, Soheil Feizi,\\net al. 2023. Identifying and mitigating the security\\nrisks of generative ai. Foundations and Trends® in\\nPrivacy and Security, 6(1):1–52.\\nHenning Bartsch, Ole Jorgensen, Domenic Rosati, Jason\\nHoelscher-Obermaier, and Jacob Pfau. 2023. Self-\\nconsistency of large language models under ambigu-\\nity. ArXiv preprint, abs/2310.13439.\\nEmily M Bender, Timnit Gebru, Angelina McMillan-\\nMajor, and Shmargaret Shmitchell. 2021. On the\\ndangers of stochastic parrots: Can language models\\nbe too big? In Proceedings of the 2021 ACM confer-\\nence on fairness, accountability, and transparency,\\npages 610–623.\\nYoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn\\nSong, Pieter Abbeel, Yuval Noah Harari, Ya-Qin\\nZhang, Lan Xue, Shai Shalev-Shwartz, Gillian Had-\\nfield, et al. 2023. Managing ai risks in an era of rapid\\nprogress. ArXiv preprint, abs/2310.17688.\\nJohannes Bjerva, Nikita Bhutani, Behzad Golshan,\\nWang-Chiew Tan, and Isabelle Augenstein. 2020.\\nSubjQA: A Dataset for Subjectivity and Review Com-\\nprehension. In Proceedings of the 2020 Conference\\non Empirical Methods in Natural Language Process-\\ning (EMNLP), pages 5480–5494, Online. Association\\nfor Computational Linguistics.\\nSebastian Borgeaud, Arthur Mensch, Jordan Hoff-\\nmann, Trevor Cai, Eliza Rutherford, Katie Milli-\\ncan, George Bm Van Den Driessche, Jean-Baptiste\\nLespiau, Bogdan Damoc, Aidan Clark, et al. 2022.\\nImproving language models by retrieving from tril-\\nlions of tokens. In International conference on ma-\\nchine learning, pages 2206–2240. PMLR.\\nZalán Borsos, Raphaël Marinier, Damien Vincent,\\nEugene Kharitonov, Olivier Pietquin, Matt Shar-\\nifi, Dominik Roblek, Olivier Teboul, David Grang-\\nier, Marco Tagliasacchi, et al. 2023. Audiolm: a\\nlanguage modeling approach to audio generation.\\nIEEE/ACM Transactions on Audio, Speech, and Lan-\\nguage Processing.\\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\\nGretchen Krueger, Tom Henighan, Rewon Child,\\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\\nClemens Winter, Christopher Hesse, Mark Chen, Eric\\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\\nJack Clark, Christopher Berner, Sam McCandlish,\\nAlec Radford, Ilya Sutskever, and Dario Amodei.\\n2020. Language models are few-shot learners. In Ad-\\nvances in Neural Information Processing Systems 33:\\nAnnual Conference on Neural Information Process-\\ning Systems 2020, NeurIPS 2020, December 6-12,\\n2020, virtual.\\nAndrew Caines, Luca Benedetto, Shiva Taslimipoor,\\nChristopher Davis, Yuan Gao, Oeistein Andersen,\\nZheng Yuan, Mark Elliott, Russell Moore, Christo-\\npher Bryant, et al. 2023. On the application of large\\nlanguage models for language teaching and assess-\\nment technology. ArXiv preprint, abs/2307.08393.\\nNicholas Carlini, Matthew Jagielski, Christopher A\\nChoquette-Choo, Daniel Paleka, Will Pearce, Hyrum\\nAnderson, Andreas Terzis, Kurt Thomas, and Florian\\nTramèr. 2023. Poisoning web-scale training datasets\\nis practical. ArXiv preprint, abs/2302.10149.\\nTyler A Chang and Benjamin K Bergen. 2023. Lan-\\nguage model behavior: A comprehensive survey.\\nArXiv preprint, abs/2303.11504.\\nChi Cheang, Hou Chan, Derek Wong, Xuebo Liu, Zhao-\\ncong Li, Yanming Sun, Shudong Liu, and Lidia Chao.\\n2023. Can lms generalize to future data? an empiri-\\ncal analysis on text summarization. In Proceedings\\nof the 2023 Conference on Empirical Methods in\\nNatural Language Processing, pages 16205–16217.\\nCanyu Chen and Kai Shu. 2023a. Can llm-generated\\nmisinformation be detected? In NeurIPS 2023 Work-\\nshop on Instruction Tuning and Instruction Follow-\\ning.\\nCanyu Chen and Kai Shu. 2023b. Combating misinfor-\\nmation in the age of llms: Opportunities and chal-\\nlenges. ArXiv preprint, abs/2311.05656.\\nHung-Ting Chen, Michael JQ Zhang, and Eunsol Choi.\\n2022. Rich knowledge sources bring complex knowl-\\nedge conflicts: Recalibrating models to reflect con-\\nflicting evidence. ArXiv preprint, abs/2210.13701.\\nJiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei\\nLi, and Yanghua Xiao. 2023a. Say what you mean!\\nlarge language models speak too positively about\\nnegative commonsense knowledge. ArXiv preprint,\\nabs/2305.05976.\\nJiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.\\n2023b.\\nBenchmarking large language models in\\nretrieval-augmented generation.\\nArXiv preprint,\\nabs/2309.01431.\\nLiang Chen, Yang Deng, Yatao Bian, Zeyu Qin, Bingzhe\\nWu, Tat-Seng Chua, and Kam-Fai Wong. 2023c. Be-\\nyond factuality: A comprehensive evaluation of large\\nlanguage models as knowledge generators. In Pro-\\nceedings of the 2023 Conference on Empirical Meth-\\nods in Natural Language Processing, pages 6325–\\n6341.\\nWenhu Chen, Xinyi Wang, and William Yang Wang.\\n2021. A dataset for answering time-sensitive ques-\\ntions. ArXiv preprint, abs/2108.06314.\\nI Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua\\nFeng, Chunting Zhou, Junxian He, Graham Neubig,\\nPengfei Liu, et al. 2023. Factool: Factuality detec-\\ntion in generative ai–a tool augmented framework\\nfor multi-task and multi-domain scenarios. ArXiv\\npreprint, abs/2307.13528.\\nTsun-Hin Cheung and Kin-Man Lam. 2023. Factllama:\\nOptimizing instruction-following language models\\nwith external knowledge for automated fact-checking.\\nIn 2023 Asia Pacific Signal and Information Pro-\\ncessing Association Annual Summit and Conference\\n(APSIPA ASC), pages 846–853. IEEE.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\\nBarham, Hyung Won Chung, Charles Sutton, Sebas-\\ntian Gehrmann, et al. 2023. Palm: Scaling language\\nmodeling with pathways. Journal of Machine Learn-\\ning Research, 24(240):1–113.\\nYung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon\\nKim, James Glass, and Pengcheng He. 2023. Dola:\\nDecoding by contrasting layers improves factual-\\nity in large language models.\\nArXiv preprint,\\nabs/2309.03883.\\nBilal Chughtai, Alan Cooney, and Neel Nanda. 2024.\\nSumming up the facts:\\nAdditive mechanisms\\nbehind factual recall in llms.\\nArXiv preprint,\\nabs/2402.07321.\\nChristopher Clark, Kenton Lee, Ming-Wei Chang,\\nTom Kwiatkowski, Michael Collins, and Kristina\\nToutanova. 2019. BoolQ: Exploring the surprising\\ndifficulty of natural yes/no questions. In Proceedings\\nof the 2019 Conference of the North American Chap-\\nter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and\\nShort Papers), pages 2924–2936, Minneapolis, Min-\\nnesota. Association for Computational Linguistics.\\nLeyang Cui, Sijie Cheng, Yu Wu, and Yue Zhang. 2020.\\nDoes bert solve commonsense task via commonsense\\nknowledge. ArXiv preprint, abs/2008.03945.\\nNicola De Cao, Wilker Aziz, and Ivan Titov. 2021. Edit-\\ning factual knowledge in language models. In Pro-\\nceedings of the 2021 Conference on Empirical Meth-\\nods in Natural Language Processing, pages 6491–\\n6506.\\nMatthias De Lange, Rahaf Aljundi, Marc Masana, Sarah\\nParisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh,\\nand Tinne Tuytelaars. 2021. A continual learning sur-\\nvey: Defying forgetting in classification tasks. IEEE\\ntransactions on pattern analysis and machine intelli-\\ngence, 44(7):3366–3385.\\nDaryna Dementieva and Alexander Panchenko. 2021.\\nCross-lingual evidence improves monolingual fake\\nnews detection. In Proceedings of the 59th Annual\\nMeeting of the Association for Computational Lin-\\nguistics and the 11th International Joint Conference\\non Natural Language Processing: Student Research\\nWorkshop, pages 310–320, Online. Association for\\nComputational Linguistics.\\nBhuwan Dhingra, Jeremy R Cole, Julian Martin\\nEisenschlos, Daniel Gillick, Jacob Eisenstein, and\\nWilliam W Cohen. 2022. Time-aware language mod-\\nels as temporal knowledge bases. Transactions of the\\nAssociation for Computational Linguistics, 10:257–\\n273.\\nShehzaad Dhuliawala, Mojtaba Komeili, Jing Xu,\\nRoberta Raileanu, Xian Li, Asli Celikyilmaz, and Ja-\\nson Weston. 2023. Chain-of-verification reduces hal-\\nlucination in large language models. ArXiv preprint,\\nabs/2309.11495.\\nQingxiu Dong, Jingjing Xu, Lingpeng Kong, Zhifang\\nSui, and Lei Li. 2023. Statistical knowledge assess-\\nment for large language models. In Thirty-seventh\\nConference on Neural Information Processing Sys-\\ntems.\\nLi Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin.\\n2022a. e-care: a new dataset for exploring explain-\\nable causal reasoning. In Proceedings of the 60th\\nAnnual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers), pages 432–446.\\nYibing Du, Antoine Bosselut, and Christopher D Man-\\nning. 2022b. Synthetic disinformation attacks on\\nautomated fact verification systems. In Proceedings\\nof the AAAI Conference on Artificial Intelligence,\\nvolume 36, pages 10581–10589.\\nNouha Dziri, Andrea Madotto, Osmar Zaiane, and\\nAvishek Joey Bose. 2021. Neural path hunter: Re-\\nducing hallucination in dialogue systems via path\\ngrounding. ArXiv preprint, abs/2104.08455.\\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Amir\\nFeder, Abhilasha Ravichander, Marius Mosbach,\\nYonatan Belinkov, Hinrich Schütze, and Yoav Gold-\\nberg. 2022. Measuring causal effects of data statis-\\ntics on language model’sfactual’predictions. ArXiv\\npreprint, abs/2207.14251.\\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhi-\\nlasha Ravichander, Eduard Hovy, Hinrich Schütze,\\nand Yoav Goldberg. 2021. Measuring and improving\\nconsistency in pretrained language models. Transac-\\ntions of the Association for Computational Linguis-\\ntics, 9:1012–1031.\\nHady Elsahar, Pavlos Vougiouklis, Arslen Remaci,\\nChristophe Gravier, Jonathon Hare, Frederique Lafor-\\nest, and Elena Simperl. 2018. T-REx: A large scale\\nalignment of natural language with knowledge base\\ntriples. In Proceedings of the Eleventh International\\nConference on Language Resources and Evaluation\\n(LREC 2018), Miyazaki, Japan. European Language\\nResources Association (ELRA).\\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018.\\nHierarchical neural story generation. In Proceedings\\nof the 56th Annual Meeting of the Association for\\nComputational Linguistics (Volume 1: Long Papers),\\npages 889–898, Melbourne, Australia. Association\\nfor Computational Linguistics.\\nZhangyin Feng, Weitao Ma, Weijiang Yu, Lei Huang,\\nHaotian Wang, Qianglong Chen, Weihua Peng, Xi-\\naocheng Feng, Bing Qin, et al. 2023. Trends in inte-\\ngration of knowledge and large language models: A\\nsurvey and taxonomy of methods, benchmarks, and\\napplications. ArXiv preprint, abs/2311.05876.\\nEmilio Ferrara. 2023. Genai against humanity: Ne-\\nfarious applications of generative artificial intelli-\\ngence and large language models. ArXiv preprint,\\nabs/2310.00737.\\nLuciano Floridi. 2023.\\nAi as agency without intel-\\nligence: on chatgpt, large language models, and\\nother generative models. Philosophy & Technology,\\n36(1):15.\\nYi R Fung, Kung-Hsiang Huang, Preslav Nakov, and\\nHeng Ji. 2022. The battlefront of combating misinfor-\\nmation and coping with media bias. In Proceedings\\nof the 28th ACM SIGKDD Conference on Knowledge\\nDiscovery and Data Mining, pages 4790–4791.\\nLuyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony\\nChen, Arun Tejasvi Chaganty, Yicheng Fan, Vin-\\ncent Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan,\\net al. 2023a. Rarr: Researching and revising what\\nlanguage models say, using language models. In\\nProceedings of the 61st Annual Meeting of the As-\\nsociation for Computational Linguistics (Volume 1:\\nLong Papers), pages 16477–16508.\\nYunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,\\nJinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen\\nWang. 2023b. Retrieval-augmented generation for\\nlarge language models: A survey. ArXiv preprint,\\nabs/2312.10997.\\nZorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen\\nElkind, and Idan Szpektor. 2023. Trueteacher: Learn-\\ning factual consistency evaluation with large lan-\\nguage models. ArXiv preprint, abs/2305.11171.\\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,\\nDan Roth, and Jonathan Berant. 2021. Did aristotle\\nuse a laptop? a question answering benchmark with\\nimplicit reasoning strategies. Transactions of the\\nAssociation for Computational Linguistics, 9:346–\\n361.\\nJosh A Goldstein, Girish Sastry, Micah Musser, Re-\\nnee DiResta, Matthew Gentzel, and Katerina Sedova.\\n2023. Generative language models and automated\\ninfluence operations: Emerging threats and potential\\nmitigations. ArXiv preprint, abs/2301.04246.\\nKai Greshake, Sahar Abdelnabi, Shailesh Mishra,\\nChristoph Endres, Thorsten Holz, and Mario Fritz.\\n2023. More than you’ve asked for: A comprehen-\\nsive analysis of novel prompt injection threats to\\napplication-integrated large language models. arXiv\\ne-prints, pages arXiv–2302.\\nRoger Grosse, Juhan Bae, Cem Anil, Nelson Elhage,\\nAlex Tamkin, Amirhossein Tajdini, Benoit Steiner,\\nDustin Li, Esin Durmus, Ethan Perez, et al. 2023.\\nStudying large language model generalization with\\ninfluence functions. ArXiv preprint, abs/2308.03296.\\nZhijiang Guo, Michael Schlichtkrull, and Andreas Vla-\\nchos. 2022. A survey on automated fact-checking.\\nTransactions of the Association for Computational\\nLinguistics, 10:178–206.\\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\\nand Ming-Wei Chang. 2020. Retrieval augmented\\nlanguage model pre-training. In Proceedings of the\\n37th International Conference on Machine Learning,\\nICML 2020, 13-18 July 2020, Virtual Event, volume\\n119 of Proceedings of Machine Learning Research,\\npages 3929–3938. PMLR.\\nPeter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zor-\\nnitsa Kozareva, Veselin Stoyanov, Mohit Bansal, and\\nSrinivasan Iyer. 2023. Methods for measuring, up-\\ndating, and visualizing factual beliefs in language\\nmodels. In Proceedings of the 17th Conference of\\nthe European Chapter of the Association for Compu-\\ntational Linguistics, pages 2706–2723.\\nTianxing He, Jun Liu, Kyunghyun Cho, Myle Ott, Bing\\nLiu, James Glass, and Fuchun Peng. 2021. Analyzing\\nthe forgetting problem in pretrain-finetuning of open-\\ndomain dialogue response models. In Proceedings\\nof the 16th Conference of the European Chapter of\\nthe Association for Computational Linguistics: Main\\nVolume, pages 1121–1133, Online. Association for\\nComputational Linguistics.\\nKarl Moritz Hermann, Tomás Kociský, Edward Grefen-\\nstette, Lasse Espeholt, Will Kay, Mustafa Suleyman,\\nand Phil Blunsom. 2015. Teaching machines to read\\nand comprehend. In Advances in Neural Information\\nProcessing Systems 28: Annual Conference on Neu-\\nral Information Processing Systems 2015, December\\n7-12, 2015, Montreal, Quebec, Canada, pages 1693–\\n1701.\\nJordan Hoffmann, Sebastian Borgeaud, Arthur Men-\\nsch, Elena Buchatskaya, Trevor Cai, Eliza Ruther-\\nford, Diego de Las Casas, Lisa Anne Hendricks,\\nJohannes Welbl, Aidan Clark, et al. 2022. Train-\\ning compute-optimal large language models. ArXiv\\npreprint, abs/2203.15556.\\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\\nYejin Choi. 2020. The curious case of neural text\\ndegeneration. In 8th International Conference on\\nLearning Representations, ICLR 2020, Addis Ababa,\\nEthiopia, April 26-30, 2020. OpenReview.net.\\nGiwon Hong, Jeonghwan Kim, Junmo Kang, Sung-\\nHyon Myaeng, and Joyce Jiyoung Whang. 2023. Dis-\\ncern and answer: Mitigating the impact of misinfor-\\nmation in retrieval-augmented models with discrimi-\\nnators. ArXiv preprint, abs/2305.01579.\\nCheng Hsu, Cheng-Te Li, Diego Saez-Trumper, and Yi-\\nZhan Hsu. 2021. Wikicontradiction: Detecting self-\\ncontradiction articles on wikipedia. In 2021 IEEE\\nInternational Conference on Big Data (Big Data),\\npages 427–436. IEEE.\\nLei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong,\\nZhangyin Feng, Haotian Wang, Qianglong Chen,\\nWeihua Peng, Xiaocheng Feng, Bing Qin, et al. 2023.\\nA survey on hallucination in large language models:\\nPrinciples, taxonomy, challenges, and open questions.\\nArXiv preprint, abs/2311.05232.\\nGabriel Ilharco, Marco Tulio Ribeiro, Mitchell Worts-\\nman, Suchin Gururangan, Ludwig Schmidt, Han-\\nnaneh Hajishirzi, and Ali Farhadi. 2022.\\nEdit-\\ning models with task arithmetic.\\nArXiv preprint,\\nabs/2212.04089.\\nJoel Jang, Seonghyeon Ye, Changho Lee, Sohee Yang,\\nJoongbo Shin, Janghoon Han, Gyeonghun Kim, and\\nMinjoon Seo. 2022. Temporalwiki: A lifelong bench-\\nmark for training and evaluating ever-evolving lan-\\nguage models. In Proceedings of the 2022 Confer-\\nence on Empirical Methods in Natural Language\\nProcessing, pages 6237–6250.\\nJoel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin,\\nJanghoon Han, KIM Gyeonghun, Stanley Jungkyu\\nChoi, and Minjoon Seo. 2021. Towards continual\\nknowledge learning of language models. In Interna-\\ntional Conference on Learning Representations.\\nMyeongjun Erik Jang and Thomas Lukasiewicz. 2023.\\nImproving language models meaning understanding\\nand consistency by learning conceptual roles from\\ndictionary. ArXiv preprint, abs/2310.15541.\\nGanesh Jawahar, Muhammad Abdul-Mageed, and Laks\\nLakshmanan, V.S. 2020. Automatic detection of ma-\\nchine generated text: A critical survey. In Proceed-\\nings of the 28th International Conference on Com-\\nputational Linguistics, pages 2296–2309, Barcelona,\\nSpain (Online). International Committee on Compu-\\ntational Linguistics.\\nGanesh Jawahar, Benoît Sagot, and Djamé Seddah.\\n2019. What does BERT learn about the structure of\\nlanguage? In Proceedings of the 57th Annual Meet-\\ning of the Association for Computational Linguistics,\\npages 3651–3657, Florence, Italy. Association for\\nComputational Linguistics.\\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\\nMadotto, and Pascale Fung. 2023. Survey of halluci-\\nnation in natural language generation. ACM Comput-\\ning Surveys, 55(12):1–38.\\nBohan Jiang, Zhen Tan, Ayushi Nirmal, and Huan\\nLiu. 2023.\\nDisinformation detection: An evolv-\\ning challenge in the age of llms. ArXiv preprint,\\nabs/2309.15847.\\nZhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Xiao-\\njian Jiang, Jiexin Xu, Qiuxia Li, and Jun Zhao. 2024a.\\nTug-of-war between knowledge: Exploring and re-\\nsolving knowledge conflicts in retrieval-augmented\\nlanguage models. ArXiv preprint, abs/2402.14409.\\nZhuoran Jin, Pengfei Cao, Hongbang Yuan, Yubo Chen,\\nJiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu,\\nand Jun Zhao. 2024b. Cutting off the head ends the\\nconflict: A mechanism for interpreting and mitigat-\\ning knowledge conflicts in language models. ArXiv\\npreprint, abs/2402.18154.\\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\\nZettlemoyer. 2017. TriviaQA: A large scale distantly\\nsupervised challenge dataset for reading comprehen-\\nsion. In Proceedings of the 55th Annual Meeting of\\nthe Association for Computational Linguistics (Vol-\\nume 1: Long Papers), pages 1601–1611, Vancouver,\\nCanada. Association for Computational Linguistics.\\nChen Ju, Tengda Han, Kunhao Zheng, Ya Zhang, and\\nWeidi Xie. 2022. Prompting visual-language mod-\\nels for efficient video understanding. In European\\nConference on Computer Vision, pages 105–124.\\nSpringer.\\nJean Kaddour, Joshua Harris, Maximilian Mozes, Her-\\nbie Bradley, Roberta Raileanu, and Robert McHardy.\\n2023. Challenges and applications of large language\\nmodels. ArXiv preprint, abs/2307.10169.\\nNikhil Kandpal, Haikang Deng, Adam Roberts, Eric\\nWallace, and Colin Raffel. 2023. Large language\\nmodels struggle to learn long-tail knowledge. In In-\\nternational Conference on Machine Learning, pages\\n15696–15707. PMLR.\\nCheongwoong Kang and Jaesik Choi. 2023. Impact\\nof co-occurrence on factual knowledge of large lan-\\nguage models. ArXiv preprint, abs/2310.08256.\\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\\nLewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\\nWen-tau Yih. 2020. Dense passage retrieval for open-\\ndomain question answering. In Proceedings of the\\n2020 Conference on Empirical Methods in Natural\\nLanguage Processing (EMNLP), pages 6769–6781,\\nOnline. Association for Computational Linguistics.\\nJungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi,\\nRonan Le Bras, Akari Asai, Xinyan Yu, Dragomir\\nRadev, Noah A Smith, Yejin Choi, and Kentaro Inui.\\n2022. Realtime qa: What’s the answer right now?\\nArXiv preprint, abs/2207.13332.\\nCeleste Kidd and Abeba Birhane. 2023. How ai can dis-\\ntort human beliefs. Science, 380(6651):1222–1223.\\nMiyoung Ko, Ingyu Seong, Hwaran Lee, Joonsuk Park,\\nMinsuk Chang, and Minjoon Seo. 2022. Claimdiff:\\nComparing and contrasting claims on contentious\\nissues. ArXiv preprint, abs/2205.12221.\\nTomáš Koˇciský, Jonathan Schwarz, Phil Blunsom, Chris\\nDyer, Karl Moritz Hermann, Gábor Melis, and Ed-\\nward Grefenstette. 2018. The NarrativeQA reading\\ncomprehension challenge. Transactions of the Asso-\\nciation for Computational Linguistics, 6:317–328.\\nSrijan Kumar and Neil Shah. 2018. False information\\non web and social media: A survey. ArXiv preprint,\\nabs/1804.08559.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\\nton Lee, Kristina Toutanova, Llion Jones, Matthew\\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\\nral questions: A benchmark for question answering\\nresearch. Transactions of the Association for Compu-\\ntational Linguistics, 7:452–466.\\nTsz Kin Lam, Eva Hasler, and Felix Hieber. 2022. An-\\nalyzing the use of influence functions for instance-\\nspecific data filtering in neural machine translation.\\nArXiv preprint, abs/2210.13281.\\nAngeliki Lazaridou, Elena Gribovskaya, Wojciech\\nStokowiec, and Nikolai Grigorev. 2022. Internet-\\naugmented language models through few-shot\\nprompting for open-domain question answering.\\nArXiv preprint, abs/2203.05115.\\nAngeliki Lazaridou, Adhi Kuncoro, Elena Gribovskaya,\\nDevang Agrawal, Adam Liska, Tayfun Terzi, Mai\\nGimenez, Cyprien de Masson d’Autume, Tomas Ko-\\ncisky, Sebastian Ruder, et al. 2021. Mind the gap:\\nAssessing temporal generalization in neural language\\nmodels. Advances in Neural Information Processing\\nSystems, 34:29348–29363.\\nKyungjae Lee, Wookje Han, Seung-won Hwang,\\nHwaran Lee, Joonsuk Park, and Sang-Woo Lee.\\n2022a. Plug-and-play adaptation for continuously-\\nupdated qa. In Findings of the Association for Com-\\nputational Linguistics: ACL 2022, pages 438–447.\\nNayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary,\\nPascale N Fung, Mohammad Shoeybi, and Bryan\\nCatanzaro. 2022b.\\nFactuality enhanced language\\nmodels for open-ended text generation. Advances in\\nNeural Information Processing Systems, 35:34586–\\n34599.\\nJoão\\nA\\nLeite,\\nOlesya\\nRazuvayevskaya,\\nKalina\\nBontcheva, and Carolina Scarton. 2023.\\nDetect-\\ning misinformation with llm-predicted credibility\\nsignals and weak supervision.\\nArXiv preprint,\\nabs/2309.07601.\\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\\nTim Rocktäschel, Sebastian Riedel, and Douwe\\nKiela. 2020.\\nRetrieval-augmented generation for\\nknowledge-intensive NLP tasks. In Advances in Neu-\\nral Information Processing Systems 33: Annual Con-\\nference on Neural Information Processing Systems\\n2020, NeurIPS 2020, December 6-12, 2020, virtual.\\nDaliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin\\nWang, Michal Lukasik, Andreas Veit, Felix Yu,\\nand Sanjiv Kumar. 2022a. Large language models\\nwith controllable working memory. ArXiv preprint,\\nabs/2211.05110.\\nJierui Li, Vipul Raheja, and Dhruv Kumar. 2023a. Con-\\ntradoc: Understanding self-contradictions in docu-\\nments with large language models. ArXiv preprint,\\nabs/2311.09182.\\nJunnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.\\n2023b. Blip-2: Bootstrapping language-image pre-\\ntraining with frozen image encoders and large lan-\\nguage models. In International conference on ma-\\nchine learning, pages 19730–19742. PMLR.\\nKenneth Li, Oam Patel, Fernanda Viégas, Hanspeter\\nPfister, and Martin Wattenberg. 2023c. Inference-\\ntime intervention: Eliciting truthful answers from a\\nlanguage model. ArXiv preprint, abs/2306.03341.\\nShaobo Li, Xiaoguang Li, Lifeng Shang, Zhenhua Dong,\\nChengjie Sun, Bingquan Liu, Zhenzhou Ji, Xin Jiang,\\nand Qun Liu. 2022b. How pre-trained language mod-\\nels capture factual knowledge? a causal-inspired anal-\\nysis. ArXiv preprint, abs/2203.16747.\\nXiang Lisa Li, Ari Holtzman, Daniel Fried, Percy\\nLiang, Jason Eisner, Tatsunori Hashimoto, Luke\\nZettlemoyer, and Mike Lewis. 2022c. Contrastive de-\\ncoding: Open-ended text generation as optimization.\\nArXiv preprint, abs/2210.15097.\\nXiang Lisa Li, Vaishnavi Shrivastava, Siyan Li, Tat-\\nsunori Hashimoto, and Percy Liang. 2023d. Bench-\\nmarking and improving generator-validator con-\\nsistency of language models.\\nArXiv preprint,\\nabs/2310.01846.\\nYinheng Li, Shaofei Wang, Han Ding, and Hang Chen.\\n2023e. Large language models in finance: A sur-\\nvey. In Proceedings of the Fourth ACM International\\nConference on AI in Finance, pages 374–382.\\nZhoubo Li, Ningyu Zhang, Yunzhi Yao, Mengru Wang,\\nXi Chen, and Huajun Chen. 2023f. Unveiling the pit-\\nfalls of knowledge editing for large language models.\\nArXiv preprint, abs/2310.02129.\\nStephanie Lin, Jacob Hilton, and Owain Evans. 2022.\\nTruthfulqa: Measuring how models mimic human\\nfalsehoods. In Proceedings of the 60th Annual Meet-\\ning of the Association for Computational Linguistics\\n(Volume 1: Long Papers), pages 3214–3252.\\nAdam Liska, Tomas Kocisky, Elena Gribovskaya, Tay-\\nfun Terzi, Eren Sezener, Devang Agrawal, D’Autume\\nCyprien De Masson, Tim Scholtes, Manzil Zaheer,\\nSusannah Young, et al. 2022. Streamingqa: A bench-\\nmark for adaptation to new knowledge over time in\\nquestion answering models. In International Con-\\nference on Machine Learning, pages 13604–13622.\\nPMLR.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\\nHiroaki Hayashi, and Graham Neubig. 2023a. Pre-\\ntrain, prompt, and predict: A systematic survey of\\nprompting methods in natural language processing.\\nACM Computing Surveys, 55(9):1–35.\\nYi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tian-\\nwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng,\\nand Yang Liu. 2023b.\\nPrompt injection attack\\nagainst llm-integrated applications. ArXiv preprint,\\nabs/2306.05499.\\nShayne Longpre, Kartik Perisetla, Anthony Chen,\\nNikhil Ramesh, Chris DuBois, and Sameer Singh.\\n2021. Entity-based knowledge conflicts in question\\nanswering. In Proceedings of the 2021 Conference\\non Empirical Methods in Natural Language Process-\\ning, pages 7052–7063.\\nKelvin Luu, Daniel Khashabi, Suchin Gururangan, Kar-\\nishma Mandyam, and Noah A Smith. 2021. Time\\nwaits for no one! analysis and challenges of temporal\\nmisalignment. ArXiv preprint, abs/2111.07408.\\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi\\nDas, Hannaneh Hajishirzi, and Daniel Khashabi.\\n2022. When not to trust language models: Inves-\\ntigating effectiveness and limitations of paramet-\\nric and non-parametric memories. ArXiv preprint,\\nabs/2212.10511.\\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\\nDaniel Khashabi, and Hannaneh Hajishirzi. 2023.\\nWhen not to trust language models: Investigating\\neffectiveness of parametric and non-parametric mem-\\nories. In Proceedings of the 61st Annual Meeting of\\nthe Association for Computational Linguistics (Vol-\\nume 1: Long Papers), pages 9802–9822.\\nPotsawee Manakul, Adian Liusie, and Mark JF Gales.\\n2023. Selfcheckgpt: Zero-resource black-box hal-\\nlucination detection for generative large language\\nmodels. ArXiv preprint, abs/2303.08896.\\nKaterina Margatina, Shuai Wang, Yogarshi Vyas,\\nNeha Anna John, Yassine Benajiba, and Miguel\\nBallesteros. 2023.\\nDynamic benchmarking of\\nmasked language models on temporal concept drift\\nwith multiple views. ArXiv preprint, abs/2302.12297.\\nLauren Martin, Nick Whitehouse, Stephanie Yiu, Lizzie\\nCatterson, and Rivindu Perera. 2024. Better call gpt,\\ncomparing large language models against lawyers.\\nArXiv preprint, abs/2401.16212.\\nLuca Massarelli, Fabio Petroni, Aleksandra Piktus,\\nMyle Ott, Tim Rocktäschel, Vassilis Plachouras, Fab-\\nrizio Silvestri, and Sebastian Riedel. 2020. How de-\\ncoding strategies affect the verifiability of generated\\ntext. In Findings of the Association for Computa-\\ntional Linguistics: EMNLP 2020, pages 223–235,\\nOnline. Association for Computational Linguistics.\\nPriyanka Meel and Dinesh Kumar Vishwakarma. 2020.\\nFake news, rumor, information pollution in social me-\\ndia and web: A contemporary survey of state-of-the-\\narts, challenges and opportunities. Expert Systems\\nwith Applications, 153:112986.\\nFilippo Menczer, David Crandall, Yong-Yeol Ahn, and\\nApu Kapadia. 2023. Addressing the harms of ai-\\ngenerated inauthentic content. Nature Machine Intel-\\nligence, 5(7):679–680.\\nKevin Meng, David Bau, Alex Andonian, and Yonatan\\nBelinkov. 2022. Locating and editing factual associ-\\nations in gpt. Advances in Neural Information Pro-\\ncessing Systems, 35:17359–17372.\\nStephen Merity, Caiming Xiong, James Bradbury, and\\nRichard Socher. 2017. Pointer sentinel mixture mod-\\nels. In 5th International Conference on Learning\\nRepresentations, ICLR 2017, Toulon, France, April\\n24-26, 2017, Conference Track Proceedings. Open-\\nReview.net.\\nSilvia Milano, Joshua A McGrane, and Sabina Leonelli.\\n2023. Large language models challenge the future\\nof higher education. Nature Machine Intelligence,\\n5(4):333–334.\\nEric Mitchell, Charles Lin, Antoine Bosselut, Chelsea\\nFinn, and Christopher D Manning. 2021. Fast model\\nediting at scale. ArXiv preprint, abs/2110.11309.\\nEric Mitchell, Joseph J Noh, Siyan Li, William S Arm-\\nstrong, Ananth Agarwal, Patrick Liu, Chelsea Finn,\\nand Christopher D Manning. 2022. Enhancing self-\\nconsistency and performance of pre-trained language\\nmodels through natural language inference. ArXiv\\npreprint, abs/2211.11875.\\nNiels Mündler, Jingxuan He, Slobodan Jenko, and Mar-\\ntin Vechev. 2023. Self-contradictory hallucinations\\nof large language models: Evaluation, detection and\\nmitigation. ArXiv preprint, abs/2305.15852.\\nHumza Naveed, Asad Ullah Khan, Shi Qiu, Muham-\\nmad Saqib, Saeed Anwar, Muhammad Usman, Nick\\nBarnes, and Ajmal Mian. 2023. A comprehensive\\noverview of large language models. ArXiv preprint,\\nabs/2307.06435.\\nElla Neeman, Roee Aharoni, Or Honovich, Leshem\\nChoshen, Idan Szpektor, and Omri Abend. 2022.\\nDisentqa: Disentangling parametric and contextual\\nknowledge with counterfactual question answering.\\nArXiv preprint, abs/2211.05655.\\nRaymond S Nickerson. 1998. Confirmation bias: A\\nubiquitous phenomenon in many guises. Review of\\ngeneral psychology, 2(2):175–220.\\nXenia Ohmer, Elia Bruni, and Dieuwke Hupkes. 2023.\\nSeparating form and meaning: Using self-consistency\\nto quantify task understanding across multiple senses.\\nCoRR.\\nYasumasa Onoe, Michael JQ Zhang, Shankar Padman-\\nabhan, Greg Durrett, and Eunsol Choi. 2023. Can\\nlms learn new entities from descriptions? challenges\\nin propagating injected knowledge. ArXiv preprint,\\nabs/2305.01651.\\nOpenAI. 2023. Chatgpt.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\\n2022. Training language models to follow instruc-\\ntions with human feedback.\\nAdvances in Neural\\nInformation Processing Systems, 35:27730–27744.\\nLiangming Pan, Wenhu Chen, Min-Yen Kan, and\\nWilliam Yang Wang. 2023a. Attacking open-domain\\nquestion answering by injecting misinformation.\\nIJCNLP-AACL. ACL.\\nXiaoman Pan, Wenlin Yao, Hongming Zhang, Dian Yu,\\nDong Yu, and Jianshu Chen. 2022. Knowledge-in-\\ncontext: Towards knowledgeable semi-parametric\\nlanguage models. In The Eleventh International Con-\\nference on Learning Representations.\\nYikang Pan, Liangming Pan, Wenhu Chen, Preslav\\nNakov, Min-Yen Kan, and William Yang Wang.\\n2023b.\\nOn the risk of misinformation pollu-\\ntion with large language models. ArXiv preprint,\\nabs/2305.13661.\\nBaolin Peng, Michel Galley, Pengcheng He, Hao Cheng,\\nYujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou\\nYu, Weizhu Chen, et al. 2023. Check your facts and\\ntry again: Improving large language models with\\nexternal knowledge and automated feedback. ArXiv\\npreprint, abs/2302.12813.\\nEthan Perez, Sam Ringer, Kamil˙e Lukoši¯ut˙e, Karina\\nNguyen, Edwin Chen, Scott Heiner, Craig Pettit,\\nCatherine Olsson, Sandipan Kundu, Saurav Kada-\\nvath, et al. 2022. Discovering language model behav-\\niors with model-written evaluations. ArXiv preprint,\\nabs/2212.09251.\\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\\nAlexander Miller. 2019. Language models as knowl-\\nedge bases?\\nIn Proceedings of the 2019 Confer-\\nence on Empirical Methods in Natural Language Pro-\\ncessing and the 9th International Joint Conference\\non Natural Language Processing (EMNLP-IJCNLP),\\npages 2463–2473, Hong Kong, China. Association\\nfor Computational Linguistics.\\nMaren Pielka, Felix Rode, Lisa Pucknat, Tobias Deußer,\\nand Rafet Sifa. 2022. A linguistic investigation of\\nmachine learning based contradiction detection mod-\\nels: an empirical analysis and future perspectives.\\nIn 2022 21st IEEE International Conference on Ma-\\nchine Learning and Applications (ICMLA), pages\\n1649–1653. IEEE.\\nYuval Pinter and Michael Elhadad. 2023. Emptying\\nthe ocean with a spoon: Should we edit models?\\nIn Findings of the Association for Computational\\nLinguistics: EMNLP 2023, pages 15164–15172.\\nJirui Qi, Raquel Fernández, and Arianna Bisazza. 2023.\\nCross-lingual consistency of factual knowledge in\\nmultilingual language models.\\nArXiv preprint,\\nabs/2310.10378.\\nCheng Qian, Xinran Zhao, and Sherry Tongshuang Wu.\\n2023. \" merge conflicts!\" exploring the impacts of\\nexternal distractors to parametric knowledge graphs.\\nArXiv preprint, abs/2309.08594.\\nElla Rabinovich, Samuel Ackerman, Orna Raz, Ei-\\ntan Farchi, and Ateret Anaby-Tavor. 2023. Predict-\\ning question-answering performance of large lan-\\nguage models through semantic consistency. ArXiv\\npreprint, abs/2311.01152.\\nHarsh Raj, Vipul Gupta, Domenic Rosati, and Sub-\\nhabrata Majumdar. 2023. Semantic consistency for\\nassuring reliability of large language models. ArXiv\\npreprint, abs/2308.09138.\\nHarsh Raj, Domenic Rosati, and Subhabrata Majumdar.\\n2022. Measuring reliability of large language mod-\\nels through semantic consistency. ArXiv preprint,\\nabs/2211.05853.\\nPranav Rajpurkar, Robin Jia, and Percy Liang. 2018.\\nKnow what you don’t know: Unanswerable ques-\\ntions for SQuAD. In Proceedings of the 56th Annual\\nMeeting of the Association for Computational Lin-\\nguistics (Volume 2: Short Papers), pages 784–789,\\nMelbourne, Australia. Association for Computational\\nLinguistics.\\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\\nPercy Liang. 2016. SQuAD: 100,000+ questions for\\nmachine comprehension of text. In Proceedings of\\nthe 2016 Conference on Empirical Methods in Natu-\\nral Language Processing, pages 2383–2392, Austin,\\nTexas. Association for Computational Linguistics.\\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\\nHow much knowledge can you pack into the param-\\neters of a language model? In Proceedings of the\\n2020 Conference on Empirical Methods in Natural\\nLanguage Processing (EMNLP), pages 5418–5426,\\nOnline. Association for Computational Linguistics.\\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\\n2020. A primer in BERTology: What we know about\\nhow BERT works. Transactions of the Association\\nfor Computational Linguistics, 8:842–866.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\\nCancedda, and Thomas Scialom. 2023. Toolformer:\\nLanguage models can teach themselves to use tools.\\nArXiv preprint, abs/2302.04761.\\nOr Sharir, Barak Peleg, and Yoav Shoham. 2020. The\\ncost of training nlp models: A concise overview.\\nArXiv preprint, abs/2004.08900.\\nMrinank Sharma, Meg Tong, Tomasz Korbak, David\\nDuvenaud, Amanda Askell, Samuel R Bowman,\\nNewton Cheng, Esin Durmus, Zac Hatfield-Dodds,\\nScott R Johnston, et al. 2023. Towards understand-\\ning sycophancy in language models. ArXiv preprint,\\nabs/2310.13548.\\nWeijia Shi, Xiaochuang Han, Mike Lewis, Yulia\\nTsvetkov, Luke Zettlemoyer, and Scott Wen-tau\\nYih. 2023a. Trusting your evidence: Hallucinate\\nless with context-aware decoding. ArXiv preprint,\\nabs/2305.14739.\\nWeijia Shi, Sewon Min, Maria Lomeli, Chunting Zhou,\\nMargaret Li, Victoria Lin, Noah A Smith, Luke\\nZettlemoyer, Scott Yih, and Mike Lewis. 2023b. In-\\ncontext pretraining: Language modeling beyond doc-\\nument boundaries. ArXiv preprint, abs/2310.10638.\\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Min-\\njoon Seo, Rich James, Mike Lewis, Luke Zettle-\\nmoyer, and Wen-tau Yih. 2023c. Replug: Retrieval-\\naugmented black-box language models.\\nArXiv\\npreprint, abs/2301.12652.\\nKai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and\\nHuan Liu. 2017. Fake news detection on social me-\\ndia: A data mining perspective. ACM SIGKDD ex-\\nplorations newsletter, 19(1):22–36.\\nRuihao Shui, Yixin Cao, Xiang Wang, and Tat-Seng\\nChua. 2023. A comprehensive evaluation of large\\nlanguage models on legal judgment prediction. ArXiv\\npreprint, abs/2310.11761.\\nKurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela,\\nand Jason Weston. 2021. Retrieval augmentation\\nreduces hallucination in conversation. In Findings\\nof the Association for Computational Linguistics:\\nEMNLP 2021, pages 3784–3803.\\nKaran Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mah-\\ndavi, Jason Wei, Hyung Won Chung, Nathan Scales,\\nAjay Tanwani, Heather Cole-Lewis, Stephen Pfohl,\\net al. 2022. Large language models encode clinical\\nknowledge. ArXiv preprint, abs/2212.13138.\\nAnton Sinitsin, Vsevolod Plokhotnyuk, Dmitriy Pyrkin,\\nSergei Popov, and Artem Babenko. 2020. Editable\\nneural networks. In 8th International Conference on\\nLearning Representations, ICLR 2020, Addis Ababa,\\nEthiopia, April 26-30, 2020. OpenReview.net.\\nCraig S. Smith. 2023. What large models cost you –\\nthere is no free ai lunch.\\nIrene Solaiman, Zeerak Talat, William Agnew, Lama\\nAhmad,\\nDylan Baker,\\nSu Lin Blodgett,\\nHal\\nDaumé III, Jesse Dodge, Ellie Evans, Sara Hooker,\\net al. 2023. Evaluating the social impact of generative\\nai systems in systems and society. ArXiv preprint,\\nabs/2306.05949.\\nGiovanni Spitale, Nikola Biller-Andorno, and Federico\\nGermani. 2023. Ai model gpt-3 (dis) informs us\\nbetter than humans. ArXiv preprint, abs/2301.11924.\\nHexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang,\\nQi Cao, and Xueqi Cheng. 2024. Blinded by gen-\\nerated contexts: How language models merge gen-\\nerated and retrieved contexts for open-domain qa?\\nArXiv preprint, abs/2401.11911.\\nRuixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023.\\nThe science of detecting llm-generated texts. ArXiv\\npreprint, abs/2303.07205.\\nIan Tenney, Dipanjan Das, and Ellie Pavlick. 2019.\\nBERT rediscovers the classical NLP pipeline. In\\nProceedings of the 57th Annual Meeting of the Asso-\\nciation for Computational Linguistics, pages 4593–\\n4601, Florence, Italy. Association for Computational\\nLinguistics.\\nArun James Thirunavukarasu, Darren Shu Jeng Ting,\\nKabilan Elangovan, Laura Gutierrez, Ting Fang Tan,\\nand Daniel Shu Wei Ting. 2023. Large language\\nmodels in medicine. Nature medicine, 29(8):1930–\\n1940.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\\nBhosale, et al. 2023.\\nLlama 2:\\nOpen founda-\\ntion and fine-tuned chat models.\\nArXiv preprint,\\nabs/2307.09288.\\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\\nand Ashish Sabharwal. 2022.\\nMusique: Multi-\\nhop questions via single-hop question composition.\\nTransactions of the Association for Computational\\nLinguistics, 10:539–554.\\nMiles Turpin, Julian Michael, Ethan Perez, and\\nSamuel R Bowman. 2023. Language models don’t\\nalways say what they think: Unfaithful explana-\\ntions in chain-of-thought prompting. ArXiv preprint,\\nabs/2305.04388.\\nJoseph E Uscinski and Ryden W Butler. 2013. The\\nepistemology of fact checking.\\nCritical Review,\\n25(2):162–180.\\nTyler Vergho, Jean-Francois Godbout, Reihaneh Rab-\\nbany, and Kellin Pelrine. 2024. Comparing gpt-4\\nand open-source language models in misinformation\\nmitigation. ArXiv preprint, abs/2401.06920.\\nTu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry\\nWei, Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny\\nZhou, Quoc Le, et al. 2023. Freshllms: Refreshing\\nlarge language models with search engine augmenta-\\ntion. ArXiv preprint, abs/2310.03214.\\nAlexander Wan, Eric Wallace, and Dan Klein. 2024.\\nWhat evidence do language models find convincing?\\nArXiv preprint, abs/2402.11782.\\nCunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan\\nLi, and Tian Gao. 2019. Does it make sense? and\\nwhy? a pilot study for sense making and explana-\\ntion. In Proceedings of the 57th Annual Meeting of\\nthe Association for Computational Linguistics, pages\\n4020–4026, Florence, Italy. Association for Compu-\\ntational Linguistics.\\nCunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru\\nTang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao,\\nWenyang Gao, Xuming Hu, Zehan Qi, Yidong Wang,\\nLinyi Yang, Jindong Wang, Xing Xie, Zheng Zhang,\\nand Yue Zhang. 2023a. Survey on factuality in large\\nlanguage models: Knowledge, retrieval and domain-\\nspecificity.\\nCunxiang Wang, Zhikun Xu, Qipeng Guo, Xiangkun\\nHu, Xuefeng Bai, Zheng Zhang, and Yue Zhang.\\n2023b. Exploiting Abstract Meaning Representation\\nfor open-domain question answering. In Findings of\\nthe Association for Computational Linguistics: ACL\\n2023, pages 2083–2096, Toronto, Canada. Associa-\\ntion for Computational Linguistics.\\nCunxiang Wang, Haofei Yu, and Yue Zhang. 2023c.\\nRFiD: Towards rational fusion-in-decoder for open-\\ndomain question answering. In Findings of the As-\\nsociation for Computational Linguistics: ACL 2023,\\npages 2473–2481, Toronto, Canada. Association for\\nComputational Linguistics.\\nFei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou,\\nand Muhao Chen. 2023d. A causal view of entity\\nbias in (large) language models.\\nArXiv preprint,\\nabs/2305.14695.\\nJiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao,\\nand Jiarong Xu. 2023e. Cross-lingual knowledge\\nediting in large language models. ArXiv preprint,\\nabs/2309.08952.\\nLiyuan Wang, Xingxing Zhang, Qian Li, Mingtian\\nZhang, Hang Su, Jun Zhu, and Yi Zhong. 2023f. In-\\ncorporating neuro-inspired adaptability for continual\\nlearning in artificial intelligence. Nature Machine\\nIntelligence, pages 1–13.\\nYike Wang, Shangbin Feng, Heng Wang, Weijia\\nShi, Vidhisha Balachandran, Tianxing He, and Yu-\\nlia Tsvetkov. 2023g.\\nResolving knowledge con-\\nflicts in large language models.\\nArXiv preprint,\\nabs/2310.00935.\\nJerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and\\nQuoc V Le. 2023.\\nSimple synthetic data re-\\nduces sycophancy in large language models. ArXiv\\npreprint, abs/2308.03958.\\nLaura Weidinger, John Mellor, Maribeth Rauh, Conor\\nGriffin, Jonathan Uesato, Po-Sen Huang, Myra\\nCheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh,\\net al. 2021. Ethical and social risks of harm from\\nlanguage models. ArXiv preprint, abs/2112.04359.\\nLaura Weidinger, Maribeth Rauh, Nahema Marchal, Ar-\\nianna Manzini, Lisa Anne Hendricks, Juan Mateos-\\nGarcia, Stevie Bergman, Jackie Kay, Conor Grif-\\nfin, Ben Bariach, et al. 2023. Sociotechnical safety\\nevaluation of generative ai systems. ArXiv preprint,\\nabs/2310.11986.\\nOrion Weller, Aleem Khan, Nathaniel Weir, Dawn\\nLawrie, and Benjamin Van Durme. 2022. Defend-\\ning against misinformation attacks in open-domain\\nquestion answering. ArXiv preprint, abs/2212.10002.\\nAdina Williams, Nikita Nangia, and Samuel Bowman.\\n2018. A broad-coverage challenge corpus for sen-\\ntence understanding through inference. In Proceed-\\nings of the 2018 Conference of the North American\\nChapter of the Association for Computational Lin-\\nguistics: Human Language Technologies, Volume\\n1 (Long Papers), pages 1112–1122, New Orleans,\\nLouisiana. Association for Computational Linguis-\\ntics.\\nXiangcheng Wu, Xi Niu, and Ruhani Rahman. 2022.\\nTopological analysis of contradictions in text. In\\nProceedings of the 45th International ACM SIGIR\\nConference on Research and Development in Infor-\\nmation Retrieval, pages 2478–2483.\\nYusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Tay-\\nlor Berg-Kirkpatrick, and Shlomo Dubnov. 2023.\\nLarge-scale contrastive language-audio pretraining\\nwith feature fusion and keyword-to-caption augmen-\\ntation. In ICASSP 2023-2023 IEEE International\\nConference on Acoustics, Speech and Signal Process-\\ning (ICASSP), pages 1–5. IEEE.\\nJian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, and\\nYu Su. 2023.\\nAdaptive chameleon or stubborn\\nsloth: Unraveling the behavior of large language\\nmodels in knowledge conflicts.\\nArXiv preprint,\\nabs/2305.13300.\\nNan Xu, Fei Wang, Bangzheng Li, Mingtao Dong, and\\nMuhao Chen. 2022. Does your model classify en-\\ntities reasonably? diagnosing and mitigating spu-\\nrious correlations in entity typing. ArXiv preprint,\\nabs/2205.12640.\\nRongwu Xu, Brian S Lin, Shujian Yang, Tianqi Zhang,\\nWeiyan Shi, Tianwei Zhang, Zhixuan Fang, Wei\\nXu, and Han Qiu. 2023.\\nThe earth is flat be-\\ncause...: Investigating llms’ belief towards misinfor-\\nmation via persuasive conversation. ArXiv preprint,\\nabs/2312.09085.\\nBoyang Xue, Weichao Wang, Hongru Wang, Fei Mi,\\nRui Wang, Yasheng Wang, Lifeng Shang, Xin Jiang,\\nQun Liu, and Kam-Fai Wong. 2023. Improving fac-\\ntual consistency for knowledge-grounded dialogue\\nsystems via knowledge enhancement and alignment.\\nIn Findings of the Association for Computational\\nLinguistics: EMNLP 2023, pages 7829–7844.\\nYunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng,\\nZhoubo Li, Shumin Deng, Huajun Chen, and Ningyu\\nZhang. 2023. Editing large language models: Prob-\\nlems, methods, and opportunities. ArXiv preprint,\\nabs/2305.13172.\\nJingwei Yi, Yueqi Xie, Bin Zhu, Keegan Hines, Emre\\nKiciman, Guangzhong Sun, Xing Xie, and Fangzhao\\nWu. 2023. Benchmarking and defending against indi-\\nrect prompt injection attacks on large language mod-\\nels. ArXiv preprint, abs/2312.14197.\\nJiahao Ying, Yixin Cao, Kai Xiong, Yidong He, Long\\nCui, and Yongbin Liu. 2023. Intuitive or dependent?\\ninvestigating llms’ robustness to conflicting prompts.\\nArXiv preprint, abs/2309.17415.\\nWenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu,\\nMingxuan Ju, Soumya Sanyal, Chenguang Zhu,\\nMichael Zeng, and Meng Jiang. 2022.\\nGener-\\nate rather than retrieve: Large language models\\nare strong context generators.\\nArXiv preprint,\\nabs/2209.10063.\\nAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,\\nHanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,\\nWendi Zheng, Xiao Xia, et al. 2022. Glm-130b: An\\nopen bilingual pre-trained model. In The Eleventh In-\\nternational Conference on Learning Representations.\\nBoyu Zhang, Hongyang Yang, Tianyu Zhou, Muham-\\nmad Ali Babar, and Xiao-Yang Liu. 2023a. Enhanc-\\ning financial sentiment analysis via retrieval aug-\\nmented large language models. In Proceedings of\\nthe Fourth ACM International Conference on AI in\\nFinance, pages 349–356.\\nHang Zhang, Xin Li, and Lidong Bing. 2023b. Video-\\nllama: An instruction-tuned audio-visual language\\nmodel for video understanding. In Proceedings of\\nthe 2023 Conference on Empirical Methods in Nat-\\nural Language Processing: System Demonstrations,\\npages 543–553.\\nJiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley A\\nMalin, and Sricharan Kumar. 2023c. Sac3: Reliable\\nhallucination detection in black-box language models\\nvia semantic-aware cross-check consistency. ArXiv\\npreprint, abs/2311.01740.\\nMichael JQ Zhang and Eunsol Choi. 2021. Situatedqa:\\nIncorporating extra-linguistic contexts into qa. ArXiv\\npreprint, abs/2109.06157.\\nMichael JQ Zhang and Eunsol Choi. 2023. Mitigating\\ntemporal misalignment by discarding outdated facts.\\nArXiv preprint, abs/2305.14824.\\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\\nLiu, and Bill Dolan. 2020. DIALOGPT : Large-scale\\ngenerative pre-training for conversational response\\ngeneration. In Proceedings of the 58th Annual Meet-\\ning of the Association for Computational Linguistics:\\nSystem Demonstrations, pages 270–278, Online. As-\\nsociation for Computational Linguistics.\\nYue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,\\nTingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,\\nYulong Chen, Longyue Wang, Anh Tuan Luu, Wei\\nBi, Freda Shi, and Shuming Shi. 2023d. Siren’s song\\nin the ai ocean: A survey on hallucination in large\\nlanguage models.\\nYunxiang Zhang, Muhammad Khalifa, Lajanugen Lo-\\ngeswaran, Moontae Lee, Honglak Lee, and Lu Wang.\\n2023e. Merging generated and retrieved knowledge\\nfor open-domain qa. ArXiv preprint, abs/2310.14393.\\nHaiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu,\\nHuiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei\\nYin, and Mengnan Du. 2023a. Explainability for\\nlarge language models: A survey. ACM Transactions\\non Intelligent Systems and Technology.\\nYukun Zhao, Lingyong Yan, Weiwei Sun, Guoliang\\nXing, Chong Meng, Shuaiqiang Wang, Zhicong\\nCheng, Zhaochun Ren, and Dawei Yin. 2023b.\\nKnowing what llms do not know: A simple yet\\neffective self-detection method.\\nArXiv preprint,\\nabs/2310.17918.\\nChujie Zheng, Jinfeng Zhou, Yinhe Zheng, Libiao Peng,\\nZhen Guo, Wenquan Wu, Zhengyu Niu, Hua Wu,\\nand Minlie Huang. 2022. Cdconv: A benchmark\\nfor contradiction detection in chinese conversations.\\nArXiv preprint, abs/2210.08511.\\nZexuan Zhong, Zhengxuan Wu, Christopher D Man-\\nning, Christopher Potts, and Danqi Chen. 2023.\\nMquake: Assessing knowledge editing in language\\nmodels via multi-hop questions.\\nArXiv preprint,\\nabs/2305.14795.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao\\nSun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu,\\nLili Yu, et al. 2023a. Lima: Less is more for align-\\nment. ArXiv preprint, abs/2305.11206.\\nHongjian Zhou, Boyang Gu, Xinyu Zou, Yiru Li,\\nSam S Chen, Peilin Zhou, Junling Liu, Yining Hua,\\nChengfeng Mao, Xian Wu, et al. 2023b. A survey of\\nlarge language models in medicine: Progress, applica-\\ntion, and challenge. ArXiv preprint, abs/2311.05112.\\nJiawei Zhou, Yixuan Zhang, Qianni Luo, Andrea G\\nParker, and Munmun De Choudhury. 2023c. Syn-\\nthetic lies: Understanding ai-generated misinforma-\\ntion and evaluating algorithmic and human solutions.\\nIn Proceedings of the 2023 CHI Conference on Hu-\\nman Factors in Computing Systems, pages 1–20.\\nWenxuan Zhou, Sheng Zhang, Hoifung Poon, and\\nMuhao Chen. 2023d.\\nContext-faithful prompt-\\ning for large language models.\\nArXiv preprint,\\nabs/2303.11315.\\nYuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and\\nChao Zhang. 2023. Toolqa: A dataset for llm ques-\\ntion answering with external tools. ArXiv preprint,\\nabs/2306.13304.\\nArkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria\\nLiakata, and Rob Procter. 2018. Detection and res-\\nolution of rumours in social media: A survey. ACM\\nComputing Surveys (CSUR), 51(2):1–36.\\n', metadata={'Published': '2024-03-13', 'Title': 'Knowledge Conflicts for LLMs: A Survey', 'Authors': 'Rongwu Xu, Zehan Qi, Cunxiang Wang, Hongru Wang, Yue Zhang, Wei Xu', 'Summary': 'This survey provides an in-depth analysis of knowledge conflicts for large\\nlanguage models (LLMs), highlighting the complex challenges they encounter when\\nblending contextual and parametric knowledge. Our focus is on three categories\\nof knowledge conflicts: context-memory, inter-context, and intra-memory\\nconflict. These conflicts can significantly impact the trustworthiness and\\nperformance of LLMs, especially in real-world applications where noise and\\nmisinformation are common. By categorizing these conflicts, exploring the\\ncauses, examining the behaviors of LLMs under such conflicts, and reviewing\\navailable solutions, this survey aims to shed light on strategies for improving\\nthe robustness of LLMs, thereby serving as a valuable resource for advancing\\nresearch in this evolving area.'}),\n",
       " Document(page_content='Branch-Train-MiX:\\nMixing Expert LLMs into a Mixture-of-Experts LLM\\nSainbayar Sukhbaatar, Olga Golovneva, Vasu Sharma, Hu Xu, Xi Victoria Lin, Baptiste Rozière, Jacob\\nKahn, Daniel Li, Wen-tau Yih, Jason Weston, Xian Li\\nFAIR at Meta\\nWe investigate efficient methods for training Large Language Models (LLMs) to possess capabilities\\nin multiple specialized domains, such as coding, math reasoning and world knowledge. Our method,\\nnamed Branch-Train-MiX (BTX), starts from a seed model, which is branched to train experts\\nin embarrassingly parallel fashion with high throughput and reduced communication cost. After\\nindividual experts are asynchronously trained, BTX brings together their feedforward parameters\\nas experts in Mixture-of-Expert (MoE) layers and averages the remaining parameters, followed\\nby an MoE-finetuning stage to learn token-level routing. BTX generalizes two special cases, the\\nBranch-Train-Merge method, which does not have the MoE finetuning stage to learn routing, and\\nsparse upcycling, which omits the stage of training experts asynchronously. Compared to alternative\\napproaches, BTX achieves the best accuracy-efficiency tradeoff.\\nDate: March 13, 2024\\nCorrespondence: {sainbar,xianl}@meta.com\\n1\\nIntroduction\\nIn recent years, Large Language Models (LLMs) have shown impressive performance in a wide-range of\\ntasks (Brown et al., 2020; Touvron et al., 2023; Achiam et al., 2023), including code generation (Li et al.,\\n2022b; Rozière et al., 2023), solving math problems (Azerbayev et al., 2023), multilinguality (Zhao et al.,\\n2024), etc. Training such LLMs requires a large amount of compute and data, exceeding thousands of GPUs\\nand trillions of tokens. The training parallelization is typically done by maintaining multiple copies of the\\nmodel on different GPUs and keeping them synchronized after each weight update. The cost of this frequent\\ncommunication is the main bottleneck in scaling the training to more GPUs. Besides this issue, synchronized\\ntraining is more vulnerable to hardware failures as a single failed GPU can cause the whole training to halt\\n(Zhang et al., 2022; Gemini Team, 2023).\\nRecent work by Li et al. (2022a) proposed the Branch-Train-Merge (BTM) method for embarrassingly parallel\\ntraining of LLMs without any synchronization for improving the throughput of pretraining. It starts by\\ncreating multiple copies of a seed LLM, then separately training each copy on different subsets of data.\\nThis results in multiple independent LLMs that do not share any parameters and each LLM is an expert\\nspecializing in its own data distribution, such as knowledge domains, languages or even modalities. At test\\ntime, an input prompt is classified into one or more of the domains, and then the final outputs are formed\\nfrom the corresponding expert models which are combined to predict the next token. While this approach\\nmakes training more efficient, its main drawback is the lack of a unified single model making it impossible to\\ndo further supervised finetuning (SFT) or reinforcement learning from human feedback (RLHF) finetuning\\n(Ouyang et al., 2022), both of which can boost performance further, and are crucial steps in building aligned\\nLLMs.\\nA separate line of work for reducing the computational footprint of LLMs is the Mixture-of-Experts (MoE)\\napproach (Jacobs et al., 1991; Shazeer et al., 2017), where only a subset of parameteters are active at any\\ngiven time. In particular, MoE is applied to the feedforward sublayer of Transformers (Fedus et al., 2022;\\nRoller et al., 2021; Lewis et al., 2021), allowing the total number of parameters to grow without additional\\ncomputation. LLMs scaled in this way have shown impressive performance on downstream tasks (Jiang\\net al., 2024; Xue et al., 2024). Unlike Branch-Train-Merge, Mixture-of-Experts are often trained in a fully\\n1\\narXiv:2403.07816v1  [cs.CL]  12 Mar 2024\\nSeed \\nLLM\\nExpert \\nLLM 2\\nBranch from a seed model\\nExpert \\nLLM N\\nExpert \\nLLM 1\\nFF 1\\nFF 2\\nFF N\\nData 2\\nData 1\\nData N\\nMoE\\nFeedforward\\nlayer \\nTrain experts separately on their \\ncorresponding data\\nMix the experts in an unified \\nMixture-of-Experts model and finetune \\nrouter\\n \\n \\n \\n…\\n…\\nFigure 1 The Branch-Train-MiX (BTX) method has three steps: 1) branch from a pretrained seed LLM by making multiple\\ncopies of it; 2) train those copies separately on different subsets of data to obtain expert LLMs; 3) mix those expert\\nLLMs by combining them into a single LLM using mixture-of-experts feedforward (FF) layers, and finetuning the\\noverall unified model.\\nsynchronized fashion, and the communication cost increases with the number of experts due to all-to-all\\ncommunication.\\nIn this paper, we aim for the best of both worlds, combining the advantages of Branch-Train-Merge and\\nMixture-of-Experts, while mitigating their disadvantages. We achieve this by training multiple expert LLMs\\nseparately as in the Branch-Train-Merge method, but subsequently combine those experts into a single model\\nusing an MoE architecture. More specifically, the feedforward sublayers from all the expert LLMs are brought\\ntogether into a single MoE module at each layer, and a router network selects which feedforward expert to\\nuse at every token. We merge other modules of the expert LLMs, including self-attention layers, by simply\\naveraging their weights. Then the resulting model is MoE-finetuned on all the combined data by continuing\\ntraining, so that the router can learn to mix the expert feedforward (FF) modules. Figure 1 shows an overview\\nof this method, which we call Branch-Train-MiX (BTX).\\nThe main advantage of BTX compared to MoE is that expert training is embarrassingly parallel and\\nasynchronous, reducing communication cost and increasing training throughput. Compared to Branch-Train-\\nMerge, the final BTX model is a unified neural network that can be finetuned or used like any other standard\\nLLM. The final BTX model will not significantly increase inference FLOPs compared to the seed model since\\nit is sparsely activated, despite having a much larger number of parameters.\\nWe conduct our experiments using Llama-2 7B (Touvron et al., 2023) as a seed model and train expert\\nLLMs on different subsets of data corresponding to the domains of math, code and Wikipedia. With the\\noriginal Llama-2 7B weights added as a fourth expert, we finetune the combined MoE model for a relatively\\nshort period compared to the pretraining process. The resulting BTX model brings significant improvements\\nover the seed model on tasks across various domains, especially bridging the gap with specialized models on\\nmath and code related tasks, while retaining performance on the original capabilities where specialized models\\nsuffer from catastrophic forgetting. BTX outperforms BTM on all tasks demonstrating the benefits of learnt\\nrouting through MoE finetuning. Compared to purely MoE training such as sparse upcycling, BTX is more\\ncompute efficient with higher training throughput and more balanced performance across tasks in different\\ndomains.\\n2\\nRelated Work\\nAsynchronous parallel training\\nReducing communication between training workers for computational efficiency\\nis a major topic of study for training deep learning systems. Zhang et al. (2015) introduced a method that\\nallows model instances on different workers to diverge from each other, thus eliminating the constant need of\\nsynchronization. Instead, the workers are loosely synchronized to master weights using elastic averaging from\\ntime to time. A more recent work by Douillard et al. (2023) showed that less frequent synchronization of\\ndiverged workers by averaging their weight changes and applying Nesterov momentum works well in practice\\n2\\nfor training LLMs. The Branch-Train-Merge method (Li et al., 2022a; Gururangan et al., 2023) takes parallel\\ntraining to the extreme by running multiple training processes completely independently. Each training\\nprocess uses specific domain data, thus the corresponding model becomes an expert in that domain. Finally,\\nthe output distributions of those expert models are averaged to make a next token prediction. Which experts\\nto average is decided by classifying the input into one or more of the domains. Wortsman et al. (2022) showed\\nsimply averaging parameters of separately trained models improves performance, but the models only differed\\nin their hyperparameters.\\nMixture-of-Experts\\nMoE is used to scale deep networks in Shazeer et al. (2017) using a simple Top-K routing\\nscheme. Since the routing decisions are discrete and thus cannot be trained by gradient descent, various\\ntraining methods have been explored for the Transformer architecture (Fedus et al., 2022; Lewis et al., 2021).\\nSurprisingly Roller et al. (2021) showed that even a fixed routing scheme without any learning works well, if\\nthe routing is done via a random mapping based on input tokens. In larger scale experiments with recent\\nLLMs, Jiang et al. (2024) demonstrated that the MoE approach can match the performance of dense LLM\\ncounterparts using a much smaller number of active parameters. A study by Dai et al. (2024) showed the\\nadvantage of more fine-grained experts, as well as having a shared expert that always stay active. More similar\\nto our work, Gururangan et al. (2021) makes experts in feedforward layers specialize to specific domains using\\na domain-conditioned fixed routing, but it lacks the asynchronous training of our approach.\\nContinual learning\\nOur method relates to continual learning (Awasthi and Sarawagi, 2019) because domain\\nexperts are trained on datasets with different distributions from the initial data used for training the seed\\nmodel, which is implemented by continued training after branching. Specifically, our approach is related\\nto parameter isolation methods (Lange et al., 2019) as we have different parameters for different domains.\\nAljundi et al. (2016) also creates a new copy of a model to train on each domain. Rusu et al. (2016) adds a new\\nmodel with a new domain, but connects it to the previous models so the previously learned features can be\\nused. Rozière et al. (2023) showed continual training of a seed LLM on a specific domain of code can produce\\na strong domain expert model, and this converges much faster than starting from scratch. For training a\\nmath expert, starting from a code expert rather than a general LLM was shown to be more beneficial (Shao\\net al., 2024; Azerbayev et al., 2023).\\n3\\nBranch-Train-MiX\\nGiven an existing LLM M which has been pretrained on a large corpora covering a wide variety of topics,\\nwe aim to improve its performance on N areas of expertise. This is achieved by continued pretraining with\\ncorresponding training datasets D := {D1, . . . , DN}, each related to a specific knowledge domain such as\\nmath, code, etc. The proposed method contains three stages: Branch, Train, and MiX.\\n3.1\\nBranch & Train: Embarrassingly Parallel Expert Training\\nInitializing from the seed model M, we train N expert LLMs {M1, . . . , MN}, with each model Mi being\\ntrained on the corresponding dataset Di in the same manner as during pretraining, using the usual language\\nmodeling objective. Since each expert model Mi can be trained in complete separation from the others, the\\nwhole training process becomes N-way embarrassingly parallel. This training paradigm has several benefits in\\nlarge-scale distributed training. It allows linear scaling of overall training throughput when scaling up the size\\nof compute, while joint training often faces uncertain performance from increasing batch size. It has lower\\nall-to-all communication cost. It is also more resilient, as a single training failure will only affect one of the N\\ntraining processes instead of halting the entire training.\\nAfter all the expert training is finished, we will end up with N different LLMs, with each specializing in a\\nspecific distribution. At this point, the Branch-Train-Merge method (Li et al., 2022a; Gururangan et al.,\\n2023) uses these domain experts as is, choosing which expert to use by determining which domain the input\\nbelongs to at inference time. Usually multiple experts are chosen, and their final output distributions are\\nsimply averaged to generate the next token. Our BTX approach, in contrast, merges these domain experts\\nback into a single LLM that is finetuned further, as we will describe in the next section.\\n3\\n3.2\\nMiX: Combining Separate Experts to be a Mixture-of-Experts\\nWe employ a Mixture-of-Experts approach to combine the domain expert models Mi. However, instead\\nof using the classical procedure of mixing the final outputs from Mi, we do a more fine-grained mixing by\\nperforming MoE within each layer of a Transformer. In particular, we combine the different feedforward\\nsublayers from the domain experts into a single MoE sublayer. If FFl\\ni(x) is the feedforward sublayer at the\\nl-th layer of the i-th domain expert Mi, then the combined MoE layer for input representation x at layer l\\nwill compute:\\nFFl\\nMoE(x) =\\nN\\nX\\ni=1\\ngi(Wlx)FFl\\ni(x).\\nHere Wl is a linear transformation and g is a routing function, which usually has sparse output and hence\\nswitches on only some experts. Since we can skip computing FFl\\ni(x) if the corresponding router output is zero,\\nthe actual computation of FFl\\nMoE(x) will be much more efficient than computing all domain experts. However,\\nrouting decisions can change from token to token, so one input sequence can employ all the domain expert FF\\nlayers if needed, even when only a few are accessed at any given token. In our experiments, we use Top-k\\n(k=2) routing where g(Wlx) = SoftMax(TopK(Wlx)), unless otherwise stated.\\nFor the self-attention sublayers, we combine the different domain experts by simply averaging their weights.\\nThe motivation behind this is the assumption that the self-attention layers are less domain specialized than\\nthe feedforward layers. We do the same averaging for the remaining parameters (embeddings, etc.) as well.\\nNote that the only new parameters we introduce are the router’s transformation parameters Wl, which\\nare negligible in size compared to the rest of the network. Nevertheless, those new parameters need to\\nbe finetuned, so the router can make optimal decisions in selecting which domain FFi to use. In addition,\\nfunetuning is helpful because the self-attention weights are constructed by averaging, and are likely not\\noptimal. Overall, the entire system has not been optimized for working together at all in the embarrassingly\\nparallel training framework, but our hypothesis is that even a small amount of combined finetuning might\\nmake large improvements.\\n3.3\\nVariations\\nWe also experimented with several variations of our method.\\nLoad balancing\\nA common problem with MoE is the emergence of dead experts, which do not get activated\\nby the router at all. Common routing methods like Top-k are unlikely to escape from such a situation because\\na dead expert is never in the top-k selection, and therefore never receives a training signal. Load balancing\\noffers a simple solution by adding an extra loss term that encourages the experts to be utilized equally. We\\nuse a loss term similar to (Fedus et al., 2022):\\nLLB = αN\\nN\\nX\\ni=1\\nuipi\\nwhere ui = 1\\n|B|\\nX\\nx∈B\\ngi(Wlx) and pi = 1\\n|B|\\nX\\nx∈B\\nSoftMaxi(Wlx).\\nHere B is the current data batch, and α is a hyperparameter. This loss is computed in each layer and added\\nto the NLL loss.\\nRouting method\\nBesides Top-k routing, we also experiment with other routing methods:\\n• Switch: It is a Top-1 routing method proposed by Fedus et al. (2022).\\n• Soft routing: We use softmax as the routing function g, so all experts are activated both during training\\nand inference. While it is likely to provide the best performance, it comes at the expense of increased\\ncompute.\\n• Sample Top-1: We use the gumbel softmax (Jang et al., 2016) for g. At training time, we generate\\na soft sample from the gumbel softmax, but zero out all its values except the largest one. Then we\\ncompute only one expert corresponding to this largest value, omitting the other expert computations.\\n4\\nAt inference time, we simply do hard sampling. We anneal the temperature to a sharp distribution at\\nthe end of training to gradually reduce the discrepancy between training and inference.\\nSplitting Experts\\nThe number of modules in the MoE layer matches the number of domains we train on,\\nsince each module corresponds to one domain. However, we can increase the number of modules in a simple\\nway by splitting each domain FF sublayer into multiple chunks. Given N domains and an FF activation size\\nof dFF, we split each FF layer into C chunks with a dimension of dFF/C. As a result, the final MoE layer will\\nhave MC modules.\\nBlending Experts\\nInstead of directly initializing MoE experts from domain experts in a one-to-one way, we\\nalso try including all domains in each MoE expert. The motivation behind this is an observation that MoE\\nexperts trained in a standard way do not show domain specialization, but rather are activated uniformly\\nacross different domains (Jiang et al., 2024). In contrast, our domain experts are specialized to a specific\\ndomain through their training data. To break this domain specialization, we split each domain expert’s FF\\nlayers into N chunks and then merge the n-th chunks from all domains to build the n-th MoE expert. This\\nway, each MoE expert contains the same amount of parameters from all domains.\\n4\\nExperiments\\n4.1\\nExperimental Setup\\nWe base our experiments on the setup used for Llama-2 pretraining (Touvron et al., 2023). In particular, we\\nuse the Llama-2 7B model as our seed model.\\n4.1.1\\nBTX Training\\nWe use the pretrained Llama-2 (Touvron et al., 2023) with 7B parameters as our seed model. After making\\nthree copies of the seed model Llama-2 7B, we continue training them on the following domain datasets to\\nderive three domain experts:\\n• Math: The same data sources and mixture used in Llemma (Azerbayev et al., 2023) model training.\\nTo be comparable to Llemma, we train on the same amount of data as well, i.e. 48k steps with 201B\\ntokens in total.\\n• Code: The same data sources and mixture of code data used in CodeLlama pretraining (Rozière\\net al., 2023). The code expert LLM is trained for 50k steps with 210B tokens in total to be comparable\\nwith the math expert.\\n• Wikipedia: Wikipedia documents extracted between June to August 2022. The data was preprocessed\\nto remove hyperlinks, comments and other formatting boilerplate. Since this is a smaller dataset, we\\ntrain a total of 42B tokens.\\nWhile we can proceed with only these three domain experts, we also include the original seed LLM as a\\n“generalist” expert so that its general knowledge is transferred to the final model. Thus we mix these four\\nexpert models into a single MoE model as described in Section 3.2. Then we finetune this MoE model on\\nall the data sources used to train the four experts (including the original Llama-2 7B pretraining data for\\nthe generalist expert) and train for another 80B tokens. The detailed sampling ratio across datasets in each\\ndomain as well as across the domains is described in Appendix A. For BTX with default Top-2 routing, we use\\nload balancing with α = 0.01, unless otherwise stated. For the Sample Top-1 routing, we use the temperature\\nannealing schedule τ=max(0.5, −rt) from Jang et al. (2016) with r = 1e − 4 where t is the number of training\\nsteps. For the first layer only, we used soft-routing instead. Since the Sample Top-1 training is more efficient\\nthan Top-2, with the same compute budget it can train 160B tokens.\\n4.1.2\\nBaselines\\nWe compare to the following baselines:\\n5\\nMath\\nCode\\nGeneral knowledge\\nGSM8K\\nMATH\\nHuman\\nMBPP\\nNatural\\nTrivia\\nMMLU\\nEval\\nQuestions\\nQA\\nLlama-2 7B\\n14.7\\n2.5\\n12.8\\n20.8\\n16.4\\n58.5\\n46.1\\nMath expert\\n39.5\\n18.8\\n25.0\\n33.6\\n14.4\\n37.1\\n52.0\\nCode expert\\n12.0\\n4.0\\n31.7\\n40.2\\n11.5\\n29.9\\n39.6\\nWikipedia expert\\n11.7\\n3.1\\n11.0\\n15.2\\n21.8\\n57.2\\n43.1\\nTable 1 Individual domain expert LLM performance on representative tasks, compared to the seed model Llama-2 7B.\\nAs expected, the code and math experts excel at their corresponding domain tasks. The Wikipedia expert performs\\nbetter on Natural Questions, but the math expert has the best score on MMLU. This could be because MMLU contains\\nmany math subjects and math training is shown to help on this task (Shao et al., 2024).\\n• Llama-2: We compare to the original Llama-2 7B that we use as a seed model, as well as Llama-2\\n13B.\\n• Dense: Instead of training separate LLMs on different domain datasets, the dense baseline continues to\\ntrain the seed LLM with all the data. We use exactly the same training data as BTX, first training on\\nthe new domain-specific data used in the experts training stage, followed by the same data mixture\\nthat includes the Llama-2 pretraining data in the MoE finetuning stage. We call this comparison\\ndata-matching (DM).\\n• Sparse upcycling: This baseline (Komatsuzaki et al., 2022) initializes a MoE model from the seed\\nmodel by making 4 identical copies of the feedforward module as experts. We use the Top-2 router with\\nrandomly initialized Wi parameters. In addition to training a data matching baseline with the same\\ndata as is used in BTX and the dense baseline, we also train a sparse upcycling baseline with the same\\namount of GPU-days, i.e. compute-matching (CM), using the MoE finetuning data mixture throughout\\ntraining. This is equivalent to a special case of BTX which does not contain embarrassingly parallel\\nexpert training.\\n• Branch-Train-Merge (BTM): This baseline (Li et al., 2022a) uses the same expert LLMs as BTX\\n(including the original seed model) but uses them directly without building a MoE model. For a given\\ncontext (input), it selects Top-k expert LLMs based on the similarity between the context and experts’\\ntraining data. Following the efficient inference method used in Gururangan et al. (2023), both context\\nand experts’ training data are embedded via tf-idf. Top-k experts are selected based on cosine similarity\\nto the mean tf-idf embedding of each expert.\\n• CodeLlama 7B: A language model specializing in code (Rozière et al., 2023) by continued training of\\nthe same seed model Llama-2 7B on code data. It also has other features such as long-context and\\ninfilling.\\n• Llemma 7B: A language model specializing in mathematics (Azerbayev et al., 2023) by continued\\ntraining of CodeLlama 7B on math data.\\nWe use the same optimization hyperparameters for training of the baselines, expert models and MoE models.\\nWe use the AdamW optimizer with weight decay 0.1, and anneal the learning rate to the peak of 1e − 4 with\\n100 steps of warmup, and decay to 10% of the peak with a cosine schedule. We use a batch size of 4M tokens\\nwith a sequence length of 4096.\\n4.1.3\\nEvaluation\\nFor evaluation, we use the zero- and few-shot performance on multiple benchmarks that test different skills:\\n• Math: we report the average performance on GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021b) for math reasoning.\\n• Code: we report the average performance of HumanEval (0 shot) (Chen et al., 2021) and MBPP (3\\nshot) (Austin et al., 2021) for code generation.\\n6\\nMath\\nCode\\nKnowledge\\nReasoning\\nMMLU\\nAverage\\nSpecialized LLMs\\nCodeLlama 7B\\n8.1\\n36.3\\n22.2\\n56.6\\n38.6\\n37.9\\nLlemma 7B\\n28.0\\n33.5\\n17.2\\n38.8\\n33.5\\n32.1\\nGeneralist LLMs\\nLlama-2 7B\\n8.6\\n16.8\\n37.4\\n63.3\\n46.1\\n40.7\\nLlama-2 13B\\n16.3\\n24.5\\n40.0\\n66.1\\n52.8\\n45.4\\nDense (DM)\\n18.3\\n25.8\\n39.6\\n63.3\\n49.8\\n44.5\\nSparse upcycling (DM), Top-2\\n28.1\\n34.7\\n34.0\\n62.3\\n51.1\\n46.3\\nBTM, Top-1\\n21.3\\n36.4\\n26.5\\n61.0\\n44.3\\n43.1\\nBTM, Top-2\\n21.5\\n36.6\\n26.9\\n61.2\\n44.3\\n43.4\\nBTX, Sample Top-1\\n26.4\\n31.5\\n40.1\\n63.7\\n53.2\\n47.3\\nBTX, Top-2\\n27.4\\n34.0\\n41.0\\n63.5\\n52.5\\n47.9\\nTable 2 Aggregated performance of BTX compared against various baselines, including both generalist and specialized\\npretrained models, tested on various capabilities aggregated across popular benchmarks. Dense, sparse upcycling,\\nBTM and BTX are trained on exactly the same amount and mixture of data with the exception that BTM does not\\nhave the finetuning stage.\\n• World knowledge: we report the average performance of Natural Questions (5 shot)(Kwiatkowski et al.,\\n2019) and TriviaQA (5 shot) (Joshi et al., 2017).\\n• Reasoning: we report the average 0-shot performance of ARC-Easy and ARC-Challenge (Clark et al.,\\n2018), SIQA (Sap et al., 2019), PIQA (Bisk et al., 2020) and WinoGrande (Sakaguchi et al., 2021).\\n• General: we report performance on MMLU (5 shot) (Hendrycks et al., 2021a) which covers multiple\\ndomains.\\n4.2\\nMain Results\\n4.2.1\\nOverall Performance\\nDomain experts excel at their respective tasks.\\nWe first analyze how expert LLMs specialize to specific domains.\\nResults are summarized in Table 1. As expected, individual expert LLMs achieve the best performance in\\ntheir respective domain, where the math and code domains see especially large improvements. In addition,\\nthere are several interesting observations. We see that the math expert training improved its code performance\\nas well, indicating a close relation of these domains. However, such single-domain continued training also\\nsuffers from catastrophic forgetting with significant performance drops on some tasks in other domains. For\\nexample, the math and code expert are much worse on TriviaQA than the seed model.\\nBTX improves all tasks where experts specialize.\\nTable 2 and Figure 2 (right) show aggregated performance\\nacross multiple domains. More detailed per-task results are reported in Table 8 in the Appendix. Compared\\nto the seed model Llama-2 7B, BTX models (both Sample Top-1 and Top-2 corresponding to different\\nnumber of active parameters) improve on all expert domains, such as math, coding and world knowledge\\nwithout regressing on other tasks such as commonsense reasoning. BTX with Top-2 experts (our default) also\\napproaches the best performance of the specialized models Llemma 7B and CodeLlama 7B in the math\\nand coding domains, while drastically improving over those models on domains that are not their speciality\\nsuch as world knowledge and commonsense reasoning. Compared to alternative data-matching (DM) methods\\nfor continued pretraining such as dense and sparse upcycling, BTX achieves better performance on average\\nwith small gaps in the math and coding domains. BTX outperforms BTM by a large margin on average,\\nindicating that MoE finetuning to learn token-level routing is beneficial. Overall, the results demonstrate\\nthat BTX is a more compute efficient method for continued pretraining which is robust to task interference\\nfrom multi-task learning. BTX also outperforms Llama-2 13B on all tasks except reasoning, even though\\nLlama-2 13B uses significantly more training compute and has slightly more active parameters.\\nWe further compare BTX with the sparse upcycling baseline in the compute-matching (CM) scenario. Both\\n7\\n0\\n500\\n1000\\n1500\\n2000\\n2500\\n3000\\nTrain GPU days (from the seed model)\\n40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\nAverage score\\nLlama-2 7B\\n(seed)\\nLlama-2 13B\\nDense (DM)\\nSparse\\nUpcycling (CM)\\nBTM\\nBTX\\nMath\\nCode\\nKnowledge\\nReasoning\\nMMLU\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nLlama-2 7B\\nLlama-2 13B\\nCodeLlama 7B\\nBTX\\nFigure 2 Left: The average performance vs training budget of BTX compared to various baselines, with different\\nactive parameters at inference time indicated by circle size. All the models except Llama-2 13B are trained starting\\nfrom Llama-2 7B using the datasets described in Section 4.1.1. The X-axis shows the total training compute starting\\nfrom the seed model measured in GPU days1, and the Y-axis is the average score over all the tasks (as computed in\\nTable 2). The BTX models outperform the baselines that started from the same seed model, as well as Llama-2 13B.\\nRight: The normalized performance over different domains where the scores are divided by the highest one. We see\\nlarge improvements for BTX in code (which matches the specialized model) and math tasks compared to the seed\\nmodel Llama-2 7B, even outperforming the Llama-2 13B model.\\nMoE\\nTraining\\nTotal compute #tokens Math Code Knowledge Reasoning MMLU Average\\ncompute time (days)\\n(GPU-days)\\n(B)\\nBTX\\n23%\\n7.8\\n926.1\\n533\\n27.4\\n34.0\\n41.0\\n63.5\\n52.5\\n47.9\\nSparse upcycling (CM)\\n100%\\n7.9\\n1007.1\\n252\\n28.2\\n30.7\\n41.3\\n62.9\\n52.1\\n47.3\\nTable 3 Comparison between BTX and Sparse upcycling with compute-matching (CM), which is a special case of BTX\\nwithout the expert training stage as is shown by the first column that 100% of compute is spent on MoE training. We\\nalso report total training time, compute and number of training tokens. Comparing both performance on individual\\ndomains as well as the average, we can see that BTX has more balanced performance, in addition to higher throughput.\\ntrain on the same data mixture during the MoE stage, but differ in terms of the percent of compute spent on\\nMoE training. While sparse cycling performs close behind BTX, the parallel training of experts increases the\\ntraining throughput of BTX, as is shown in Table 3. As a result, BTX can train with more than 2× the data\\nthan pure MoE given the same training compute budget, and achieves slightly higher average performance\\nacross all domains.\\n4.2.2\\nBetter compute-performance tradeoff\\nWe compare BTX with baselines in terms of compute efficiency in Figure 2 (left). The X-axis shows the total\\ntraining compute starting from the seed model measured in GPU days, which includes the domain expert\\ntraining and finetuning of the MoE model. The Y-axis measures the overall performance reported in Table 2.\\nBetter performance than dense and BTM.\\nDespite that the MoE training stage uses a fraction of the\\ntotal training budget in pretraining (for example, Llama-2 pretraining uses 2T tokens), BTX brings steep\\nimprovements on general capabilities compared to alternative continued pretraining approaches such as\\nmulti-task learning of the dense model and Branch-Train-Merge.\\n1The GPU days of Llama-2 13B is an approximate measurement, calculated by doubling the training compute of a 7B model\\ntrained with the same amount of pretraining data (according to Touvron et al. (2023) Table 2). Since Llama-2 13B is not trained\\nfrom the seed model, we simply report their difference in GPU days.\\n8\\nRouting method\\nActive parameters (B)\\nMoE Finetune\\ntokens (B)\\nAverage\\nscore\\nTraining\\nInference\\nSwitch Top-1\\n6.7\\n6.7\\n10\\n24.7\\nSample Top-1\\n6.7\\n6.7\\n10\\n33.0\\nTop-2\\n11.1\\n11.1\\n10\\n34.6\\nSoft routing\\n19.7\\n19.7\\n10\\n35.8\\nSample Top-1\\n6.7\\n6.7\\n40\\n35.3\\nTop-2\\n11.1\\n11.1\\n40\\n35.9\\nSoft routing\\n19.7\\n19.7\\n40\\n37.3\\nSample Top-1\\n6.7\\n6.7\\n160\\n36.9\\nTop-2\\n11.1\\n11.1\\n80\\n37.3\\nTable 4 Ablations on different routing methods during BTX training. Average score is based on performance on\\nrepresentative tasks including GSM8K, HumanEval, Natural Questions, ARC Challenge and MMLU.\\nGSM8K\\nHuman\\nNatural\\nARC\\nMMLU\\nAverage\\nEval\\nQuestions\\nChallenge\\nScore\\nBTX\\n29.8\\n27.4\\n23.0\\n43.4\\n50.0\\n34.7\\nno load-balancing (LB)\\n34.6\\n19.5\\n23.2\\n44.4\\n51.6\\n34.6\\nno LB & freeze experts\\n34.8\\n18.3\\n24.1\\n44.9\\n51.4\\n34.7\\nblending experts\\n13.9\\n17.1\\n9.9\\n34.1\\n36.2\\n22.2\\nsplit experts, top-2 of 8\\n22.0\\n20.1\\n16.8\\n39.1\\n41.8\\n28.0\\nsplit experts, top-4 of 8\\n29.6\\n26.8\\n22.9\\n44.0\\n49.4\\n34.5\\nTable 5 Ablations on different BTX training strategies. All variants are initialized from the same experts and trained\\nfor a total of 10B tokens during MoE finetuning.\\nMore efficient than sparse upcycling.\\nAs a special case of BTX, sparse upcycling without expert training\\noutperforms dense and BTM but not BTX, given the same or larger compute budget. The compute efficiency\\ngains of BTX are from the embarrassingly parallel training of experts before MoE finetuning.\\nIn terms of the active number of parameters (shown as circle sizes in 2 (left)), the MoE models are similar to\\nthe Llama-2 13B model. BTX uses less than half of the additional training compute compared to Llama-2\\n13B, but demonstrates improved performance on expert domains (math, code, and knowledge) and achieves\\nbetter overall performance. This indicates that BTX’s training is more effective for the late stage of pretraining\\nthan using the same training protocol throughout the entire of pretraining.\\n4.3\\nAblations & Analysis\\n4.3.1\\nAblations of BTX training\\nFirst, we compare the different routing methods with varying amount of active parameters for different\\namounts of finetuning. For fair comparison, load balancing is not used in any of them. Results are shown in\\nTable 4. For Switch routing, we set its capacity factor to 1.5 (a hard limit after which routed tokens will be\\ndropped). We found the Switch router to be subpar in average performance. The soft routing performs the\\nbest, but that is expected since it lacks sparsity and has the highest number of active parameters. Overall,\\nthe Top-2 routing gives us a good balance between performance and efficiency.\\nWe also ablate additional design choices of BTX, with results summarized in Table 5. We found that MoE\\ntraining without load balancing performs worse on the coding task (HumanEval), but has higher math\\n(GSM8k) accuracy. The routing analysis in the next section will give more insight into this trade-off. Next,\\nfreezing the feedforward modules initialized from each expert, and only training the rest of the MoE model has\\nlittle impact on performance across all tasks. This suggests that individual experts already gained sufficient\\ndomain knowledge during the branch-train stage, while the mix (MoE finetuning) stage mainly trains the\\n9\\nWiki\\nMath\\nCode\\nLLaMa-2 7B\\n0.0\\n0.1\\n0.2\\n0.3\\n0.4\\nLayer 1\\nWiki\\nMath\\nCode\\nLLaMa-2 7B\\nLayer 16\\nWiki\\nMath\\nCode\\nLLaMa-2 7B\\nLayer 32\\nTop-2 routing with load-balancing\\nWiki\\nMath\\nCode\\nLLaMa-2 7B\\n0.0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\nLayer 1\\nWiki\\nMath\\nCode\\nLLaMa-2 7B\\nLayer 16\\nWiki\\nMath\\nCode\\nLLaMa-2 7B\\nLayer 32\\nTop-2 routing with no load-balancing\\nMath domain\\nCode domain\\nWorld knowledge\\nReasoning\\nFigure 3 BTX routing decisions of the tokens at various layers to different experts (Wiki, Math, Code, LLaMa-2 7B)\\nfor different downstream tasks. The tasks are aggregated by domain: Code (Human Eval, MBPP), Math (GSM8K,\\nMATH), World knowledge (Natural Questions, TriviaQA), and Reasoning (ARC-Easy, ARC-Challenge, SIQA, PIQA,\\nand WinoGrande). We observe that Top-2 routing with load balancing (top) ensures a more uniform distribution of\\nthe load between experts compared to Top-2 without load balancing (bottom).\\nother parameters such as averaged weights in the self-attention and the router transformations Wi.\\nWe also test our blending and splitting techniques described in Section 3.3. The performance across all tasks\\ndropped when experts are mixed, suggesting that domain FF layers cannot be mixed in this way. Splitting\\neach domain FF into C = 2 chunks to obtain 8 modules in the MoE layer also does not improve performance,\\neven if Top-4 routing is used to match the active number of parameters.\\n4.3.2\\nRouting Analysis\\nTo gain an in-depth understanding of the performance of BTX, we run model evaluations on downstream\\ntasks and examine the routing decisions among the experts. The results are summarized in Figure 3, and we\\nalso report detailed ablation results for different BTX setups in Appendix C. Compared to other routing\\nmethods, Top-2 routing with load balancing ensures a more uniform distribution of the load between experts.\\nAnalyzing the token probability distributions, we observe a shift towards low probability scores across all\\nexperts with load balancing, especially closer to the final layers of the model, which contributes to the fair\\nrouting. Interestingly, all models without load balance heavily rely on the Math expert, with a low overall\\ncontribution from other experts, especially the Code expert. A dead Code expert comes “back to life” with\\nload balancing introduced in training. In fact, it not only becomes visible, but becomes the dominant expert\\nin the math and code domains.\\nExamples of the routing decisions for Top-2 with load balancing can be found in the Table 6. Overall across\\nmath domain tasks, tokens are often routed to the Code and Llama-2 7B experts. If we look at a more\\ndetailed token distribution (Appendix C, Figure 6), we find that the GSM8K task prefers Code and Llama-2\\nexperts, while the MATH task relies more on the in-domain Math expert. We hypothesise that this happens\\nbecause the GSM8K dataset consists of grade school math problems that require common sense knowledge and\\nbasic arithmetic operations. Both the Code and World knowledge tasks mostly route to the in-domain Code\\nand Wikipedia experts respectively. As observed earlier in Section 4.3.1, when load balancing is introduced,\\nthere are improvements in coding tasks but degradation in math tasks, which can be explained with these\\nchanges in domain expert routing. The reasoning tasks in contrast exhibit similar behaviour, and rely equally\\n10\\nTask\\nQuestion and generation\\nGSM8K\\nQ: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for\\nher friends every day with four. She sells the remainder at the farmers’ market daily for $2 per fresh\\nduck egg. How much in dollars does she make every day at the farmers’ market?\\nA: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning. So she has 16 - 3 =\\n13 eggs left. She bakes muffins for her friends every day with 4. So she has 13 - 4 = 9 eggs left. She\\nsells the remainder at the farmers’ market daily for $2 per fresh duck egg. So she has 9 * 2 = 18 dollars.\\nThe answer is 18.\\nHuman Eval\\nQ: from typing import List\\ndef has_close_elements(numbers: List[float], threshold: float)-> bool:\\n\"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\ngiven threshold.\\n> > > has_close_elements([1.0, 2.0, 3.0], 0.5)\\nFalse\\n> > > has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\nTrue\\n\"\"\"\\nA: for i in range(len(numbers) - 1):\\nfor j in range(i + 1, len(numbers)):\\nif abs(numbers[i] - numbers[j]) < threshold:\\nreturn True\\nreturn False\\nNatural\\nQuestions\\nQ: who got the first nobel prize in physics\\nA: Max Planck\\nTable 6 Examples of the token routing decisions for the Top-2 routing with load balancing in the math (GSM8K), code\\n(Human Eval), and knowledge (Natural Questions) domains. Tokens highlighted are routed to the following experts:\\nWikipedia and LLaMa-2 7B, Math and LLaMa-2 7B, Code and LLaMa-2 7B, Math and Code, Wikipedia and\\nMath, Wikipedia and Code. Tokens that were routed to the in-domain expert are underlined.\\non Math and generalist LLM’s expertise.\\n5\\nConclusion\\nWe introduced Branch-Train-MiX (BTX), a simple continued pretraining method to improve an LLM’s\\ncapabilities. It trains multiple copies of a seed LLM to specialize in multiple domains in an asynchronous and\\nparallel fashion and later merges them back into a single Mixture-of-Experts (MoE) model via finetuning.\\nWhile the initial parallel training stage brings higher training throughput and scalability, the second MoE\\nfinetuning stage makes the final LLM more performant. Our experiments suggest that a generalist LLM’s\\nperformance can be boosted by continued training on datasets with specialized knowledge and skills using our\\nmethod. We find that the BTX approach is more compute efficient than training a larger generalist LLM or\\nseveral separately specialized LLMs. These insights can inform how to allocate compute in late pretraining to\\nachieve a strong generalist model.\\n6\\nLimitations & Future Work\\nAlthough our experimental results on BTX are promising, we have not fully explored its potential in this\\npaper. Due to compute limitations, we only experimented with three domains and four experts in this paper.\\nTraining on more domains such as using unsupervised domain discovery (Gururangan et al., 2023) should\\namplify the benefit of the parallelization of experts training. Having more experts will also make the final\\nMoE model more efficient because the number of active experts can remain the same while its overall capacity\\nincreases. In our experiments, we used a simple implementation of MoE and did not optimize it using more\\ncomplex techniques such as placing different experts on different GPUs to run them in parallel. Such an\\nefficient MoE implementation could shorten the training time of BTX, and the sparse upcycling baseline as\\nwell.\\n11\\nCompared to BTM, BTX provides an approach to finetune the combined experts, which can be directly\\napplied in instruction finetuning or RLHF procedures. However, we leave that for future work as we focused\\non the pretraining stage in this paper.\\nThe question of whether experts in MoE are better off specializing in specific domains or not is an interesting\\none that is worth further investigation. Our approach explicitly tied experts to certain domains, but such\\nspecialization does not seem to emerge naturally during MoE training (Jiang et al., 2024). We observed that\\nsome experts are used more in their corresponding domain tasks, showing that their domain specialization\\npartially remains even after the MoE finetuning.\\nWe only compared BTX to two of its special variants, i.e. BTM with 100% compute allocated to expert\\ntraining and 0% on MoE finetuning, and sparse upcycling with 0% compute allocated to expert training\\nand 100% on MoE finetuning. Future work could perform a thorough sweep of the compute allocation ratio\\nbetween expert training and MoE training. Also, we did not perform experiments with different data mixtures\\nfor MoE finetuning other than uniform sampling.\\n7\\nAcknowledgements\\nWe thank Margaret Li, Kushal Tirumala, Luke Zettlemoyer, Artidoro Pagnoni, Suchin Gururangan, Mike\\nLewis and Emily Dinan for their discussion and feedback, and Andrew Cohen and Arun Babu for their help\\nwith the training implementation.\\n12\\nReferences\\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida,\\nJanko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774,\\n2023.\\nRahaf Aljundi, Punarjay Chakravarty, and Tinne Tuytelaars. Expert gate: Lifelong learning with a network of\\nexperts. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 7120–7129, 2016.\\nhttps://api.semanticscholar.org/CorpusID:914027.\\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang,\\nCarrie J. Cai, Michael Terry, Quoc V. Le, and Charles Sutton. Program synthesis with large language models.\\nArXiv, abs/2108.07732, 2021. https://api.semanticscholar.org/CorpusID:237142385.\\nAbhijeet Awasthi and Sunita Sarawagi. Continual learning with neural networks: A review. In Proceedings of the\\nACM India Joint International Conference on Data Science and Management of Data, pages 362–365, 2019.\\nZhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Albert Q. Jiang, Jia Deng,\\nStella Biderman, and Sean Welleck. Llemma: An open language model for mathematics. ArXiv, abs/2310.10631,\\n2023. https://api.semanticscholar.org/CorpusID:264172303.\\nYonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about physical commonsense in natural\\nlanguage. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 7432–7439, 2020.\\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\\nPranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J.\\nHenighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark\\nChen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish,\\nAlec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. ArXiv, abs/2005.14165,\\n2020. https://api.semanticscholar.org/CorpusID:218971783.\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura\\nBurda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,\\nGirish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\\nKaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, David W. Cummings, Matthias\\nPlappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Igor Babuschkin,\\nSuchir Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford,\\nMatthew M. Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei,\\nSam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code. ArXiv,\\nabs/2107.03374, 2021. https://api.semanticscholar.org/CorpusID:235755472.\\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.\\nThink you have solved question answering? Try ARC, the AI2 reasoning challenge. arXiv preprint arXiv:1803.05457,\\n2018.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert,\\nJerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve\\nmath word problems. arXiv preprint arXiv:2110.14168, 2021.\\nDamai Dai, Chengqi Deng, Chenggang Zhao, R. X. Xu, Huazuo Gao, Deli Chen, Jiashi Li, Wangding Zeng, Xingkai\\nYu, Y. Wu, Zhenda Xie, Y. K. Li, Panpan Huang, Fuli Luo, Chong Ruan, Zhifang Sui, and Wenfeng Liang.\\nDeepseekmoe: Towards ultimate expert specialization in mixture-of-experts language models. ArXiv, abs/2401.06066,\\n2024. https://api.semanticscholar.org/CorpusID:266933338.\\nArthur Douillard, Qixuang Feng, Andrei A. Rusu, Rachita Chhaparia, Yani Donchev, Adhiguna Kuncoro, Marc’Aurelio\\nRanzato, Arthur Szlam, and Jiajun Shen. Diloco: Distributed low-communication training of language models.\\nArXiv, abs/2311.08105, 2023. https://api.semanticscholar.org/CorpusID:265158012.\\nWilliam Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter models with simple\\nand efficient sparsity. The Journal of Machine Learning Research, 23(1):5232–5270, 2022.\\nGemini Team. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023. Team,\\nGemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and\\nSoricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others.\\n13\\nSuchin Gururangan, Michael Lewis, Ari Holtzman, Noah A. Smith, and Luke Zettlemoyer. Demix layers: Disentangling\\ndomains for modular language modeling. In North American Chapter of the Association for Computational Linguistics,\\n2021. https://api.semanticscholar.org/CorpusID:236976189.\\nSuchin Gururangan, Margaret Li, Mike Lewis, Weijia Shi, Tim Althoff, Noah A Smith, and Luke Zettlemoyer. Scaling\\nexpert language models with unsupervised domain discovery. arXiv preprint arXiv:2303.14177, 2023.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring\\nmassive multitask language understanding. In 9th International Conference on Learning Representations, ICLR 2021,\\nVirtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021a. https://openreview.net/forum?id=d7KBjmI3GmQ.\\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Xiaodong Song, and\\nJacob Steinhardt. Measuring mathematical problem solving with the math dataset. ArXiv, abs/2103.03874, 2021b.\\nhttps://api.semanticscholar.org/CorpusID:232134851.\\nRobert A. Jacobs, Michael I. Jordan, Steven J. Nowlan, and Geoffrey E. Hinton. Adaptive mixtures of local experts.\\nNeural Computation, 3:79–87, 1991. https://api.semanticscholar.org/CorpusID:572361.\\nEric Jang, Shixiang Gu, and Ben Poole.\\nCategorical reparameterization with gumbel-softmax.\\narXiv preprint\\narXiv:1611.01144, 2016.\\nAlbert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh\\nChaplot, Diego de Las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume\\nLample, L’elio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia\\nYang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and\\nWilliam El Sayed. Mixtral of experts. ArXiv, abs/2401.04088, 2024. https://api.semanticscholar.org/CorpusID:\\n266844877.\\nMandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge\\ndataset for reading comprehension.\\nArXiv, abs/1705.03551, 2017.\\nhttps://api.semanticscholar.org/CorpusID:\\n26501419.\\nAran Komatsuzaki, Joan Puigcerver, James Lee-Thorp, Carlos Riquelme Ruiz, Basil Mustafa, Joshua Ainslie, Yi Tay,\\nMostafa Dehghani, and Neil Houlsby. Sparse upcycling: Training mixture-of-experts from dense checkpoints. ArXiv,\\nabs/2212.05055, 2022. https://api.semanticscholar.org/CorpusID:254535822.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle\\nEpstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei\\nChang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: a benchmark for question\\nanswering research. Transactions of the Association of Computational Linguistics, 2019.\\nMatthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory G. Slabaugh,\\nand Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE Transactions\\non Pattern Analysis and Machine Intelligence, 44:3366–3385, 2019. https://api.semanticscholar.org/CorpusID:\\n218889912.\\nMike Lewis, Shruti Bhosale, Tim Dettmers, Naman Goyal, and Luke Zettlemoyer. Base layers: Simplifying training\\nof large, sparse models. In International Conference on Machine Learning, 2021. https://api.semanticscholar.org/\\nCorpusID:232428341.\\nMargaret Li, Suchin Gururangan, Tim Dettmers, Mike Lewis, Tim Althoff, Noah A. Smith, and Luke Zettlemoyer.\\nBranch-train-merge: Embarrassingly parallel training of expert language models. ArXiv, abs/2208.03306, 2022a.\\nhttps://api.semanticscholar.org/CorpusID:251371375.\\nYujia Li, David H. Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom, Eccles, James\\nKeeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de, Masson d’Autume, Igor\\nBabuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey, Cherepanov, James Molloy,\\nDaniel Jaymin Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de, Freitas, Koray Kavukcuoglu,\\nand Oriol Vinyals. Competition-level code generation with alphacode. Science, 378:1092 – 1097, 2022b. https:\\n//api.semanticscholar.org/CorpusID:246527904.\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini\\nAgarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke E. Miller, Maddie Simens,\\nAmanda Askell, Peter Welinder, Paul Francis Christiano, Jan Leike, and Ryan J. Lowe. Training language models to\\nfollow instructions with human feedback. ArXiv, abs/2203.02155, 2022. https://api.semanticscholar.org/CorpusID:\\n246426909.\\n14\\nStephen Roller, Sainbayar Sukhbaatar, Arthur Szlam, and Jason Weston. Hash layers for large sparse models. In\\nNeural Information Processing Systems, 2021. https://api.semanticscholar.org/CorpusID:235367626.\\nBaptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Tan, Yossi Adi, Jingyu Liu, Tal\\nRemez, Jérémy Rapin, Artyom Kozhevnikov, I. Evtimov, Joanna Bitton, Manish P Bhatt, Cristian Cantón Ferrer,\\nAaron Grattafiori, Wenhan Xiong, Alexandre D’efossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin,\\nNicolas Usunier, Thomas Scialom, and Gabriel Synnaeve. Code llama: Open foundation models for code. ArXiv,\\nabs/2308.12950, 2023. https://api.semanticscholar.org/CorpusID:261100919.\\nAndrei A. Rusu, Neil C. Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu,\\nRazvan Pascanu, and Raia Hadsell. Progressive neural networks. ArXiv, abs/1606.04671, 2016. https://api.\\nsemanticscholar.org/CorpusID:15350923.\\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial winograd\\nschema challenge at scale. Communications of the ACM, 64(9):99–106, 2021.\\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Commonsense reasoning about\\nsocial interactions. arXiv preprint arXiv:1904.09728, 2019.\\nZhihong Shao, Peiyi Wang, Qihao Zhu, R. X. Xu, Jun-Mei Song, Mingchuan Zhang, Y. K. Li, Yu Wu, and Daya Guo.\\nDeepseekmath: Pushing the limits of mathematical reasoning in open language models. ArXiv, abs/2402.03300,\\n2024. https://api.semanticscholar.org/CorpusID:267412607.\\nNoam M. Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoffrey E. Hinton, and Jeff Dean.\\nOutrageously large neural networks: The sparsely-gated mixture-of-experts layer. ArXiv, abs/1701.06538, 2017.\\nhttps://api.semanticscholar.org/CorpusID:12462234.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov,\\nSoumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen,\\nGuillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj\\nGoswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez,\\nMadian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril,\\nJenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor\\nMolybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan\\nSilva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams,\\nJian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan\\nNarang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and\\nfine-tuned chat models, 2023.\\nMitchell Wortsman, Gabriel Ilharco, Samir Yitzhak Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S. Morcos,\\nHongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, and Ludwig Schmidt. Model soups: averaging\\nweights of multiple fine-tuned models improves accuracy without increasing inference time. ArXiv, abs/2203.05482,\\n2022. https://api.semanticscholar.org/CorpusID:247362886.\\nFuzhao Xue, Zian Zheng, Yao Fu, Jinjie Ni, Zangwei Zheng, Wangchunshu Zhou, and Yang You. Openmoe: An early\\neffort on open mixture-of-experts language models. arXiv preprint arXiv:2402.01739, 2024.\\nSixin Zhang, Anna E Choromanska, and Yann LeCun. Deep learning with elastic averaging sgd. In C. Cortes,\\nN. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Sys-\\ntems, volume 28. Curran Associates, Inc., 2015.\\nhttps://proceedings.neurips.cc/paper_files/paper/2015/file/\\nd18f655c3fce66ca401d5f38b48c89af-Paper.pdf.\\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona T.\\nDiab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh\\nKoura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. Opt: Open pre-trained transformer language models.\\nArXiv, abs/2205.01068, 2022. https://api.semanticscholar.org/CorpusID:248496292.\\nJun Zhao, Zhihao Zhang, Qi Zhang, Tao Gui, and Xuanjing Huang. Llama beyond english: An empirical study on\\nlanguage capability transfer. arXiv preprint arXiv:2401.01055, 2024.\\n15\\nAppendix\\nA\\nData mixture\\nTable 7 shows the exact data mixture ratios used in training each domain expert. For finetuning the MoE\\nmodel, we sample datasets that used to train math expert, code expert, wikipedia expert and the original\\nLlama-2 7B with probabilities 30.16%, 40.31%, 10.30% and 19.23%.\\nDomain\\nDataset\\nSampling ratio (%)\\nMath\\nAlgebraicStack\\n13.57\\nOpenWebMath\\n54.27\\nArxiv\\n27.14\\nGithub\\n2.99\\nCommoncrawl\\n5.01\\nCode\\nCode\\n82.18\\nNatural language related to code\\n9.90\\nNatural language\\n6.93\\nWikipedia\\nWikipedia\\n90.91\\nCommoncrawl\\n9.09\\nTable 7 Data sources and weights for domain experts.\\nB\\nEvaluation\\nWe use the same evaluation metrics as is used in Touvron et al. (2023) and Rozière et al. (2023): for code\\ntasks (HumanEval and MBPP) we report pass@1, for math tasks (GSM8k and MATH) and knowledge tasks\\n(Natural Questions and TriviaQA) we report exact match, we report accuracy for MMLU and ARC. We use\\ngreedy decoding for all generations. Detailed results on all tasks are reported in Table 8.\\nGSM8K MATH Human MBPP\\nNatural\\nTrivia ARC-e ARC-c Wino SIQA PIQA MMLU\\nEval\\nQuestions\\nQA\\nSpecialized LLMs\\nCodeLlama 7B\\n13.0\\n3.3\\n31.1\\n41.4\\n11.5\\n32.8\\n67.4\\n34.0\\n62.7\\n46.1\\n72.9\\n38.6\\nLlemma 7B\\n39.3\\n16.7\\n25.6\\n41.4\\n9.4\\n24.9\\n28.7\\n26.8\\n50.1\\n37.3\\n51.0\\n33.5\\nGeneralist LLMs\\nLlama-2 7B\\n14.7\\n2.5\\n12.8\\n20.8\\n16.4\\n58.5\\n76.4\\n43.8\\n69.2\\n48.3\\n78.8\\n46.1\\nLlama-2 13B\\n28.7\\n3.9\\n18.3\\n30.6\\n16.1\\n63.8\\n77.3\\n49.4\\n73.0\\n50.1\\n80.8\\n52.8\\nDense (DM)\\n26.7\\n9.9\\n20.7\\n30.8\\n24.0\\n55.3\\n76.7\\n44.5\\n68.9\\n48.3\\n78.2\\n49.8\\nSparse upcycling (DM), Top-2\\n37.3\\n18.9\\n29.3\\n40.2\\n18.8\\n49.2\\n76.3\\n43.4\\n66.4\\n47.3\\n77.9\\n51.1\\nSparse upcycling (CM), Top-2\\n40.1\\n16.2\\n26.2\\n35.2\\n24.5\\n58.2\\n75.6\\n44.7\\n69.1\\n47.1\\n78.0\\n52.1\\nBTM, Top-1\\n27.4\\n15.2\\n30.8\\n41.9\\n15.0\\n38.0\\n72.8\\n38.1\\n68.4\\n47.8\\n77.9\\n44.3\\nBTM, Top-2\\n27.7\\n15.3\\n30.6\\n42.6\\n15.3\\n38.5\\n73.1\\n38.5\\n68.3\\n48.0\\n78.1\\n44.3\\nBTX, sample Top-1\\n36.9\\n15.8\\n25.6\\n37.4\\n23.7\\n56.4\\n76.7\\n45.0\\n70.6\\n48.0\\n78.2\\n53.2\\nBTX, Top-2\\n37.1\\n17.8\\n28.7\\n39.4\\n24.8\\n57.1\\n76.9\\n45.6\\n67.9\\n48.7\\n78.7\\n52.5\\nTable 8 Individual task performance of BTX and baselines.\\nC\\nRouting analysis\\nLayer-by-layer comparison of the routing decision for different router designs and downstream tasks aggregated\\nby task domain is shown in Figure 4. Routing distributions slightly vary in the first few layers, but quickly\\nbecome indistinguishable from layer to layer. One exception is in Switch routing where Math expert becomes\\ndominant across tasks in the last model layer.\\n16\\nWe observe that Code expert is a dominant force in Code domain in Top-2 routing with load balancing. Note\\nthe difference with other models where load balancing is not added, and Math expert prevails across domains.\\nWe look at Code domain closer and compare routing probability distribution for models with and without load\\nbalancing in Figure 5. On the bottom three graphs of the picture we can observe a phenomena of the dead\\nexpert, where routing probability to Code expert shifted to 0, while with load balancing added, probability\\ndistributions across experts look more similar, with slightly higher expectations for the Code expert.\\nTo understand if experts specialize in other domains, we look closer at per-task distribution. Routing decision\\nof the tokens in Math and Reasoning domains are shown in Figure 6. We observe that GSM8K task prefers\\nCode and Llama-2 experts, while Math task more relies on in-domain expert. We hypothesise that this\\nhappens because GSM8K dataset consists of grade school math word problems that require common sense\\nknowledge and basic arithmetic operations, while Math task requires college-level math knowledge, and more\\naligned with Math expert’s training data. In the Reasoning domain, all tasks exhibit similar behaviour and\\nequally rely on Math and generalist LLM’s expertise.\\n17\\n18\\nFigure 4 BTX routing decisions of the tokens at various layers to different experts (Wiki, Math, Code, LLaMa-2 7B)\\nfor different downstream tasks. The tasks are aggregated by domain: Code (Human Eval, MBPP), Math (GSM8K,\\nMATH), World knowledge (Natural Questions, TriviaQA), and Reasoning (ARC-Easy, ARC-Challenge, SIQA, PIQA,\\nand WinoGrande). We observe that top-2 routing with load balancing ensures more uniform distribution of the load\\nbetween experts compared to the other routing methods across all layers.\\n19\\nFigure 5 Routing probabilities per expert across different layers for Human Eval task. We compare top-2 routing with\\n(left) and without load balancing (right).\\n20\\nFigure 6 Routing decision of the tokens in Math and Reasoning domains. We observe that GSM8K task prefers Code\\nand Llama-2 experts, while MATH task relies more on in-domain expert. In the Reasoning domain, the load is\\ndistributed between Math and LLaMa-2 7B experts.\\n21\\n', metadata={'Published': '2024-03-12', 'Title': 'Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM', 'Authors': 'Sainbayar Sukhbaatar, Olga Golovneva, Vasu Sharma, Hu Xu, Xi Victoria Lin, Baptiste Rozière, Jacob Kahn, Daniel Li, Wen-tau Yih, Jason Weston, Xian Li', 'Summary': 'We investigate efficient methods for training Large Language Models (LLMs) to\\npossess capabilities in multiple specialized domains, such as coding, math\\nreasoning and world knowledge. Our method, named Branch-Train-MiX (BTX), starts\\nfrom a seed model, which is branched to train experts in embarrassingly\\nparallel fashion with high throughput and reduced communication cost. After\\nindividual experts are asynchronously trained, BTX brings together their\\nfeedforward parameters as experts in Mixture-of-Expert (MoE) layers and\\naverages the remaining parameters, followed by an MoE-finetuning stage to learn\\ntoken-level routing. BTX generalizes two special cases, the Branch-Train-Merge\\nmethod, which does not have the MoE finetuning stage to learn routing, and\\nsparse upcycling, which omits the stage of training experts asynchronously.\\nCompared to alternative approaches, BTX achieves the best accuracy-efficiency\\ntradeoff.'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9a5a0-4226-4616-8e57-7d9644968b7a",
   "metadata": {},
   "source": [
    "Add paper text to a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0304c16-0e3d-45b8-be1c-ba92850c71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "ds_name = \"AI_SOTA_ArxiV\"\n",
    "ds = client.create_dataset(dataset_name=ds_name)\n",
    "client.create_examples(\n",
    "    inputs=[{\"paper\": doc.page_content} for doc in docs], dataset_id=ds.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0f3d8-0d6a-493f-86dc-a292d91b3906",
   "metadata": {},
   "source": [
    "## 2. Test with initial prompt\n",
    "\n",
    "Test with a reasonable initial prompt for [Claude-Opus](https://python.langchain.com/docs/integrations/chat/anthropic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "624d93d3-2889-4d34-be85-ae295ea82c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LLM\n",
    "chat_OPUS = ChatAnthropic(temperature=0, model_name=\"claude-3-opus-20240229\")\n",
    "chat_GPT4 = ChatOpenAI(temperature=0, model=\"gpt-4-32k-0613\") #gpt-4-32k-0613 gpt-4-0125-preview\n",
    "\n",
    "\n",
    "# Prompt\n",
    "system = (\n",
    "    \"<role> You are an assistant that generates Tweets to distill / summarize\"\n",
    "    \" an academic paper or open source project. It should be\"\n",
    "    \" well crafted but avoid gimicks or over-reliance on buzzwords. </role>\"\n",
    ")\n",
    "human = \"Here is a paper to convert into a Tweet: <paper> {paper} </paper>\"\n",
    "current_prompt_str = system + human\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "# Chain\n",
    "tweet_generator_Opus = prompt | chat_OPUS\n",
    "tweet_generator_GPT = prompt | chat_GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2870879-3a16-4755-8d4f-3baccb7bfdec",
   "metadata": {},
   "source": [
    "## 3. Test on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6569a-61ed-431d-a54d-f1cd9ef80df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opus = client.run_on_dataset(\n",
    "    dataset_name=ds_name,\n",
    "    llm_or_chain_factory=tweet_generator_Opus,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "882697c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'respectful-pet-42' at:\n",
      "https://smith.langchain.com/o/ad40a70f-3b43-52e1-abd3-aad46bd3324a/datasets/c36d51b6-5508-4f45-8a5b-1de34295233c/compare?selectedSessions=6442b148-ee5f-4eb3-8ebe-ce175a9e6091\n",
      "\n",
      "View all tests for Dataset AI_SOTA_ArxiV at:\n",
      "https://smith.langchain.com/o/ad40a70f-3b43-52e1-abd3-aad46bd3324a/datasets/c36d51b6-5508-4f45-8a5b-1de34295233c\n",
      "[------------------------------------------------->] 5/5"
     ]
    }
   ],
   "source": [
    "res_GPT = client.run_on_dataset(\n",
    "    dataset_name=ds_name,\n",
    "    llm_or_chain_factory=tweet_generator_GPT,\n",
    ")"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image-4.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b2aaf759-6865-4e18-bf79-c7d7aca8e73b",
   "metadata": {},
   "source": [
    "## 4. Manually evaluate\n",
    "\n",
    "We can use the LangSmith annotation queue:\n",
    "\n",
    "https://blog.langchain.dev/announcing-data-annotation-queue/\n",
    "\n",
    "1. After you've executed the res_GPT or res_opus go to LangSmith to annotation queue section\n",
    "![image.png](attachment:image.png)\n",
    "2. Provide a negative fedback to the model by putting 0 to the correctness.\n",
    "![image-2.png](attachment:image-2.png)\n",
    "3. Insert to the Note section the text with the tweet to which you wanna tairoled the model's output\n",
    "![image-3.png](attachment:image-3.png)\n",
    "4. Click \"Done\" and go the next article.\n",
    "\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "Example Tweets that we used for feedback:\n",
    "\n",
    "https://twitter.com/omarsar0/status/1767251740443746435\n",
    "\n",
    "https://x.com/omarsar0/status/1766123621326475285?s=20\n",
    "\n",
    "https://x.com/omarsar0/status/1762533498492010761?s=20\n",
    "\n",
    "https://x.com/omarsar0/status/1768288774532858003?s=20\n",
    "\n",
    "https://x.com/omarsar0/status/1767919732542378089?s=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2dd9c36-786b-43ca-9a3e-fbad8670defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = client.create_annotation_queue(name=\"AI_SOTA_ArxiV\") #\n",
    "client.add_runs_to_annotation_queue(\n",
    "    q.id,\n",
    "    run_ids=[\n",
    "        r.id\n",
    "        for r in client.list_runs(project_name=res_GPT[\"project_name\"], execution_order=1)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9bd78-07ce-4cbc-a21c-9daff49c678d",
   "metadata": {},
   "source": [
    "Pull in feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c2fbf1b-bf37-4706-9de7-78c3fd67a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def format_feedback(single_feedback, max_score=1):\n",
    "    \"\"\"\n",
    "    Formats a single feedback item into a structured string.\n",
    "\n",
    "    This function takes a feedback object and an optional maximum score,\n",
    "    then formats the feedback's score (if present) and comment into a structured\n",
    "    string representation. The feedback's key is used as an identifier in the\n",
    "    output string.\n",
    "\n",
    "    Parameters:\n",
    "    - single_feedback (object): An object representing a single piece of feedback.\n",
    "                                It must have `score`, `comment`, and `key` attributes.\n",
    "    - max_score (int, optional): The maximum possible score that can be assigned to\n",
    "                                 feedback. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "    - str: A structured string representation of the feedback, including the key,\n",
    "           score (if available), and comment.\n",
    "    \"\"\"\n",
    "    if single_feedback.score is None:\n",
    "        score = \"\"\n",
    "    else:\n",
    "        score = f\"\\nScore:[{single_feedback.score}/{max_score}]\"\n",
    "    comment = f\"\\n{single_feedback.comment}\".strip()\n",
    "    return f\"\"\"<feedback key={single_feedback.key}>{score}{comment}\n",
    "</feedback>\"\"\"\n",
    "\n",
    "\n",
    "def format_run_with_feedback(run, feedback):\n",
    "    \"\"\"\n",
    "    Formats the output of a run along with its associated feedback into a structured string.\n",
    "\n",
    "    This function takes a run object and a list of feedback objects associated with that run,\n",
    "    then formats the run's output and the feedback into a structured string representation\n",
    "    suitable for display or further processing.\n",
    "\n",
    "    Parameters:\n",
    "    - run (object): An object representing a single run. Must have an `outputs` attribute\n",
    "                    that contains a dictionary with an `\"output\"` key.\n",
    "    - feedback (list): A list of feedback objects to be formatted and included with the run's output.\n",
    "\n",
    "    Returns:\n",
    "    - str: A structured string representation of the run's output and associated feedback.\n",
    "    \"\"\"\n",
    "    all_feedback = \"\\n\".join([format_feedback(f) for f in feedback])\n",
    "    return f\"\"\"<example>\n",
    "<tweet>\n",
    "{run.outputs[\"output\"]}\n",
    "</tweet>\n",
    "<annotations>\n",
    "{all_feedback}\n",
    "</annotations>\n",
    "</example>\"\"\"\n",
    "\n",
    "\n",
    "def get_formatted_feedback(project_name: str):\n",
    "    \"\"\"\n",
    "    Retrieves and formats feedback for all runs associated with a given project name.\n",
    "\n",
    "    This function fetches run and feedback data for a specific project, then formats\n",
    "    the data into a structured string representation for each run that has associated feedback.\n",
    "\n",
    "    Parameters:\n",
    "    - project_name (str): The name of the project for which to retrieve and format feedback.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of structured string representations of runs and their associated feedback.\n",
    "    \"\"\"\n",
    "    traces = list(client.list_runs(project_name=project_name, execution_order=1))\n",
    "    feedbacks = defaultdict(list)\n",
    "    for f in client.list_feedback(run_ids=[r.id for r in traces]):\n",
    "        feedbacks[f.run_id].append(f)\n",
    "    return [\n",
    "        format_run_with_feedback(r, feedbacks[r.id])\n",
    "        for r in traces\n",
    "        if r.id in feedbacks\n",
    "    ]\n",
    "\n",
    "\n",
    "formatted_feedback = get_formatted_feedback(res_GPT[\"project_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c15306b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<example>\\n<tweet>\\n{\\'content\\': \\'🚀 Introducing Branch-Train-MiX (BTX): A novel method to train Large Language Models (LLMs) for multi-domain expertise, achieving the best accuracy-efficiency tradeoff. BTX starts with a seed model, branches out to train domain-specific experts in parallel, and mixes them into a unified MoE LLM. 🧠💡 #AI #MachineLearning #LLMs #MoE #MetaResearch\\\\n\\\\nRead more about our findings and the future of efficient LLM training: [Link to paper]\\', \\'additional_kwargs\\': {}, \\'response_metadata\\': {\\'token_usage\\': {\\'completion_tokens\\': 109, \\'prompt_tokens\\': 16573, \\'total_tokens\\': 16682}, \\'model_name\\': \\'gpt-4-turbo-preview\\', \\'system_fingerprint\\': \\'fp_49f48e4b1f\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, \\'type\\': \\'ai\\', \\'example\\': False}\\n</tweet>\\n<annotations>\\n<feedback key=note>here is better output: Branch-Train-MiX \\n\\nThis new work proposes mixing expert LLMs into a Mixture-of-Experts LLM as a more compute-efficient approach for training LLMs.  \\n\\nIt\\'s shown to be more efficient than training a larger generalist LLM or several separate specialized LLMs.\\n\\nThe approach, BTX, first trains (in parallel) multiple copies of a seed LLM specialized in different domains (i.e., expert LLMs) and merges them into a single LLM using MoE feed-forward layers, followed by fine-tuning of the overall unified model.  \\n\\nQuote from the paper: \"The main advantage of BTX compared to MoE is that expert training is embarrassingly parallel and asynchronous, reducing communication cost and increasing training throughput. Compared to Branch-TrainMerge, the final BTX model is a unified neural network that can be finetuned or used like any other standard LLM. The final BTX model will not significantly increase inference FLOPs compared to the seed model since it is sparsely activated, despite having a much larger number of parameters.\"\\n</feedback>\\n<feedback key=correctness>\\nScore:[0.0/1]\\n</feedback>\\n</annotations>\\n</example>',\n",
       " '<example>\\n<tweet>\\n{\\'content\\': \\'\"Exploring Knowledge Conflicts in Large Language Models (LLMs): A comprehensive survey by Rongwu Xu et al. unveils the intricate challenges LLMs face with context-memory, inter-context, & intra-memory conflicts. These conflicts impact LLM trustworthiness & performance, especially amidst misinformation. The study categorizes conflicts, investigates causes, LLM behaviors, & reviews solutions to enhance LLM robustness. #AI #NLP #LLMResearch\"\\', \\'additional_kwargs\\': {}, \\'response_metadata\\': {\\'token_usage\\': {\\'completion_tokens\\': 94, \\'prompt_tokens\\': 32250, \\'total_tokens\\': 32344}, \\'model_name\\': \\'gpt-4-turbo-preview\\', \\'system_fingerprint\\': \\'fp_2090dec553\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, \\'type\\': \\'ai\\', \\'example\\': False}\\n</tweet>\\n<annotations>\\n<feedback key=note>here is better output: Knowledge Conflicts for LLMs\\n\\nIt\\'s great to see a nice overview of the common issue of knowledge conflict when working with LLMs. \\n\\nThe survey paper categorized these conflicts into context-memory, inter-context, and intra-memory conflict. It also provides insights into causes and potential ways to mitigate these knowledge conflict issues.\\n\\nIf you are working with RAGs this is a well-known issue which is why I would recommend this survey paper to everyone working and building with LLMs.\\n</feedback>\\n<feedback key=correctness>\\nScore:[0.0/1]\\n</feedback>\\n</annotations>\\n</example>',\n",
       " '<example>\\n<tweet>\\n{\\'content\\': \\'\"New study introduces LearnAct, a framework that empowers Large Language Model (LLM) agents with the ability to learn and refine actions through experience, akin to human learning. By dynamically generating and updating Python functions as actions, LearnAct significantly improves LLM agents\\\\\\' performance in complex environments. #AI #MachineLearning #LLMAgents 🤖📈\\\\n\\\\nRead more about the breakthrough: [Link to paper] 📄\\\\n\\\\nExplore the code: https://github.com/zhao-ht/LearnAct 💻\"\\', \\'additional_kwargs\\': {}, \\'response_metadata\\': {\\'token_usage\\': {\\'completion_tokens\\': 110, \\'prompt_tokens\\': 17236, \\'total_tokens\\': 17346}, \\'model_name\\': \\'gpt-4-turbo-preview\\', \\'system_fingerprint\\': \\'fp_31c0f205d1\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, \\'type\\': \\'ai\\', \\'example\\': False}\\n</tweet>\\n<annotations>\\n<feedback key=note>here is better output: Advancing LLM Agents through Action Learning\\n\\nCan LLM agents be improved by learning new actions through direct interaction with the environment?\\n\\nThis work explores open-action learning for language agents through an iterative learning strategy that creates and improves actions using Python functions. \\n\\nOn each iteration, the proposed framework (LearnAct) expands the action space and enhances action effectiveness by revising and updating available actions based on execution feedback.\\n\\nThe LearnAct framework was tested on Robotic planning and AlfWorld environments. It improves agent performance by 32% in AlfWorld compared to ReAct+Reflexion. \\n\\nIt\\'s remarkable to see the performance gain when using GPT-4 as the LLM during testing. Even in the agent setting we still rely on strong language models which is why it\\'s important to keep improving model capacity, especially for open-source models.\\n\\nThese results are not surprising as in many ways humans use a similar approach to acquire and enhance skills. Overall, this is a great concept that showcases the huge potential of action learning for LLM agents.\\n</feedback>\\n<feedback key=correctness>\\nScore:[0.0/1]\\n</feedback>\\n</annotations>\\n</example>',\n",
       " '<example>\\n<tweet>\\n{\\'content\\': \\'\"Exploring the limits of AI: Subbarao Kambhampati\\\\\\'s research at Arizona State University challenges the notion that Large Language Models (LLMs) like GPT-3 and GPT-4 can autonomously plan and reason. Despite improvements, these models excel in idea generation rather than principled reasoning, highlighting the need for external verification in tasks involving complex planning. #AI #MachineLearning #Reasoning https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.15125\"\\', \\'additional_kwargs\\': {}, \\'response_metadata\\': {\\'token_usage\\': {\\'completion_tokens\\': 112, \\'prompt_tokens\\': 4869, \\'total_tokens\\': 4981}, \\'model_name\\': \\'gpt-4-turbo-preview\\', \\'system_fingerprint\\': \\'fp_ace12ee232\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, \\'type\\': \\'ai\\', \\'example\\': False}\\n</tweet>\\n<annotations>\\n<feedback key=note>here is better output: Can LLMs Reason and Plan?\\n\\nThere is a lot of debate about whether LLMs can reason and plan. \\n\\nThese are important capabilities for unlocking complex applications with LLMs such as in the domains of robotics and autonomous agents. This position paper discusses the topic of reasoning and planning for LLMs. \\n\\nHere is a summary of the author\\'s conclusion: \"To summarize, nothing that I have read, verified, or done gives me any compelling reason to believe that LLMs do reasoning/planning, as normally understood. What they do instead, armed with web-scale training, is a form of universal approximate retrieval, which, as I have argued, can sometimes be mistaken for reasoning capabilities\"\\n\\nI sometimes refer to LLMs as \"retrieval on steroids\" so it\\'s interesting to see it referred to as a form of universal approximate retrieval in this piece. I think we should have more work on theoretical analysis and rigorous evaluation to better understand whether reasoning and planning are \"truly\" possible with LLMs.\\n</feedback>\\n<feedback key=correctness>\\nScore:[0.0/1]\\n</feedback>\\n</annotations>\\n</example>',\n",
       " '<example>\\n<tweet>\\n{\\'content\\': \\'🔍 \"Retrieval Augmented Thoughts (RAT) revolutionizes LLMs\\\\\\' reasoning in long-horizon tasks, reducing hallucinations by iteratively refining thoughts with task-relevant info. Applied to GPT-3.5, GPT-4, & CodeLLaMA-7b, RAT boosts performance across code generation, math reasoning, creative writing, & planning tasks. #AI #MachineLearning #NLP\" 🌐 Demo: craftjarvis.github.io/RAT\\', \\'additional_kwargs\\': {}, \\'response_metadata\\': {\\'token_usage\\': {\\'completion_tokens\\': 103, \\'prompt_tokens\\': 24252, \\'total_tokens\\': 24355}, \\'model_name\\': \\'gpt-4-turbo-preview\\', \\'system_fingerprint\\': \\'fp_2090dec553\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, \\'type\\': \\'ai\\', \\'example\\': False}\\n</tweet>\\n<annotations>\\n<feedback key=correctness>\\nScore:[0.0/1]\\n</feedback>\\n<feedback key=note>Here is better output: Retrieval Augmented Thoughts\\n\\nShows that iteratively revising a chain of thoughts with information retrieval can significantly improve LLM reasoning and generation in long-horizon generation tasks. \\n\\nThe key idea is that each thought step is revised with relevant retrieved information to the task query, the current and past thought steps. \\n\\nRetrieval Augmented Thoughts (RAT) can be applied to different models like GPT-4 and CodeLlama-7B to improve long-horizon generation tasks (e.g., creative writing and embodied task planning).\\n\\nRAT is a zero-shot prompting approach and provides significant improvements to baselines that include zero-shot CoT prompting, vanilla RAG, and other baselines. \\n\\nInteresting idea to elicit context-aware reasoning and how it can benefit these long-horizon generation tasks.\\n</feedback>\\n</annotations>\\n</example>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983f583-90e4-48d8-90ab-140143874b79",
   "metadata": {},
   "source": [
    "## 5. Generate new version of the prompt\n",
    "\n",
    "Template that accepts the above feedback:\n",
    "\n",
    "https://smith.langchain.com/hub/rlm/prompt-optimizer-tweet-drafts?organizationId=1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d437c331-5710-473c-b547-f07ee22dbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def extract_new_prompt(gen: str):\n",
    "    return gen.split(\"<improved_prompt>\")[1].split(\"</improved_prompt>\")[0].strip()\n",
    "\n",
    "\n",
    "optimizer_prompt = hub.pull(\"rlm/prompt-optimizer-tweet-drafts\")\n",
    "optimizer = optimizer_prompt | chat_GPT | StrOutputParser() | extract_new_prompt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9510f962-eaa5-45b7-8f8a-1573e8505c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "New Prompt\n",
      "\n",
      "<role> You are an assistant tasked with generating concise, informative Tweets that summarize academic papers or open-source projects. Your Tweets should capture the essence of the work, highlighting its novelty, methodology, and impact without resorting to gimmicks or an overuse of buzzwords. Aim for clarity and brevity, ensuring the Tweet is accessible to a broad audience. </role>\n",
      "\n",
      "Instructions:\n",
      "- Begin with a clear, engaging statement that captures the main contribution or finding of the paper/project.\n",
      "- Briefly describe the methodology or approach taken, using layman's terms where possible.\n",
      "- Highlight the significance or potential impact of the work, avoiding technical jargon.\n",
      "- Conclude with a call to action, such as inviting readers to read the full paper or explore the project further, without including a specific link.\n",
      "- Your Tweet should not exceed 280 characters, aiming for the sweet spot of 200-250 characters for optimal engagement.\n",
      "- Avoid emojis, hashtags, and URLs to keep the focus on the content's substance.\n",
      "\n",
      "Example:\n",
      "\"Discover how the new Branch-Train-MiX method revolutionizes training for Large Language Models by efficiently combining domain-specific expertise. This approach promises significant advancements in AI efficiency and accuracy. Dive into the groundbreaking research.\"\n",
      "\n",
      "Remember, the goal is to distill complex information into an easily digestible and engaging Tweet that sparks interest and understanding among a diverse audience.\n",
      "\n",
      "<paper> {paper} </paper>\n"
     ]
    }
   ],
   "source": [
    "new_prompt_str = optimizer.invoke(\n",
    "    {\n",
    "        \"current_prompt\": current_prompt_str,\n",
    "        \"annotated_predictions\": \"\\n\\n\".join(formatted_feedback).strip(),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"*\" * 80 + \"\\nNew Prompt\\n\\n\" + new_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52f518ad-ea67-4941-99ee-33eb17fa7828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/hub/coldra1n/tweet-draft-prompt/6cf86eb2'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it in\n",
    "new_prompt = ChatPromptTemplate.from_messages([(\"user\", new_prompt_str)])\n",
    "hub.push(\"coldra1n/tweet-draft-prompt\", new_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25e487-ee5f-4e68-9524-acf1dcf5aba0",
   "metadata": {},
   "source": [
    "## 6. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8724c10-a587-421b-894f-dc02fe29e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'left-son-60' at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/datasets/892cdeb2-0332-43b4-9c15-c36e6613e316/compare?selectedSessions=7d2d4b62-35ba-4cd0-ab33-b4b8cffe2947\n",
      "\n",
      "View all tests for Dataset Tweet Generator at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/datasets/892cdeb2-0332-43b4-9c15-c36e6613e316\n",
      "[------------------------------------------------->] 3/3"
     ]
    }
   ],
   "source": [
    "# Chain\n",
    "tweet_generator_v2 = new_prompt | chat\n",
    "\n",
    "updated_results = client.run_on_dataset(\n",
    "    dataset_name=ds_name,\n",
    "    llm_or_chain_factory=tweet_generator_v2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f9dbb41f-af98-4853-b372-efe3e1a8d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_runs_to_annotation_queue(\n",
    "    q.id,\n",
    "    run_ids=[\n",
    "        r.id\n",
    "        for r in client.list_runs(\n",
    "            project_name=updated_results[\"project_name\"], execution_order=1\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3a7fa-8e8c-4ab6-90e8-cdf77ea1dd9b",
   "metadata": {},
   "source": [
    "Paper that was referenced, but not summarized - \n",
    "\n",
    "https://x.com/omarsar0/status/1763187964501254492?s=20\n",
    "\n",
    "Paper - \n",
    "\n",
    "https://arxiv.org/abs/2402.17944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a8a02fc-04de-423a-ab84-d56f286ba6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "********************************************************************************\n",
      " Old tweet\n",
      "\n",
      "Here is a potential Tweet to summarize the paper:\n",
      "\n",
      "New survey on using large language models (LLMs) for tabular data tasks like prediction, generation, and question answering. Covers key techniques like serialization, prompt engineering, and benchmarks. Identifies opportunities and challenges.\n",
      "\n",
      "The Tweet concisely captures the main points of the survey paper:\n",
      "\n",
      "- It's about applying LLMs to various tabular data tasks \n",
      "- Discusses key enabling techniques and benchmarks\n",
      "- Highlights both the potential and open challenges in this emerging area\n",
      "\n",
      "The Tweet avoids jargon and gives a high-level overview that would be understandable to a broad audience interested in AI and data science. It motivates reading the full paper to dive deeper into the techniques and implications.\n",
      "********************************************************************************\n",
      " New tweet\n",
      "\n",
      "Here is a summary tweet for the paper \"Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey\":\n",
      "\n",
      "Unlocking LLMs' Potential for Tabular Data 🔑\n",
      "\n",
      "This comprehensive survey explores how large language models can be applied to tabular data for tasks like prediction, generation, and understanding.\n",
      "\n",
      "Key techniques covered:\n",
      "- Serializing tables into LLM-readable formats\n",
      "- Table manipulations to fit context length\n",
      "- Prompt engineering tricks \n",
      "- Building end-to-end systems\n",
      "\n",
      "The paper provides a taxonomy of datasets, metrics, and methods for each application area. It also discusses current limitations and future research directions.\n",
      "\n",
      "LLMs show great promise for working with structured data when combined with the right preprocessing steps and prompting strategies. This opens up exciting possibilities for more intelligent and automated systems to analyze tabular data.\n",
      "\n",
      "What other innovative applications of LLMs to structured data do you foresee? 🤔\n"
     ]
    }
   ],
   "source": [
    "doc = ArxivLoader(query=\"2402.17944\", load_max_docs=1).load()\n",
    "example_tweet_v1 = tweet_generator.invoke({\"paper\": doc[0].page_content})\n",
    "example_tweet_v2 = tweet_generator_v2.invoke({\"paper\": doc[0].page_content})\n",
    "print(\"*\" * 80 + \"\\n Old tweet\\n\\n\" + example_tweet_v1.content)\n",
    "print(\"*\" * 80 + \"\\n New tweet\\n\\n\" + example_tweet_v2.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
